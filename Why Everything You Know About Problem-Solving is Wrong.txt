SYSTEMANTICS
THE SYSTEMS BIBLE

THE BEGINNER'S GUIDE TO SYSTEMS LARGE AND SMALL
BEING THE THIRD[a]EDITION OFSYSTEMANTICS
BY
JOHN GALL

ILLUSTRATED BY D. H. GALL

GENERAL SYSTEMANTICS PRESS
1

WALKER MINNESOTA

Third Edition, Copyright © 2002 by John Gall
Second printing 2006
Third printing 2011
Version 3.5 2012
“This Third Edition has been extensively revised and expanded by the
addition of several new Chapters including new Axioms, Theorems, and Rules
of Thumb, together with many new case histories.”
Printed at Saline, Michigan, by McNaughton & Gunn. Text is 11 pt. Times
Roman. Illustrated by D. H. Gall.
Library of Congress Control Number: 2002095534
Library of Congress Cataloging in Publication Data:
Gall, John, 1925Systemantics.
First ed. published in 1975 under title: General Systemantics. Published by
Quadrangle/The New York Times Book Company, Inc., 1977.
Second ed., first printing 1986.
Third edition 2002.
Bibliography: p. 1.
System theory-anecdotes, facetiae, satire, etc.
I. Title
For paperback edition: ISBN 0-9618251-7-0

Published by: The General Systemantics Press
7027 So. Walker Bay Rd., N.W.
Walker, MN 56484.
FAX: (218) 547-0195.
Website: www.generalsystemantics.com.

TO MY ALMA MATER
ST. JOHN’S COLLEGE
—for having the courage to be different and for
encouraging me to be the same—that is, different.
1

Table of Contents
Acknowledgments
Preface to the First Edition
Preface to the Second Edition
Preface to the Third Edition
Introduction
Historical Overview
Part One: Basic Theory
A. The Mysterious Ways of Systems
First Principles
2. Laws of Growth
3. The Generalized Uncertainty Principle
4. A…B…C…Disaster (Feedback)
5. The Power Of Positive Feedback: A Warning
6. What Next? (The Life Cycle Of Systems)
B. Inside and Outside
7. The Grand Illusion
8. Inside Systems
9. Delusion Systems Versus Systems Delusions
10. Systems-People
C. Function and Failure
11. Elementary Systems-Functions
12. Advanced Systems-Functions
13. The System Knows (System Goals)
14. Systems-Failure (Theory of Errors)
15. Glitches, Gremlins, Bugs
16. Form, Function, Failure
17. Colossal Errors
18. Unexpected Interactions
D. Communication Theory
19. Communication Theory
20. Information
21. Talking to the System
Part Two:Applied Systemantics
A. Systems and Self-Defense (Meta-Strategies)
22. How Not to Solve Problems
23. The Tao of Problem Avoidance

24. The Creative Tack
B. Practical Systems-Design
25. Design Don’ts
26. Catastrophe Theory
C. Management and Other Myths
27. Wishful Feedback
28. Fear of Feedback
29. Feedback and the Future
30. Catalytic Managership
31. The “Problem” Problem
32. The Limits to Grandiosity
33. Disaster Control
D. Intervention
34. Where’s the Problem?
35. Probing the System
36. The Problem in the Solution
37. Taming Systems
38. The Problem in the Question
39. The Net of Indra
40. Beyond Stability
41. After the Solution, What? (The Next Problem)
42. Envoi: Beyond Expertise
43. Appendix I. Annotated Compendium
44. Appendix II. Self-Evaluation Quizzes
45. Appendix III. Readers’ Tear-Out Feedback Sheet
46. Appendix IV. Horrible Examples
47. Appendix V. Glossary
48. Appendix VI. Animal Exemplars
49. Appendix VII. List of Horrible Examples
50. Biased Bibliography and Good Reading List
51. Endnotes and References
7

Acknowledgments
To Kenneth Boulding, whose ever-fertile mind continued to sprout new
concepts for the new age, and who encouragedSystemanticswhen it was still but
a sprawling pup;
To Robert L. Weber, author ofA Random Walk In Science, who
recognizedSystemanticsas a sister endeavor and wrote the review that provided it
with entree into the Establishment of Humane Letters;
To W. Evert Welch, who joyfully and freely shared the wisdom acquired in a
lifetime of close encounters with Systems;
And to Hamilton Armstrong, George I. Brown, Richard Byrne, Kathleen
Ursin, William E. Powers, S. A. Lanzarotta, R. L. Payton, Edward G. Prentice,
Frederick R. Cronin, William Delaney, Helen Harte, Johann Klaassen, and many
others, for stimulus, encouragement, and support.
7

Preface to the First Edition
The immediate motivation for undertaking this work was provided by the
bizarre experience of a colleague of the author (let us call him Jones), a medical
scientist specializing in the study of Mental Retardation. That field until recently
was a very unfashionable one for investigation, and Jones considered himself
fortunate to be employed as Research Associate at a small State Home for
Retarded Children. In this humble, even despised position, he was too low on the
Civil Service scale to merit the attention of administrators, and he was therefore
left alone to tinker with ideas in his chosen field. He was happily pursuing his
own research interests when, following Presidential interest and national
publicity, Mental Retardation suddenly became a fashionable subject. Jones
received an urgent invitation to join an ambitious federally-funded project for a
systematic attack upon the “problem” of mental retardation.
Thinking that this new job, with its ample funds and facilities, would advance
him in his own career while also facilitating his research, Jones joined. Within
three months his research had come to a haIt, and within a year he was unable to
speak or think intelligently in the field of mental retardation. He had, in fact,
become retardedrelative to his previous condition.
Looking about him to discover, if possible, what had happened, Jones found
that a dozen other skilled professionals who made up the staff of the project had
experienced a similar catastrophe. That ambitious project, designed to advance
solutions to the “problem,” had in fact taken most of the available workers in the
field and neutralized them.
What had gone wrong? Jones, knowing of the author’s interest in Systems
Operation, turned to him for advice, and the two investigators jointly tried to
analyze the problem. They first of all reviewed Parkinson’s classic essay[i] on
Institutional Paralysishoping to find enlightenment there. Was the disease a
fulminating case of Injelititis? Obviously not: the professional staff of the
Institute were competent, dedicated, and hardworking. Furthermore, the
administrators were experienced, energetic, and extremely logical in their
approach to problems.The Institute was failing in spite of the best efforts of every
one of its members.
Was it an example of the Peter Principle,[ii]in which members of the staff had
ascended the hierarchy until they had reached jobs for which they were not
fitted? No. This was a new organization, and no one had been promoted very
far.Slowly it began to dawn upon the investigators that we humans do not yet
understand the basic laws governing the behavior of complex organizations. A

great enterprise can flounder helplessly or even wither away before our very
eyes, as a result of malignant but as yet unnamed disorders, or in response to the
operation of natural laws whose Newton has not yet been born to announce them
to Mankind.
Faced with this realization, and moved by the dramatic and touching crisis
that had overtaken his colleague, the author resolved to redouble his researches
into the causes of organizational ineptitude and Systems malfunction, seeking
deep below the surface for the hidden forces that cause the best-laid plans to
gang agley. Little did he suspect, at that moment, where those studies would
lead. He had not yet experienced the blinding illumination of the
OPERATIONAL FALLACY. The FUNDAMENTAL THEOREM OF
SYSTEMANTICS lay well over the horizon. Even the relatively simple and
easy-to-understand GENERALIZED UNCERTAINTY PRINCIPLE was not yet
a gleam. Those and other deep- ranging and depressing generalizations were to
come only much later, after many minutes, hours, even days of exhaustive
researches conducted under the least auspicious circumstances.
What follows is the fruit of those researches, set forth as briefly and as simply
as possible, in a style that is deliberately austere and (the author may be
permitted to hope) even not without a certain elegance, derived from the
essentially mathematical nature of the science itself. The reader must imagine for
him-or-herself at what cost in blood, sweat, and tears— and in time spent in deep
observation of contemporary Systems—these simple statements have been
wrung from the messy complexity of the real world. They are offered in the hope
and faith that a knowledge of the natural laws of complex Systems will enable
Mankind to avoid some of the more egregious errors of the past.
At the very least it is hoped that this little book may serve as a warning to
those who read it, thus helping to counter the headlong rush into Systemismthat
characterizes our age. And who knows? Perhaps readers of this modest treatise
will be stimulated to discover new Systems- insights of their own, that can lead
to even higher achievements for the infant science of Systemantics.
9

Preface to the Second Edition
We are forced to report that in the interval since the original edition
ofSystemantics, no significant improvement in Systems-behavior has taken
place. Indeed, the unexpected antics of certain truly Colossal Systems—for
example, the radioactive decay of the Nuclear Power Industry—have surprised
even some who (having been exposed to previous exhibitions of Large-Systems
behavior) had thought themselves beyond surprise.
Nor has Coping with Systems become any easier. Computers have brought
with them a host of new opportunities for malfunctions at the interface between
Systems and the hapless Individual. A bank customer may be presented with a
bill for the whole bank’s overhead for the month; a credit-card holder may be
held accountable for everyone’s purchases. Furthermore, as these examples
suggest, increasing Consolidation and Centralization have raised the stakes in
cases of error. A broken pipe in a Nuclear Power Plant can cut off the power to
an entire Province or even a whole nation. In Detroit, a computer, having been
fed all the votes in a major election (over a million in all), refused to tell how
many were for whom. At last report the votes were still being tallied by hand.
Nevertheless, the response to the First Edition of Systemantics has been
gratifying. From distant corners of the globe and from next-door neighbors have
come comments, Horrible Examples, and new Axioms, many of which have
been incorporated in this new Edition. There have, naturally enough, been some
grumblers, too. There are those who reject the universal validity of the Primal
Scenario[a.], with its overtones of muddle and mediocrity, in favor of their own
formulation:
THINGS HAVE NEVER BEEN BETTER—BUT THEY’RE IMPROVING
Although we refrain, as a matter of policy, from dusty polemics, we invite the
reader, in rebuttal, merely to survey the course of national and global events
during the time that has elapsed since the First Edition. If, having objectively
done that, the reader still inclines to the above formulation in preference to the
Primal Scenario, then Systemantics is probably not for him or her. While we do
not propose to actually carry out such a survey for the reader, we offer the
following small Starter Kit of typical items, merely to provide an idea of how to
proceed:
•An austerity budget, proposed and implemented by a Conservative
administration, results in the largest deficits in U.S. history.
•The “non-aligned” nations continue to attack each other vigorously for not

being sufficiently against the “aligned” nations.[b.]
•The major product of book-publishing companies is now the non-book.
•The Theory of Plate Tectonics—the major advance in Geology in this
century—is rejected by the leading Geophysical journal to which it was
submitted. (See Notes and Refs for documentation)[iii]
•Contact with required safety equipment is now a major cause of sports
injuries.
•The British fighting ship H.M.S. Sheffield, defended by a computer, is
struck and sunk by a missile the computer had been instructed to ignore as
“friendly.” [iv]
Naturally the picture is not entirely dark. Here and there are encouraging
signs that the Spirit of Systemantics is beginning to take hold. For example:
•The police in a State in southern Brazilhave begun a protest against low
pay and poor working conditions. The form of their protest? They
havestopped making illegal arrests. Arrests are down 90% since the protest
began.[v]
•In similar vein, when the workers of Solidarity Union, in Poland, went on
strike, they were striking, of course, for theright to strike. Theirs is the
quintessential spirit of the Science of Systemantics.
•Not to be outdone by their comrades in the Eastern Bloc,
NewfoundlandCivil Servants recently went on strike in protest against
restrictions ontheirright to strike.[vi]
A question frequently asked is: does not the persistent occurrence of Horrible
Examples of Systems-function (or Malfunction) prove something about human
nature? If humans were rational, wouldn’t they act otherwise than they do? We
reply: Systems-functions are not the result of human intransigeance. We take it
as given that people are generally doing the very best they know how. Our point,
repeatedly stressed in this text, is that Systems operate according to Laws of
Nature, and that Laws of Nature are not suspended to accommodate our human
shortcomings. There is no alternative to learning How Systems Work, unless one
is willing to continue to run afoul of those Laws. Whoever does not study the
Laws of Systemantics and learn them that way, is destined to learn them the hard
way, by direct encounter in the world of Experience. That such runnning-afoul
continues to occur is simply a reflection of the fact that knowledge of those laws
is not yet sufficiently widespread. The problem is one of Education, and this
book represents an effort in that direction.
S. Freud, in his great work on the Psychopathology of Everyday Life, directed

attention to the lapses, failures, and mishaps resulting from forces
operatingwithin the individual. We, on the other hand, are interested in those
lapses, failures, and mishaps that are attributable to the (mal)functioning of
theSystems surrounding the individual, within which the individual is immersed
and with which he or she must interact and attempt to cope in everyday life.
Specifically, we are interested, not in the process of forgetting to mail a letter,
but in the Post Office Box that is too full to acceptthat letter.[c. ][vii]We are
interested, not in the traveler who forgets to take Highway 17 to reach his or her
destination, but in the Freeway Interchange that lacks a ramp for access to
Highway 17. We are concerned with that strange, self-defeating quality of a
System that ensures that a Pension Plan, when finally activated, will never
provideenoughmoney, and that an Emergency Phone Line will likely be busy
when you really need to get through.[d. ][viii]We stress, further, that these words
are not written for those who are having no problem with Systems—those
fortunate individuals who have never encountered a Vending Machine that takes
their money but fails to deliver the goods; those who have never been attacked
by an automated mop cart in a hospital corridor, who have never been
misidentified by the Internal Revenue Service nor promoted to Section Chief
three weeks before the Section is abolished. We are writing, in the most general
sense, from the standpoint of Everyman, the victim of Systems, the individual
who must daily interact with them and cope with them as best s/he can.
Failure, the Final Taboo
Like Freud’s observations on the lapses of everyday life, these observations on
the lapses of Systems have led us, step by step, into the wonderland of Systemsfunction, a wonderland fully as strange as the world of the Unconscious explored
by Freud. And like those lapses followed up by Freud, these lapses have a way
of eluding us, of disappearing from our consciousness once the painful encounter
is over.Failure is perhaps our most taboo subject.
Charles Darwin made it a rule to write down immediately any observation or
argument that seemed to run counter to his theories. He had noticed that we
humans tend to forget inconvenient facts, and if special notice is not taken of
them, they simply fade out of awareness. Therefore, urged Darwin:
CHERISH YOUR EXCEPTIONS
Along similar lines, we propose:
CHERISH YOUR SYSTEM-FAILURES
One need only follow this precept for a few days to become aware of the true
dimensions of the discrepancy between the world as advertised and as it actually

functions or fails to function. When Memoryis thus deliberately frustrated in its
basic task ofprotecting us from too much awareness, we see what we had
hitherto failed to notice: that malfunction is the rule and flawless operation the
exception. Even in the world of computers, Professor Kemeny reminds us that
“most computer runs do not result in the solution to a problem, but in the
detection of errors or in the printing of completely wrong answers.”[ix]
The advent of the Computer Revolution merely provides new opportunities
for errors at levels of complexity and grandiosity not previously attainable. The
microprocessor, like the multinational corporation, is even now providing
material for new chapters in the Annals of Egregious and Unexpected
Misbehavior. Intelligent machines, when they arrive, will demonstrate the
inability of the human imagination to anticipate the truly bizarre and mindboggling forms of malfunction of which complex Systems are capable.
The reader who is familiar with the First Edition will note, in the Second
Edition, a very slight and subtle shift of focus, a change of emphasis, in the
direction of Pragmatism. Some of the later Chapters, if read uncritically, could
even lead to a sort of optimism regarding Man’s ultimate ability to take charge of
Systems—those created by his own hand as well as those originated by Mother
Nature. The reader is hereby warned that any such optimism is the reader’s own
responsibility. The author, for his own part, remains firmly convinced that the
height and depth of practical wisdom lies in the ability torecognize and not to
fight againstthe Laws of Systems. Systemantics is a Science, perhaps even a
branch of Mathematics. Pathways to success can only be found, not made. In
order to emphasize that conviction, we here spell out our basic strategy, which
was implicit in the pages of the First Edition and is now made explicit:
THE MOST EFFECTIVE APPROACH TO COPING IS TO LEARN THE
BASIC LAWS OF SYSTEMS-BEHAVIOR
As Virginia Satir has aptly reminded us:[x]
PROBLEMS ARE NOT THE PROBLEM; COPING IS THE PROBLEM
We shall continue to warn against the dangers of megalomania and shall
persist in our practice of proceeding cautiously, one small step at a time,
continually emphasizing the importance of utmost clarity and precision in our
concepts. The world may largely consist of Fuzzy Systems[e] but fuzzy thinking
is definitely not the way to Cope with them, let alone to Prevail.
12

Preface to the Third Edition
The world rolls on, constantly changing. Current events take place every day,
perhaps even more so than before, providing new and even more edifying
examples of Systems-function. The diligent Systems- student may wonder, in the
midst of all this bewildering activity,
“Is there anything steadfast, anything permanent, to serve as a sheet- anchor in
the gales of constant change?”
The answer remains, as always, “Yes.” There is a steady point of reference.
The Principles of Systems-function do not change. They remain as reliable as
they were when first collected within the pages ofSystemantics. But the passage
of time has brought to light not only new Horrible Examples, but also new
Axioms and above all, deeper insights, that justify us in bringing out a new
essay.
However, we remain committed to our original positions of Humbleness and
of Caution in dealing with Systems of any size. Recent experience has borne in
upon us with even greater emphasis the necessity of this twofold attitude, and we
venture the opinion that no amount of scientific advance in the study of Systems
will ever enable us to depart from that fundamental orientation. A System, after
all, is a partial Intelligence; it participates in the great Mind of the Universe; and
unless we ourselves have a direct pipeline into that Mind, we had jolly well
better watch our step. Systems don’t appreciate being fiddled and diddled with.
They will react to protect themselves; and the unwary intervenor may well
experience an unexpected shock.
Language such as the above, with its half-humorous attribution of Conscious
Purpose to systems, has elicited a cry of dissent from a Critic who accuses the
author of trying to reintroduce Demons into scientific discourse and indeed, into
systems.[xi]For his own part, the author disclaims any such intent. If there are
Demons in systems, they were not put there by this humble student. However,
the author finds blind faithaplenty—blind faith insystems—placed there by
scientists themselves and by practically everyone else.
We live in a new age of faith, an age of faith in systems. If there is any one
belief which is not challenged anywhere in the world, it is this faith in systems.
Russians, Chinese, Americans, Africans, may differ on everything else in the
world, but the one thing they all agree on is that whatever the problem may be,
the answer lies in setting up some system to deal with it. There seems to be no
hint of awareness that there could be a pitfall in all this; that a system is not

simply a straightforward set of plans that we, the masters, make.
Indeed, it is our human fate to have to deal with systems, both those in which
we find ourselves and those that we build. We are the tool-using creature par
excellence. But if we remain unaware of what we are actually doing when we
use a tool, when we make a plan, when we interact with our surroundings—well,
such unawarenessis usually rewarded with an unpleasant surprise at some point
in the future, if not immediately.Our purpose is to help the Systems-student to
minimize such experiences; to become aware of the many opportunities of
incurring such a shock; and to be mentally prepared, so that the shock will at
least not be unexpected.
Ominously, the Angry Upright Ape with the Spear is back again, more
numerous and more grimly determined than ever, insisting on trying to achieve
through Rage what can only be accomplished through Correct Perception,
Analysis, and Appropriate Response—in brief, through mastery of Systemantics.
Since the author’s personal platform is one of sincere opposition to
unpleasantness of whatever kind, this development provides another personal
motive for bringing forth this Third Edition ofSystemantics.
Readers’ initial responses toSystemanticstend to be either strongly positive or
strongly negative. A typical positive reaction is along the lines of:
“Yes! Yes! Yes! This is what happens to me all the time! Thank goodness
someone has finally brought it out into the open!”
Negative responses tend to be approximately:
“Why does the author keep harping on the bad stuff? So mistakes happen. Is
that any reason to dwell on them?”
Negative responses are more interesting than positive responses because they
indicate that learning could be about to take place. The Negative Responder is
usually experiencing Cognitive Dissonance and deserves our sympathetic
understanding.
Just before a dolphin actually understands the point of a new routine, it gets
more and more irritable, swims in circles and finally loses its temper, leaps out
of the water and sends a giant splash over the trainer. Psychologists call it
Cognitive Dissonance—that irritating feeling that something just doesn't fit.
Karen Pryor, the Dolphin Lady, whose animal-training methods are used worldwide, calls it the Learning Tantrum.
Down through history, the Learning Tantrum recurs at moments of crisis.
When Darwin proposed his new theory, the Establishment had a collective fit.
Sigmund Freud had to set up his own press in order to get published. And the
new breed of scientists around Einstein recognized sadly that new theories in

physics only prevail as the previous generation of physicists die off.
Cybernetic interaction—that is, feedback and error-correction—appears to
apply to a wide range of human functions. Gregory Bateson once called it, “. .
.the biggest bite out of the apple since Eve.”
It is also a difficult idea to grasp. But error correction is a big part of what we
do. We notice (or, worse, fail to notice) the difference between our expectations
and our actual sensory feedback. When we notice it, we register it as an error, a
defect, a failure, a shortcoming, something to be corrected. If we fail to notice it,
or if, instead of acknowledging the discrepancy we have noticed, we try to shut it
out (see Taboo on Failure, in Preface to the Second Edition) and proceed as if it
weren't there—then we have the bizarre, funny, sometimes excruciating results
catalogued inSystemantics.
Anyone who struggles to take in this hard and humbling lesson—that error is
our existential situation and that our successes are destined to be temporary and
partial—deserves our sympathy.Systemanticsis an attempt to make the
experience bearable by means of humor and irony. Those are the qualities that
people have called upon down through the ages to enable them to cope with the
permanently provisional human situation.
It’s a good sign that at least one critic foundSystemanticsdisturbing, because
there is after all a deeper, more serious side to it under the humor. There really
are unknown and perhaps unknowable aspects of the world around us, and
awareness of that fact is a very necessary part of any non-trivial approach to
human knowledge. The critic may be right in suggesting that there are "demons"
inSystemantics. But they were not put there by the author.
They reside in the material itself, in the baffling behavior of this Universe in
which we find ourselves.
14

Introduction
All around us we see a world of paradox: deep, ironic, and intractable. A
world in which the hungry nations export food; the richest nations slip into
demoralizing economic recessions; the strongest nations go to war against the
smallest and weakest and are unable to win; a world in which revolutions against
tyrannical systems themselves become tyrannies. In human affairs, celebrities
receive still more publicity because they are “well known”; men rise to high
positions because of their knowledge of affairs only to find themselves cut off
from the sources of their knowledge; scientists opposed to the use of scientific
knowledge in warfare find themselves advising the government on how to win
wars by using scientific knowledge. . . the list is endless. Ours is a world of
paradox.
Why is this? How does it come about that things turn out so differently from
what common sense would expect?
The religious person may blame it on Original Sin. The historian may cite the
force of trends such as population growth and industrialization. The Sociologist
offers reasons rooted in the peculiarities of human associations. Reformers
blame everything on “the system” and propose new systems that would—they
assert—guarantee a brave new world of justice, peace, and abundance.
Everyone, it seems, has his own idea of what the problem is and how it can be
corrected. But all agree on one point—that their own System would work very
well if only it were universally adopted.
The point of view espoused in this essay is more radical and at the same time
more pessimistic. Stated as succinctly as possible: the fundamental problem does
not lie in any particular System but rather in Systems As Such (Das System an
und fuer sich)[a.]. Salvation, if it is attainable at all, even partially, is to be
sought in a deeper understanding of the ways of all Systems, not simply in a
criticism of the errors of a particular System.
But although people build Systems almost instinctively,[b. ] they do not
lightly turn their ingenuity to the study of How Systems Work. That branch of
knowledge is not congenial to human beings; it goes against the grain. Goaloriented Man, the Upright Ape with the spear, is interested in the end-result. If
the spear flies wide of the mark, Man is equally likely to trample it to bits in a
rage or to blame the erratic flight on malevolent spirits. He is much less likely to
undertake a critical analysis of hand- propelled missiles, and infinitely less likely
to ponder the austere abstractions presented in this book.

If young people lack experience and interest for understanding How Systems
Work, older persons are already defeated. They may have learned by direct
experience a few things about Systems, but their experience will have been
fragmentary and painful. And in any case, for them the battle is over. No, only a
handful—only a lucky few—ever come to clear awareness of this dread and
obscure subject. Will you be one of those?
No one, these days, can avoid contact with Systems. Systems are everywhere:
big Systems, little Systems, Systems mechanical and electronic, and those
special Systems that consist of organized associations of people. In self-defense,
we must learn to live with Systems, to controlthemlesttheycontrolus. As Humpty
Dumptysaid to Alice (though in another context):It’s just a question of who is to
be master, that’s all.
No one can afford not to understand the basic principles of How Systems
Work. Ignorance of those basic laws is bound to lead to unrealistic expectations
of the type that have plagued dreamers, schemers, and so- called men of affairs
from the earliest times. Clearly there is a great need for more widespread
knowledge of those basic laws. But (and just here is another example of the
paradoxical nature of Systems-functions) there is a strange dearth of available
information written for the general reader. Technical tomes of Systems Analysis
and Operations Research abound on the shelves of science libraries and of
business management institutes. But nowhere is there to be found a single basic
primer that spells out the essential pragmatic facts of practical systems in the
form of simple and easy-to-grasp Axioms. Similarly there are no courses in
Systems Function in our High Schools and Junior Colleges. Like sex education,
Systems Sophistication has until recently been a Taboo Subject. This book
breaks the taboo. It tells all, in frank and intimate language understandable to
anyone who is willing to read and reflect. No longer can people take refuge in
the plaint, “Nobody told me.”
It’s all here, within the covers of one small book.[c.]
16

Historical Overview
All over the world, in great metropolitan centers as well as in the remotest
rural backwaters, in sophisticated electronics laboratories and in dingy clerical
offices, people everywhere are struggling with a Problem:[a. ][xii]
THINGS AREN’T WORKING VERY WELL
This, of course, is nothing new. People have been discouraged about things in
general many times in the past. A good deal of discouragement prevailed during
the Dark Ages, and morale was rather low in the Middle Ages, too. The
Industrial Revolution brought with it depressing times, and the Victorian era was
felt by many to be particularly gloomy.[b.] At all times there have been people
who felt that things weren’t working out very well. This observation has
gradually come to be recognized as an ongoing fact of life, an inseparable
component of the Human Condition. Because of its central role in all that
follows (being the fundamental observation upon which all further research into
Systems has been based) it is known as the Primal Scenario. We give it here in
full:
THINGS (THINGS GENERALLY/ ALL THINGS/THE WHOLE WORKS)
ARE INDEED NOT WORKING VERY WELL. IN FACT, THEY NEVER DID
In more formal terminology:
SYSTEMS IN GENERAL WORK POORLY OR NOT AT ALL
More technically stated:[c. ][xiii]
COMPLICATED SYSTEMS SELDOM EXCEED FIVE PERCENT
EFFICIENCY
But this fact, repeatedly observed by men and women down through the ages,
has always in the past been attributed to variousspecial circumstances.It has been
reserved for our own time, and for a small band of individuals of genius
(working mostly alone), to throw upon the whole subject the brilliant light of
intuition, illuminating for all Mankind the previously obscure reasons why
Things So Often Go Wrong, or Don’t Work, or Work In Ways Never
Anticipated. To list the names of those contributors is to recite the Honor Roll Of
Systemantics.
No history of the subject would be complete without some reference to the
semi-legendary, almost anonymous Murphy[d.][xiv](floreat circa 1940?) who
chose to disguise his genius by stating a fundamental Systems Theorem in
commonplace, almost pedestrian terminology. This Law, known to schoolboys

the world over asJelly-bread always falls jelly side down, is here restated in
Murphy’s own words, as it appears on the walls of most of the world’s scientific
laboratories:
IF ANYTHING CAN GO WRONG, IT WILL
In the Law as thus formulated, there is a gratuitous and unjustified element of
Teleology, an intrusion of superstition or even of belief in magic, which we
today would resolutely reject. The universe is not actually malignant, it
onlyseemsso.
Shortly after Murphy, there appeared upon the scene a new and powerful
mind, that of Count Alfred Korzybski,[xv]in whose honor the entire field of
General Systemantics has been named. Korzybski was the creator ofGeneral
Semantics, a vaulting effort at a comprehensive explanation of Why Things
Don’t Work. This early attempt to pinpoint the flaw in human Systems was itself
flawed, however, by the author’s monistic viewpoint.
Korzybski seemed to have convinced himself that all breakdowns of human
Systems are attributable to misunderstandings—in brief, to failures of
communication.
Our position, on the contrary, is that human Systems differ only in degree, not
in kind, from other types of Systems. Systems in general are prevented from
working, not by some single, subtle, hidden defect, whether of communication
or of anything else. We shall show in a later Chapter thatfailure to function as
expectedis to beexpected, and that this behavior results from Systems-laws that
are as rigorous as any in Natural Science or Mathematics. Hence the
appropriateness of the termGeneral Systemanticsfor the entire field. It is a
perfectlygeneralfeature of Systems not to do what we expected them to do.
Furthermore, the word “ANTICS” hidden in the term “Systemantics” carries
this implication in a lively way. SYSTEMS DISPLAY ANTICS. They “act up.”
Nevertheless, as we shall see, Korzybski, by stressing the importance of precise
definitions, laid the groundwork for the Operational Fallacy, which is the key to
understanding the paradoxical behavior of Systems.
One is tempted at this point to mention the name of Ludwig von
Bertalanffy[e.][xvi], if only to pay due respect to the founder of the scientific,
mathematical Theory of Systems. But Systemantics, we hasten to add, is
something else again. System Theory is a respectable academic subject,
elaborated at leisure by professional scholars (mostly with tenure) who have the
time and security to make sure that their researches turn out the way they should.
Systemantics, by contrast, is almost a form of Guerilla Theater. It is the
collection of pragmatic insights snatched from painful contact with the burning

issues and ongoing problems of the day. Seldom is an Axiom of Systemantics
derived purely from abstract ratiocination or unpressured cerebration. More
often it has the hands-on immediacy of the Apprentice’s grubby handbook of
maxims, marked down with sweaty hands and stubby pencil in the heat of the
experience itself.
After Korzybski, a brilliant trio of founders established the real basis of the
field. Of these, the earliest was Stephen Potter[xvii], who, in the masterly work
entitledOne-Upmanship, painstakingly elaborated a variety of elegant methods
for bending recalcitrant Systems to the needs of personal advancement.
Although Potter’s goals were essentially utilitarian, lacking the broad generality
of Parkinson’s or Peter’s approach, he is rightly regarded as one of the pioneers
of Intervention into the operations of Systems.
Following Potter, C. Northcote Parkinson established an undying claim to
fame by prophesying, as early as 1957, the future emergence of the problem of
Table Shape in diplomatic conferences.[xviii]He was triumphantly vindicated in
the Paris Peace Talks of 1968, when an entire season was devoted to just this
topic before discussion of an end to the war in Vietnam could even begin. No
clearer demonstration of the Generalized Uncertainty Principle could have been
asked.[f.]
Third in the brilliant trio of founders is Doctor Laurence J. Peter, whose
Principle of Incompetence lies at the heart of Administrative Systemantics.
Having paid this well-deserved tribute, however, one still must recognize that
the infant science on whose foundations those giants were working (one must
mix metaphors now and then) was still limited.There was no organized set of
basic principles from which to operate. The foundations had been laid
erratically, a piece at a time, by individual workers of genius. Still needed was a
systematic exposition of the fundamental principles—the Axioms—upon which
all later superstructures could be built. The present work is humbly offered as a
first approach to that goal. It will have its shortcomings, of course. The
individual propositions will be argued, dissected, criticized. They will then be
either rejected as trivial, erroneous, or incomprehensible, or enshrined in the
literature as having stood the test of open debate and criticism. This is as the
author would wish it. In the pages that follow, we shall be principally concerned
with Systems that involve human beings, particularly with very large Systems
such as National Governments, Nations themselves, Religions, the Railway
System, the Postal Service, the University System, the Public School System,
etc., etc. But in our formulations of the laws of such Systems, we have striven
for the greatest possible degree of generality. If we are correct, our theorems

apply to the steamship itself as well as to the crew who run it and to the
company that built it.
Here, then, is the very first book of Systems-Axioms, the very first attempt to
deal with the cussedness of Systems in a fundamental, logical way, by getting at
the basic rules of their behavior.
19

Part One: Basic Theory
20

A. The Mysterious Ways of Systems
21

1. First Principles
We begin at the beginning, with the Fundamental Theorem:
NEW SYSTEMS MEAN NEW PROBLEMS
When a system is set up to accomplish some goal, a new entity has come into
being—the system itself. No matter what the “goal” of the system, it
immediately begins to exhibit systems-behavior, that is, to act according to the
general laws that govern the operation of all systems. Now the system itself has
to be dealt with. Whereas before there was only the Problem—such as warfare
between nations, or garbage collection—there is now an additional universe of
problems associated with the functioning or merely the presence of the new
system.
In the case of Garbage Collection, the original problem could be stated briefly
as “What do we do with all this garbage?” After setting up a garbage-collection
system, we find ourselves faced with a new Universe of Problems. These include
questions of collective bargaining with the garbage collectors’ union, rates and
hours, collection on very cold or rainy days, purchase and maintenance of
garbage trucks, millage and bond issues, voter apathy, regulations regarding
separation of garbage from trash, etc., etc.
Although each of these problems, considered individually, seems to be only a
specific technical difficulty having to do with setting up and operating a
garbage-collecting system, we intend to show that such problems are really
specific examples of the operation of general laws applicable to any system, not
just to garbage-collecting. For example, absenteeism, broken-down trucks, late
collections, and inadequate funds for operation are specific examples of the
general law thatLarge Systems Usually Operate in Failure Mode. Again, if the
collectors bargain for more and more restrictive definitions of garbage, refusing
to pick up twigs, trash, old lamps, etc., and even leaving behind properly
wrapped garbage if it is not placed within a regulation can, so that most
taxpayers revert to clandestine dumping along the highway, this exemplifies
thePrinciple of Le Chatelier (The System Tends To Oppose Its Own Proper
Function), a basic law of very general application. These and other basic laws of
Systems function are the subject of subsequent Chapters of this book.
In most towns of small-to-medium size, a garbage-collecting System qualifies
as a small-to-medium sized System, and Systems of such size often do
accomplish a measurable fraction of what they set out to do.Some garbage does
get collected. The original problem is thereby somewhat reduced in magnitude

and intensity. Over against this benefit, however, one must balance thenew
problemsfacing the community, the problems of administering, maintaining, and
otherwise adjusting to the Collection System. The sum total of problems facing
the community has not changed. They have merely changed their form and
relative importance. We require at this point adefinition:
ANERGY. ANERGY-STATE. Any state or condition of the Universe, or of
any portion of it, that requires the expenditure of human effort or ingenuity
to bring it into line with human desires, needs, or pleasures is defined as an
ANERGY-STATE. Anergy is measured in units of effort required to bring
about the desired change.
We are now in position to state a Theorem[a. ] of sweeping generality:
THE TOTAL AMOUNT OF ANERGY IN THE UNIVERSE IS CONSTANT
This Theorem is known, naturally, as the Law of Conservation of Anergy. We
offer without proof the following Corollary:
SYSTEMS OPERATE BY REDISTRIBUTING ANERGY INTO DIFFERENT
FORMS AND INTO ACCUMULATIONS OF DIFFERENT SIZES
One school of mathematically-oriented Systems-theoreticians holds that the
Law of Conservation of Anergy is only approximately true. According to them,
in very large Systems a Relativistic Shift occurs, whereby the total amount of
Anergy increases exponentially. In really large and ambitious Systems, the
original Problem may persist unchanged and at the same time a multitude of new
Problems may arise to fester (or ferment) unresolved. The Relativists point to
Garbage Collection in large metropolitan areas as an example. Not only does the
garbage not get collected, but also armies of striking workers must be fed and
clothed, the multitudes of the city must be immunized against diseases of filth,
the transportation Systems break down because cars and busses cannot get
around the mountains of refuse, and things in general quickly go to an extreme
degree of disrepair.
Granted that some of these effects would have been present to some degree
had there never been any garbage collection System at all, it is clear that they
aremuch worsebecause of the presence of the System.
23

2. Laws of Growth
Systems are like babies: once you get one, you have it.[a.] They don’t go
away. On the contrary, they display the most remarkable persistence. They not
only persist; they grow. And as they grow, they encroach. The growth potential
of Systems was explored in a tentative, preliminary way by Parkinson, who
concluded that Administrative Systems maintain an average rate of growth of
five to six percent per annum (corrected for inflation) regardless of the work to
be done. Parkinson was right so far as he goes, and we must give him full honors
for initiating the serious study of this important topic. But what Parkinson failed
to perceive, we now enunciate—the General Systems analogue of Parkinson’s
Law:
THE SYSTEM ITSELF (DAS SYSTEM AN UND FUER SICH) TENDS TO
GROW AT 5-6% PER ANNUM
Again, this Law is but a preliminary to the most general possible formulation,
the Big-Bang Theorem of Systems Cosmology:
SYSTEMS TEND TO EXPAND TO FILL THE KNOWN UNIVERSE
That this outcome does not occur in fact is due to the existence of various
inhibitory forces.[b.]
We have remarked that Systems not only Grow, they also Encroach. An entire
volume could be devoted to researches in this area alone. Examples of the
phenomenon of Encroachment can be found everywhere in our society. A blatant
example is the “do it yourself”movement, a maneuver invented by the managers
of the largest and most sophisticated System of mass production in the world
tomake the consumer do some of the work the system is supposed to do. The
consumer is encouraged to do the work of assembling the product he has bought
on the bizarre grounds that “it saves so much work and expense.” But if one
thinks a moment, one may recall that the System of mass production was set up
in the first place because such functions can be more cheaply and rapidly done
under factory conditions. The System simply prefers to encroach, that is, to
make someone else do the work.
Pushing the expenses off on the consumer goes back at least as far as
theancien regime in France, where the peasants were subjected to grinding
taxation to support the aristocracy, who were not taxed.[c.] The System of
Government, originating as a System for protecting the people, encroached upon
them until it became their worst oppressor. In the United States, the Internal
Revenue Service not only collect our taxes, they also make us compute the tax

for them, a task that produces a demonstrable shortening of both lifespan and
temper.
In a recent scholarly study,[xix] Mr. Russell Baker has drawn attention to the
development of the self-service gas station, the self-service supermarket, and the
self-service salad bar in restaurants, thus demonstrating that the phenomenon of
Encroachment has itself tended in recent years to encroach.[d. ] Mr. Baker
somewhat nostalgically recalls the era when: “You didn’t have to work for the
grocery industry; the grocery industry worked for you.” Painting a picture of
future developments that might well include self-service funerals, he comments,
“Industry’s discovery that the buyer could be made to do its work for it promises
to blight the lives of . . . generations to come . . .”
In accordance with the same principle, patients in hospitals are blamed for not
getting well or for reacting badly to medicine or surgery (“bad life-style”).
Motorists whose cars develop engine trouble are ticketed by the police or their
vehicles are towed away and crushed into scrap metal. Schoolboys who have
difficulty learning their lessons are punished by their teachers; conversely,
teachers may be punished if their students fail to learn.[e.] And the Telephone
Company, which once was happy to tell you the number of the person you
wanted to call, now charges you the price of a call to talk to the Information
Operator. Your listing in the Telephone Book has become a privilege for which
you pay. But if—exasperated by dinner-time calls from real-estate promoters
(who have bought your number from the Telephone Company)—you ask for an
unlisted number, you pay again to be removed from the Telephone Book. Truly,
SYSTEMS EXPAND, AND AS THEY EXPAND, THEY ENCROACH.

FIGURE 1. SYSTEMS TEND TO EXPAND TO FILL THE KNOWN
UNIVERSE
27

3. The Generalized Uncertainty
Principle
God moves in a mysterious way
His wonders to perform.
—William Cowper[xx]
The Primal Scenario enshrines the universal observation that Things Don’t
Work Very Well. For most people, it is enough to sigh and remark that Things
Were Ever Thus. However, to the serious Systems-student, a world of absorbing
interest lies beneath the superficial observation of things-as-they-are. The more
one delves beneath the surface—the more one becomes committed to close
observation and most importantly, to generalization from particular experience—
the more one begins to attain insight into the true and deeper meanings of things.
Such is the case with the Primal Scenario. Let us ask what lies beneath the
surface of that melancholy but universal observation. Just what is the
characteristic feature of Things Not Working Out?
To ask the question is to see the answer, almost immediately. It is the element
of Paradox, to which we have already alluded. Things not only don’t work out
well, they work out in strange, even paradoxical ways. Our plans not only go
awry, they produce results we never expected. Indeed, they often produce the
opposite result from the one intended.
•Insecticides, introduced to control disease and improve crop yields, turn up
in the fat pads of Auks in the Antipodes and in the eggs of Ospreys in the
Orkneys, resulting in incalculable ecologic damage. Meanwhile, the insects
develop immunity to insecticides, even learning to thrive on them.
•The Aswan Dam, built at enormous expense to improve the lot of the
Egyptian peasant, has caused the Nile to deposit its fertilizing sediment in
Lake Nasser, where it is unavailable. Egyptian fields must now be
artificially fertilized. Gigantic fertilizer plants have been built to meet the
new need. The plants require enormous amounts of electricity. The dam
must operate at capacity merely to supply the increased need for electricity
which was created by the building of the dam.
•Many backward nations, whose greatest need is food to feed their people,
sell their crops and bankrupt themselves to buy—not food, but advanced
military hardware for the purpose of defending themselves against their

equally backward neighbors, who are doing the same thing.
Now, so long as one is content merely to make the observation that a
particular System isn’t working well, or isn’t doing what was expected, one is
really only at the level of insight summarized in the Primal Scenario. The crucial
step forward in logic is a small one, but it is a giant step forward in Systemsthinking. There is a world of difference, psychologically speaking, between the
passive observation that Things Don’t Work Out Very Well and the active,
penetrating insight that:
COMPLEX SYSTEMS EXHIBIT UNEXPECTED BEHAVIOR
One is merely a pessimistic feeling; the other conveys the exhilaration that
accompanies recognition of a Law of Nature. Because of its fundamental
importance for all that follows, we have termed this Law the Generalized
Uncertainty Principle.
The Generalized Uncertainty Principle is constantly being rediscovered by
individuals encountering for the first time the full impact of the Primal Scenario.
One of the most recent and certainly most memorable of such reformulations has
been provided (inadvertently, we admit) by a Science Writer who, in the course
of an article on Computer Simulations, noted with exemplary directness:[xxi]
REALITY IS MORE COMPLEX THAN IT SEEMS
We agree completely. It is the theme of this book.
Incredibly enough, the first big breakthrough in recognition of the Generalized
Uncertainty Principle did not come until the 1950’s, when a daring—if
anonymous—group of biologists toppled Watsonian determinism with one short,
pithy aphorism, now known as the Harvard Law of Animal Behavior:
Under precisely controlled experimental conditions, a test animal will
behave as it damn well pleases.[a.]
The formulators of this Law failed to generalize to Systems as such, thereby
missing—by a whisker, so to speak—their chance for immortality:
Not just animal behavior, but the behavior of complex Systems generally,
whether living or non-living, is unpredictable.
It is fitting that this Law should have been foreshadowed, even in limited
form, by biologists, for they more than others are brought face to face in their
daily professional activities with the essential unpredictability of living things.
Mathematicians and engineers have considerably more difficulty with the G.U.P.
Accustomed as they are to creating Systems out of their own heads, they are
affronted that such Systems—their own creatures, so to speak—should exhibit
behavior that was unplanned and even undreamed of by themselves. Some even

go so far as to assert that the G.U.P. is “not logical.”
We sympathize with this point of view, or rather with the visceral reaction
underlying it. Most people would like to think of themselves as anticipating all
contingencies. But this is a yearning, not an accomplished fact. And to make
matters worse, once our pet System is translated into the real world of hardware
and people, it undergoes further largely unspecified changes. Mere humans can
never know all there is to know about the real world. And therein lies the
inevitability of the G.U.P.
This can perhaps be clarified by saying that, no matter what else it does, a
System will act like a System. We are accustomed to thinking that a System acts
like amachine,[b. ] and that if we only knew its mechanism, we could
understand, even predict, its behavior. This is wrong. The correct orientation is:
A MACHINE ACTS LIKE A SYSTEM
—and if the machine is large and complex enough, it will act like a large
System. We simply have our metaphors backwards. With this deep insight
tucked under our belt, or otherwise stashed, we can understand the philosophical
error that has plagued astronomers and cosmologists since the eighteenth
century:
THE UNIVERSE IS NOT LIKE A MACHINE
except in certain trivial ways. Rather:
THE UNIVERSE IS LIKE A VERY LARGE SYSTEM
The operation of the G.U.P. is perhaps most clearly displayed in the special
area of Climax Design; that is, in the construction of the largest and most
complex examples of manmade Systems, whether buildings, ships and planes, or
organizations. The ultimate model (the largest, fastest, tallest, etc.) often, if not
invariably, exhibits behavior so unexpected as to verge on the uncanny. The
behavior is often an unsuspectedway of failing, to which, on account of its
importance, we have devoted an entire Chapter.[c.]
Let us review only a few examples of Climax Design:
•The largest building in the world, the Space Vehicle Preparation Shedat
Cape Canaveral,generates its own weather, including clouds and
rain.Designed to protect space rockets from the elements, it pelts them with
storms of its own.[d. ][xxii]
•The Queen Elizabeth ll, greatest ocean liner ever built, has three separate
sets of boilers for safety, reliability, and speed. Yet on a recent cruise, in
fine weather and a calm sea, all three sets of boilersfailed simultaneously.
[xxiii]

•The largest telescope in the world, a 230-inch reflector, takes so long to
reach thermal equilibrium with the surrounding air that the night is over
before it can focus a star image.
We summarize these observations[e.] in the Non-additivity Theorem,
alternatively known as the Climax Design Theorem:
A LARGE SYSTEM, PRODUCED BY EXPANDING THE DIMENSIONS OF
A SMALLER SYSTEM, DOES NOT BEHAVE LIKE THE SMALLER
SYSTEM

31

4. A…B…C…Disaster (Feedback)
Every student of science is required, at some point or other in his/her career, to
learn Le Chatelier’s Principle. This Law states that any natural process, whether
physical or chemical, tends to set up conditions opposing the further operation of
the process. Although the Law has very broad application, it is usually looked
upon more as a curiosity than as a profound insight into the nature of the
universe. We, on the other hand, regard it as a cornerstone of General
Systemantics. No one who has had any experience of the operation of large
Systems can fail to appreciate its truth and relevance:
THE SYSTEM ALWAYS KICKS BACK
SYSTEMS GET IN THE WAY
—or, in slightly more elegant language:
SYSTEMS TEND TO OPPOSE THEIR OWN PROPER FUNCTIONS
In the field of human organizations, probably the outstanding example of Le
Chatelier’s Principle is in connection with the Goals and Objectives mania, itself
a specialized manifestation of an ancient and widespread phenomenon which we
shall designate as Administrative Encirclement.[a. ]
Let us take as an example the case of Lionel Trillium, a young Assistant
Professor in the Department of Botany at Hollyoak College. Although it is now
too late to do any good for poor Trillium, we shall review his case- history step
by step in the hope that similar tragedies may be averted in future. Trillium’s
Department Head, Baneberry, has for some years now failed to initiate new and
interesting hypotheses about the behavior of the Slime Molds, his chosen area of
specialization. Paralleling this decline of scientific productivity, he has exhibited
increasing interest in improving the “efficiency” of his Department. (The
medically-oriented reader will recognize in these symptoms the insidious onset
of intellectual menopause.)
Baneberry has actually gone to the extreme of checking out of the Library
some recent publications on Management Science. Before his jaded eyes a new
world has been revealed, and his mind is now buzzing with the terminology of
Information Retrieval Systems, Technology Assessment, Program Budgeting,
and, above all, Management by Goals and Objectives. He fires off a Memo to the
staff of his Department, requiring that they submit to him, in triplicate, by
Monday next, a statement of their Goals and Objectives.
This demand catches Trillium at a bad time. His studies of Angiosperms are at
a critical point. Nevertheless, he must take time out to consider his Goals and

Objectives, as the wording of the Memo leaves little doubt of the consequences
of failure to comply.
Now, Trillium really does have some personal goals of his own, that his study
of Botany can advance. In actual fact, he entered that field because of
unanswered questions[b. ] having to do with the origin of babies. His boyhood
curiosity was never satisfied, and it became fixed on the mechanics of
reproductive processes in living creatures. But to study reproduction directly, in
animals, creates too much anxiety. Therefore he has chosen the Flowering
Plants, whose blatant sexuality is safely isolated from our own. Trillium is happy
as a Botanist, and never so happy as when he is elucidating the Life Cycle of an
Angiosperm.
But now his Chief is demanding Goals and Objectives. This is both disturbing
and threatening. Trillium doesn’t want to think about his real goals and
objectives; indeed, they are unknown to his conscious mind. He only knows he
likes Botany.
But he can’t just reply in one line, “I like Botany and want to keep on studying
it.” No, indeed! What is expected is a good deal more formal, more organized,
than that. It should fill at least three typewritten sheets, single-spaced, and
should list Objectives and Sub-objectives in order of priority, each being
justified in relation to the Overall Goal and having appended a time-frame for
completion and some criteria for determining whether they have been achieved.
Ideally, each paragraph should contain at least one reference to DNA or the
phrase “double helix.” Trillium goes into a depression just thinking about it.
Furthermore, he cannot afford to state his true goals. He must at all costs
avoid giving the impression of an ineffective putterer or a dilettante. He must not
appear fuzzy-headed. His goals must be well-defined and crisply stated and must
appear to lead somewhere important. And he must appear to be active in areas
that tend to throw reflected glory on the Department. After all, one can’t expect a
University to maintain a Department just for people who have a faintly
scurrilous interest in how plants reproduce. Therefore, Trillium is forced to
include in his statement of Goals and Objectives all kinds of things that he’s
really not in the least interested in.
Poor Trillium struggles with all these considerations, which he does not
consciously formulate. He only feels them as a deep malaise and sense of
confusion that seizes him whenever he thinks about writing the Goals and
Objectives Statement. He puts it off as long as possible, but still it interferes with
his studies of Angiosperms. He can’t concentrate. Finally he gives up his
research, stays home three days, and writes the damned thing.

But now he is committed—in writing—to a Program, in terms of which his
“success” can be objectively assessed by his Chief. If he has stated that one
Objective for the coming year is to write three papers on Angiosperms and he
actually writes only two, he is only 67% “successful,” despite the fact that each
of the two papers may be a substantial contribution to the field. Or he may not
write any papers at all, devoting the time instead to a book for which the idea has
matured unexpectedly. In that case his “success” is zero. No matter that he has
overachieved in an unexpected area. If the Chief wants to get rid of him, he need
only point out his “failure.” And so Trillium has been led, step by step, down the
primrose path of logic, to disaster. The logic was devised by others, but that is no
consolation to him.
The next step is even more catastrophic. Since Trillium has clearly stated his
Goals and Objectives, it is now possible to deduce with rigorous logic how he
should spend his working and waking hours to achieve them. No more pottering
around pursuing spontaneous impulses and temporary enthusiasms! No more
happy hours in the Departmental greenhouse! Just as a straight line is the
shortest distance between two points, so an efficient worker will move from Subobjective A to Sub-objective B in logical pursuit of Objective K which leads in
turn toward the Overall Goal. Not only can Trillium be graded on
hisachievementsfor the year, he can also be separately graded on
theefficiencywith which he moves toward each of his objectives. He has become
Administratively Encircled. The Administrators, whose original purpose was to
keep track of office supplies for the professors, now have the upper hand and sit
in judgment on their former masters.
Only one step remains to be taken to complete Trillium’s shackling in the
chains he himself has helped to forge. On advice of the University
administrators, the legislators of his State establish by law the number of hours a
Professor of Botany must spend on each phase of his professional activities.
Trillium may feel impelled to protest, but how can he? The lawmakers are only
formalizing what he himself has told them he wants to do! The System of
Management by Goals and Objectives, designed to measure Trillium’s
performance as a botanist and to improve his efficiency, has kicked back, gotten
in the way, and opposed its own proper function.[xxiv] Once more the universal
validity of Le Chatelier’s Law has been demonstrated.
Baneberry, meanwhile, has been powerfully reinforced in his newfound
function as judge of other botanists. His own botanical career may be wilting,
but he has found a new careerin assessing the strengths and weaknesses of his
colleagues—especially their weaknesses. The heady experience of hobnobbing

with legislators and people of power in the “real” world gives him a new lease
on life and convinces him that Trillium really is just a poor putterer who will
never amount to anything. If only Botany could attractmen of actionlike the
lawgivers with whom he has been wining and dining![c. ]
34

5. The Power Of Positive Feedback: A
Warning
We have seen that the natural tendency of Systems is to set up negative
feedback to their own operations. That is to say, they oppose their own functions.
But what about positive feedback?
A great deal of nonsense is talked these days about positive feedback. When
the term is used merely as an inflated way of referring to praise given a person
for a job well done, no particular harm results. But positive feedback in
electronic systems leads to a loud squeal and loss of function. The entire energy
of the System suddenly goes down the drain, in a burst of useless or even
harmful noise. In Mechanics, the ill-fated Electra airplane was a victim of
positive feedback of energy from the propellors to the wings. In the world of
political events, no one can watch a huge political rally with its engineered
positive feedback without experiencing that same ominous sense of things
vibrating out of control. The wild career of Nazi Germany was largely the result
of uncontrolled positive feedback into a susceptible Governmental System.
No, students of Systemantics, Positive Feedback into a large System is a
dangerous thing. Remember, even though a System may function very poorly, it
can still tend to Expand to Fill the Known Universe, and Positive Feedback only
encourages that tendency.
Some radical humanists have suggested that people—ordinary human beings
—should receive positive feedback (i.e., praise) for theirhuman qualities, and
that negative feedback to individuals should be restricted to special
circumstances. In accordance with our basic axioms, such a policy would
causepeopleto tend to expand to fill the known universe, rather than shrinking to
fit the System. The result, it may fairly be speculated, would be revolutionary, if
not millennial. And since this is not a handbook for revolution, we cannot
officially endorse such a policy. But we can suggest informally: try it, you might
like it.
Oscillating Systems
Alternating positive and negative feedback[a. ] produces a special form of
stability represented by endless oscillation between two polar states or
conditions. In Human Systems, the phenomenon is perhaps best exemplified by
certain committees whose recommendations slowly oscillate between two polar
alternatives, usually over a period of some years. The period of the cycle has

been found, on close examination, to be just longer than the time required for the
advocates of Program “A” to graduate, retire, or otherwise leave the scene of
action, being replaced by a new generation whose tendency is (having been
exposed to the effects of Program “A”) to demand Program “B”. After some
months or years of Program “B”, a new generation of postulants is ripe to begin
agitations to restore Program “A”.
Thus, in academic affairs, Pass-Fail versus numerical or alphabetical grading
represent two polar positions. In most Universities, the Committee on Student
Academic Affairs slowly oscillates from the one to the other of these two
positions. The time period of this particular oscillation is just over four years,
thus qualifying such cycles as Medium-Period Variables.
Such cycles may be found everywhere, wherever Systems exist. In Fashion,
skirts go up and down, neckties become wider or thinner. In Politics, the mood
of the nation swings Left or Right. Sunspots advance or retreat. Economic
indicators rise or decline.
The pragmatic Systems-student neither exhorts nor deplores, but merely notes
thewaste of energyinvolved in pushing the wrong way against such trends.[b.]
35

6. What Next? (The Life Cycle Of
Systems)
Our little systems have their day.
—Alfred, Lord Tennyson[xxv]
We have seen that Systems Don’t Go Away, they Grow and Encroach, in a
process that can continue even when the System itself is in an advanced stage of
senile decay. Is there a pattern in that process? Is there a Life Cycle of Systems?
To that haunting and recurrent question, despite vigorous investigation, no
clear answer yet appears. Even Toynbee, floundering through his massive survey
of 20-odd civilizations, was finally able to discern only that:
SYSTEMS TEND TO MALFUNCTION CONSPICUOUSLY JUST AFTER
THEIR GREATEST TRIUMPH
Toynbee explains this effect by pointing out the strong tendency to apply a
previously-successful strategy to the new challenge:
THE ARMY IS NOW FULLY PREPARED TO FIGHT THE PREVIOUS WAR
For brevity, we shall in future refer to this Axiom as Fully Prepared for the
Past (F.P.F.P.)[a. ][xxvi]
We are speaking metaphorically, of course, in order to emphasize an abstract
general principle of Systems-operation. However, the list of armies that were
actually so prepared is impressively long.
In point of fact, the System may be so thoroughly organized around the
familiar response strategy that a new response would require extensive
restructuring—something that Systems do with the greatest reluctance and
difficulty. An example is the French Maginot Lineof underground fortresses with
long-range cannon aimed at Germany—the ultimate development of World-WarI-style trench warfare. In 1940, the Germans simplywent around it, leaving the
cannons pointed the wrong way. Only then did the defenders realize with awful
clarity that the cannonscouldn’t be turned around.[b.]
It was Parkinson who, with the delicious insight of the born historian, applied
this Principle to Architecture, pointing out that
PERFECTION OF PLANNING IS A SYMPTOM OF DECAY
and providing us with a dazzling succession of examples including the Palace
of Versailles (completed in time to receive the news of defeat at Blenheim), the
League of Nations Building (readied in time for Mussolini’s invasion of

Abyssinia) and the Pentagon (Korea, Vietnam). More recently, we note the
massive new home of the FBI, completed just in time to witness the disgrace of
both the Agency and its first Chief. One must withhold judgment on the New
Senate Office Building, at one hundred million dollars the most costly office
building in history, since it cannot be called complete.[c. ] Yet it has already
witnessed the Abscam scandals, Koreagate, and the Pageboy furore. For the sake
of America’s future, one might propose that at least a portion of the building be
left undone.
Finally, to bring our coverage of this topic right up to the present, we note that
the UN has responded to famine in sub-Saharan Africa by planning a
magnificent new Conference Center to accommodate UN personnel meeting to
discuss this problem.
The field of Architecture has given rise to a second major principle relating to
the Life Cycle of Systems. This principle has emerged from the observation that
temporary buildings erected to house Navy personnel in World War I continued
to see yeoman service in World War II as well as in subsequent ventures, and are
now a permanent, if fading, feature of Constitution Avenue in Washington, D.C.
The construction of the Pentagon, a few short miles away across the Potomac
River, never even threatened their tenure. We conclude:
A TEMPORARY PATCH WILL VERY LIKELY BE PERMANENT
Since Systems generally Don’t Go Away, and since they occupy space, our
landscape is now littered with the bleached bones and rotting carcasses of old
attempted solutions to our problems:
THE OLD SYSTEM IS NOW THE NEW PROBLEM
or, as even more poignantly formulated by Parkinson:
THE GHOST OF THE OLD SYSTEM CONTINUES TO HAUNT THE NEW
For our own part, we are partial to the Horrible Example represented by
Nuclear Power Plants, which, after a useful life of perhaps thirty to fifty years,
must then be sealed off and guarded for five hundred thousand years, give or
take a few millennia, while their radioactive poisons[d.] decay.

FIGURE 2. THE GHOST OF THE OLD SYSTEM CONTINUES TO
HAUNT THE NEW
38

B. Inside and Outside
39

7. The Grand Illusion
May God us keep
From simple vision and Newton’s sleep.
—William Blake[xxvii]
We move now to consideration of the Central Theorem of Systemantics, the
one indispensable principle that must be thoroughly understood by anyone who
wishes to be considered adept in the field. It is not an easy Theorem. It is subtle
and elusive, and true mastery of it requires real intellectual effort. In order to
make the progress of the neophyte a little smoother as he struggles upward over
thispons asinorumof Systems Theory, we approach the principle gradually and
piece-meal, beginning with a lesser but closely related Theorem.
Example:
There is a man in our neighborhood who is building a boat in his back yard.
He knows very little of boat-building and still less of sailing or navigation. He
works from plans drawn up by himself. Nevertheless, he is demonstrably
building a boat and can be called, in some real sense, a boat-builder.
Now if you go down to Hampton Roads or any other great shipyard and look
around for a ship-builder, you will be disappointed. You will find in abundance
welders, carpenters, foremen, engineers, and many other specialists, but no shipbuilders. True, the company executives may call themselves ship-builders, but if
you observe them at their work, you will see that it really consists of writing
contracts, planning budgets, and other administrative activities. Clearly, they are
not in any concrete sense building ships. In cold fact, a SYSTEM is building
ships, and the SYSTEM is the shipbuilder. In brief:
PEOPLE IN SYSTEMS DO NOT DO WHAT THE SYSTEM SAYS THEY
ARE DOING
This paradox was clearly recognized and described in detail by that
nineteenth-century team of empirical sociologists, Gilbert and Sullivan, when
they wrote:
I sailed that ship so well, you see,
That now I am the ruler of the Queen’s Navee.
The “ship” referred to, the reader will recall, was the Admiral’s
legalapprenticeship.
Unfortunately, Gilbert and Sullivan, like so many pioneers of the prescientific
era, failed to recognize the wider significance of the principle they had stumbled

upon. By this oversight, the entire field was held back at least forty years. In
general, the larger and more complex the System, the less the resemblance
between a particular function and the name it bears. For brevity, we shall refer to
this paradox as FUNCTIONARY’S FALSITY. Further examples are legion. The
following case-studies may serve as warming-up exercises for the reader, who is
urged to try out his or her own analytic skill:
1. What is the real-world function of a King?
Answer: In theory Kings are supposed to rule their country—that is, to
govern. In fact they spend much of their time and energy and their country’s
treasure fighting off usurpers. In democratic countries, a newly-elected President
may find it expedient to begin planning immediately for the next election.
2. What is the real-world function of a University Scholar?
Answer: University Scholarsare supposed to think and study deeply on basic
intellectual problems of their own choosing. In fact they must teach assigned
courses, do “research” on problems for which research money is available, and
publish, or perish.[xxviii]
With these Examples to light the way, the reader may now feel competent to
undertake the analysis of such common Systems-functions as Professional
Football Player (must include TV appearances), Minister of the Gospel (a taste
for White House Breakfasts is required), or University President (fund-raising,
riot control).
Having mastered Functionary’s Falsity, we are now prepared to encounter the
OPERATIONAL FALLACY in all its austere grandeur. Just as people in
Systems do not do what the System says they are doing, so also:
THE SYSTEM ITSELF DOES NOT DO WHAT IT SAYS IT IS DOING
In slightly greater detail: The function performed by a System is not
operationally identical to the function of the same name performed by a person.
In general, a function performed by a larger System is not operationally identical
to the function of the same name as performed by a smaller System. For
example, let us suppose that you, the reader, have a taste for a fresh apple. How
can this desire be satisfied?
(a) Minimal-systems approach: If you are lucky enough to live on a farm and
if the season is right, you can stroll out of your front door and down to the
orchard where you pick a dead-ripe, luscious specimen right off the tree.
(b) A small systemserving the function with the same name (supplying a fresh
apple) is the neighborhood grocery. Your grocer gets his apples in bushel baskets
from the commercial orchard twenty miles away. The apples are not quite as

fresh, and the very best of the lot have been selected out for sale to gift houses,
but you are still reasonably satisfied.
(c) A large systemserving the “same” function is the supermarket chain. The
apples are picked green and placed in “controlled atmosphere” storage where
they tend to ripen, although the ripening process is now by no means the same as
tree-ripening. The apples are then shipped by rail, spending days or weeks in
boxcars under variable conditions. In somecases, enzymes or exotic gases may
be used to complete the “ripening” process. Only a few varieties of apple can
survive this treatment.[a. ] The resulting product is still called a “fresh apple” but
in texture and flavor it bears little resemblance to (a) above.[b.]
Corollary:
THE FUNCTION (OR PRODUCT) IS DEFINED BY THE SYSTEMSOPERATIONS THAT OCCUR IN ITS PERFORMANCE OR
MANUFACTURE
The importance of Korzybski’s contribution to understanding Systems is now
apparent. An Apple that has been processed through the supermarket System is
not the same as an apple picked right off the tree, and we are in error to use the
same word for two different things.[c.]
Naturally (see Primal Scenario) most of the things we human beings desire are
non-systems things. We want a fresh apple picked right off the tree. But this is
precisely what a large System can never supply. The System has other goals and
other people in mind.
Apparent exceptions to the Operational Fallacy can be found in abundance.
Closer inspection, however, will almost invariably reveal the true state of affairs.
Example 1:
Doesn’t the Auto Industrysupply us with millions of new cars each year,even
tailoring them to our changing tastes in style and performance?[d.]
Answer:The reason we think the auto industry is meeting our needs is that we
have almost completely forgotten what we originally wanted, namely, a means of
going from one place to another that would be cheap, easy, convenient, safe, and
fast. We have been brainwashed into thinking that the Detroit product meets
these requirements:[e.]
IF DETROIT MAKES IT, IT MUST BE AN AUTOMOBILE
Obviously, if what we desire is what a System is actually producing, the
System will appear to be functioning as we wished.
Example 2:

Doesn’t the universal availability of cheap, fresh, enriched white bread
represent a great Systems-achievement in terms of nourishing the American
population?
Answer:The short answer is that it is not bread as that term is generally
understood throughout the world. The French country-dweller or the Egyptian
fellah, to name only two, would scarcely recognize the American product. To
qualify as Bread in most parts of the world a product would have to be baked
locally, from regionally grown whole grain flour, and sold still hot from the oven
—all features that have been sacrificed in the American product in order to
satisfy mass marketing requirements. As for enrichment, it seems a misnomer to
speak of enrichment when what is meant is the replacement of components lost
in earlier stages of manufacture. One draws a discreet veil of silence over other
attributes of the manufactured product such as the addition of non-nutritive
chemicals to retard spoilage, alter texture, etc., whose long-term effects are, to
speak charitably, conjectural.
The reader who has mastered Functionary’s Falsity and the Operational
Fallacy will be able to absorb without excitement and even to nod knowingly at
the latest examples of their effects as reported in the daily press and on
television. He or she will smile on being informed (as if it were something
unexpected) that Leadership Training Fails to Train Leaders.[xxix]S/he will
quickly grasp the truth that the Boy Scout Movement, designed to popularize
camping out in the wilderness, has actually popularized—Scouting. And finally
(that saddest example of the Operational Fallacy), he or she will understand the
meaning of the fact that every peace-keeping scheme ever devised has included
—as an essential component—an army.
The Naming Game:
In Zen, there is a saying, “If you meet the Buddha on the road, kill him!”
After the initial shock, one understands that someone who claims to have
achieved Buddha-hood obviously has not done so. The claim refutes itself. We
have already noted that a supermarket Apple is not like the Apple we had in
mind, that what comes out of a Coffee-vending machine is not Coffee as we
once knew it, and that a person who takes a course in Leadership Training is
acting out a behavioral pattern better described as Following rather than
Leading. We summarize in the Naming Fallacy:
THE NAME IS MOST EMPHATICALLY NOT THE THING
The Naming Fallacy is at the heart of the Grand Illusion and of the many forms
of Systems-Delusions.

Clearly it is easy to enter the world of Delusion through the open doorway of
Naming. Familiarity with this pathway to Error, and facility in recognizing the
Naming Fallacy, are skills that will serve us well in what is to come.
Naming and Framing
“Your president is not a crook,” asserted Mr. Nixon, thereby demonstrating the
existence of the Unconscious. Mr. Nixon’s performance also demonstrates for us
the process called Drawing a Distinction, whereby the universe is dichotomized.
[xxx] The very act of Naming (whether done aloud or under one’s breath, or
purely mentally) throws everything into a certain Frame of Reference—in this
case, having to do with possessing or lacking the quality of “Crookhood.” The
Crook System has sprung into being, and now everything is either part of that
system or of the counter-system, the Non-crook system. The two Systems, being
reflections of each other and unable to exist separately from each other,
constitute a Universe or Total System which can be called the Crook/Noncrook
System.[f.]
The power of the Naming Effect should not be underestimated. It is literally
the power to bring new “realities” into existence.[g.] Because of this power the
various wars on “crime,” “poverty,” “addiction,” and the like not only continue
in a state of chronic failure: they are doomed to be waged forever, so long as
they continue to be framed in those terms. They perpetuate that which they have
named.[h.][xxxi]
We are indebted to Mr. George Orwell for bringing home to us the real
functions of a Ministry of Truth or a Ministry of Peace or of Justice; but Orwell
was only updating an insight first enunciated by Lao-tzu at the dawn of written
history, when he wrote:
People, through finding something ‘beautiful,’ think something else
‘unbeautiful’[xxxii]
Hard experience has taught us the meaning of Orwellian Ministries of this and
that; but the delicate nuance of Lao-Tzu still escapes us, until we realize that the
thing called Education is not really education, just as the supermarket Apple is
not the apple we once knew and loved. In that moment we escape from the
Naming Delusion.
We become free to encounter and to study Systems with our eyes open.
43

8. Inside Systems
Our study of the Operational Fallacy has made clear how and why it is that (1)
large Systems really do not do what they purport to do and that (2) people in
large Systems are not actually performing the function ascribed to them. These
two facts quite naturally lend an air of unreality to the entire operation of a large
System. In the present Chapter we propose to explore in more detail some of the
effects of that unreal atmosphere, especially its effects upon the people in the
System. But first, following our rule of placing the most fundamental Axioms at
the beginning, we present the Fundamental Law of Administrative Workings
(F.L.A.W.):
THINGS ARE WHAT THEY ARE REPORTED TO BE
The observant reader has doubtless already noted various alternative
formulations of this Axiom, all to the same general effect, for example:
THE REAL WORLD IS WHAT IS REPORTED TO THE SYSTEM
—or, in the world of Diplomacy:
IF IT ISN’T OFFICIAL, IT HASN’T HAPPENED
Amongst television journalists this Axiom takes the following form:
IF IT DIDN’T HAPPEN ON CAMERA, IT DIDN’T HAPPEN
Mind-boggling as it may seem, theconverse proposition is also true.For
example, on March 6, 1985, the Canadian National Television News reported
that Mr. Paul Nitze of the United States had met with Prime Minister Mulroney
and afterwards had expressed his satisfaction with their conversation.[xxxiii] In
point of fact, this reporthad been released by the American State Department
before the meeting actually occurred. We therefore add the Related Theorem:
IF THE SYSTEM SAYS IT HAPPENED, IT HAPPENED
The F.L.A.W., which is fundamental to Communication Theory as well as to
Epistemology, may have been foreshadowed by McLuhan[a.], although he seems
to have gotten it backwards. Correctly stated: the Message is the Medium by
which the System knows the World. The net effect of this Law is to ensure that
people in Systems are never dealing with the real world that the rest of us have
to live in, but instead with a filtered, distorted, and censored version which is all
that can get past the sensory organs of the System itself.
Corollary #1:
A SYSTEM IS NO BETTER THAN ITS SENSORY ORGANS

This Corollary, the validity of which is crystal clear to you and me, is viewed
with perplexity by the personnel living within the System. For them, the real
world is what their Intake says it is, and any other world is simply a wild
hypothesis. A true Systems-person can no more imagine inadequacy of sensory
function than a Flatlander can imagine three- dimensional space.
Corollary #2:
TO THOSE WITHIN A SYSTEM, THE OUTSIDE REALITY TENDS TO
PALE AND DISAPPEAR
This effect has been studied in detail by a small group of dedicated General
Systemanticists. In an effort to introduce quantitative methodology into this
important area of research they have paid particular attention to the amount of
information that reaches, or fails to reach, the attention of the relevant
administrative officer or corresponding Control Unit.
The crucial variable, they have found, is the fraction
Ro/Rs,
where Ro equals the amount of Reality which fails to reach the Control Unit,
and Rs equals the total amount of Reality presented to the System.
The fraction Ro/Rs varies from zero (full awareness of outside reality) to unity
(no reality getting through). It is known, naturally enough, as the
COEFFICIENT OF FICTION.
Positive Feedback (P.F.) obviously competes with Reality (R) for input into
the System. The higher the P.F., the larger the quantity of Reality which fails to
gain entrance into the System (Ro) and thus the higher the C.F.
In large Systems employing P.F., values of C.F. in excess of 0.99 have been
recorded.[b.] Examples include evangelistic religious movements, certain
authoritarian governmental systems, and the executive suites of some large
corporations[c].[xxxiv] A high C.F. has particular implications for the
relationship between the System and an Individual Person (represented by the
lower-case letter i[d].)
We state the relationship as follows in
Corollary #3:
THE BIGGER THE SYSTEM, THE NARROWER AND MORE
SPECIALIZED THE INTERFACE WITH INDIVIDUALS
In very large Systems, the relationship is never with the individual at all, but
with his Social Security number, his driver’s license, or some other paper
phantom derived from an extremely specialized aspect of the person. In Systems

of medium size, some residual awareness of the individual may still exist. A
hopeful indication was recently observed by the author in a medium-sized
Hospital. Taped to the wall of the nurses’ station, just above the Vital Signs
Remote Sensing Console that enables the nurses to record whether the patient is
breathing and even to take his pulse without actually going down the hall to see
him, was the following hand-lettered reminder:
THE CHART IS NOT THE PATIENT
Unfortunately, this slogan, with its humanistic implications, turned out to be
misleading. The nurses were neither attending the patients normaking notations
in the charts. They were in the hospital auditorium, taking a course in
Interdisciplinary Function.[e.]
The gradual fading-out of the individual as systems grow larger has been
further confirmed by developments in the System of Peer Review, with its
emphasis upon improvements in charting. The watchword seems to be:
A SANE MIND, A SOUND BODY, AND A HEALTHY CHART
—not necessarily in that order.
Government Agencies, on the other hand, qualify as components of truly large
Systems. Nowhere on the wall of any such agency has the author seen a notation
to the effect that:
THE DOSSIER IS NOT THE PERSON
—nor does he expect ever to see such a notation.
At this point we must offer our emendation of the work of Dr. Laurence J.
Peter, who rightly pointed out that people within the System rise to their Level of
Incompetence, with results everywhere visible. But it must be clear that the
strange behavior of people in Systems is not solely nor even primarily the result
of mere incompetence, any more than it is mere “criminality” that makes people
commit crimes. Would that the solution were so simple! Competence or lack of
it has little if anything to do with the larger-scale manifestations of Systemsfunction. A large role must be ascribed to the F .L.A.W., which isolates the
Systems-person from the everyday world. As we all know, sensory deprivation
tends to produce hallucinations. Similarly, immersion in a System tends to
produce an altered mental state that results in various bizarre malfunctions,
recognizable to us but not to the persons so immersed. We therefore pause for a
Definition:
FUNCTIONARY’S FAULT: A complex set of malfunctions induced in a
Systems-person by immersion in the System, and primarily attributable to
sensory deprivation (that is to say, to lack of alternative, or contrasting,

experiences).
Several subtypes of FUNCTIONARY’S FAULT are known. Only twowill be
mentioned here. We leave to others the tilling of this field.[f.]
1. Functionary’s Pride:
This disorder was already ancient when it was definitively characterized by W.
Shakespeare as “the insolence of office.” A kind ofmania of self-esteeminduced
by titles and the illusion of power, it is so well-known as to need no elaboration.
However, this treatise claims distinction as the first to attribute the syndrome, not
to inherent vice nor to maladministration, but to the operation of the F .L.A. W.
in the System itself upon the office- holder.
2. Hireling’s Hypnosis:
A trance-like state, a suspension of normal mental activity, induced by
membership within a System. May strike at any time, afflicting anyone from
chief officer to night watchman, and quite capable of jumping large distances to
infect innocent bystanders.
Example 1:
A large private medical clinic installed a computerized billing system. One
day the computerprinted out a bill for exactly $111.11 for every one of the more
than 50,000 persons who had ever attended the clinic. During the next several
days the clinic switchboard was jammed with calls from irate recipients of the
erroneous bills. Emergency calls could not get through. Ten thousand former
clients took their business elsewhere, for a total loss to the clinic of almost a
million dollars. The person operating the computer on that day, as well as the
office clerk, the programmer, and twelve employees working in the same room
on stuffing, sealing, and stamping the envelopes—all had observed the striking
identity of numbers on the statements but had done nothing to stop the error.The
System had hypnotized them.
Forty years later, in an age of sophisticated computers and equally
sophisticated software, the decimal point was dropped from the hotel bills of
some 26,000 patrons of three nationwide hotel chains, inflating their charges one
hundred fold. By way of compensation, the overcharged patrons were offered
two free nights at any hotel operated by the three chains, at an unspecified cost
to the owners.[xxxv]
Example 2:
The President of a neighborhood Bank located in a modest shopping center in
Oklahoma City, vulnerable to the speculative ambience of the Oil Fields, was
led, step by step, to underwrite ever more ambitious ventures until finally, in a

climax of trust, he issued an unsecured line of credit to a single customer for the
sum of one hundred million dollars. But the true power of Hireling’s
Hypnosiswas demonstrated when the bank president was then able to persuade
several of the largest banks in the country toactually lend the money. Having
achieved a level of unreality rarely reached even in governmental circles, the
little bank was then able to repeat the process with increasing confidence and
grandiosity before finally sinking into bankruptcy and taking the banking giants
with it.[g. ][xxxvi]
Example 3:
At 2 AM on Sunday, October 27, 1985, Amtrak trains all over the United
States ground to a halt and remained motionless for a solid hour.
Bewildered passengers were informed that the nation was switching back to
Standard Time from Daylight Saving Time, and the trains werewaiting for the
clock to catch up.[xxxvii]

FIGURE 3. THE OPERATIONAL FALLACY: SYSTEMS “FLYING” IS
NOT “FLYING.”
49

9. Delusion Systems Versus Systems
Delusions
“I’m going to fly to New York this afternoon,” you say. But what you really
do, after driving an hour to get to the airport, is to strap yourself into a coffinlike tube of sheet metal and remain almost immobile, except for being passively
shaken about, for a period of some hours. You are not flying in any real sense. At
best the airplane could be said to be flying, though certainly not in the sense that
birds fly.
Why do we not say you are laboring under a delusion? The answer is: because
we share your set of beliefs. We are in yourdelusion system, and we are both
victims of aSystems-delusion.
Systems-delusions are the delusion systems that are almost universal in our
modern world. Wherever a System is, there also is a Systems-delusion, the
inevitable result of the Operational Fallacy and the F.L.A. W. in Systems.
Continuing our theme of Air Travel, we note that in the Jet Age one flies, not
to the great world-metropolises, but to small villages 20, 40, or even 60 miles
away from them. Air travelers arrive at places like Chantilly, Romulus,
Viracopos, Grapevine, Rosemont, or Orly, believing themselves to be in
Washington, D.C., Paris, Dallas, Sao Paulo, Detroit, or Chicago.[a. ] They may
indeed be arriving quite literally nowhere (as far as named habitations are
concerned), but that is of little consequence, as the airport complex itself may be
larger and more populous than many a proud town. These observations lead
naturally to enunciation of the Jet Travel Paradox:[b.]
WHEN YOU GET THERE, YOU’RE STILL NOT THERE
—an observation whose validity is of course not limited to large
Transportation Systems. In the field of Nuclear Energy, for example, one may
note that when a large reactor is “shut down,” it continues to generate enormous
amounts of heat from secondary radiation (200 million watts for a good-sized
plant).[xxxviii] The coolant liquid must continue to circulate for several weeks
or disaster will ensue. The “reactor” System may in some sense have been shut
down, but the power plant as a whole can not be shut down without the threat of
a meltdown.[c. ]
Systems-delusions of practical importance include the following:
1. Manager’s Mirage.
The belief that some event (usually called an “outcome”) was actually caused

by the operation of the System. Examples:
•The Public School System is obviously responsible for the literary works
of Faulkner, Hemingway, and Arthur Miller, since ittaught them to write.
•Similarly, the NIH is clearly responsible for (and has actually claimed
credit for) the major biomedical advances of the past generation, since
itfunded the research.
We generalize:
THE SYSTEM TAKES THE CREDIT (FOR ANY FAVORABLE
EVENTUALITY)
1. (a). Manager’s Mania:
The preceding Delusion, if unchallenged, rapidly escalates into an even more
grandiose conviction, as exemplified in the dictum:
“What’s Good For General Motors Is Good For The Country.”
Such propositions may be momentarily accurate, but they cannot
begenerallycorrect in any logical or scientific sense. One need only make a
quick mental substitution such as:
“What’s Good For Enron is Good For The Country.”
in order to experience the impact of the logical error involved. Only one
proposition of this form isnecessarilytrue. With modest pride we state it as
follows:
WHAT’S GOOD FOR GENERAL SYSTEMANTICS IS GOOD FOR THE
COUNTRY
2. Orwell’s Inversion.
Closely related to the Orwellian Newspeak and Doublethink. The confusion of
Input and Output.
A giant program to Conquer Canceris begun. At the end of five years, cancer
has not been conquered,[xxxix] but one thousand research papers have been
published. In addition, one million copies of a pamphlet entitled “You and the
War Against Cancer” have been distributed. Those publications will absolutely
be regarded as Output rather than Input. The cancerous multiplication of
paperwork willnotbe regarded as a malignancy.
Beyond Systemism
The shift from Systemism to Systemantics is not an easy one. The person
immersed in a System does not recognize that fact. It is like the situation of the
goldfish in the goldfish bowl: the fish does not recognize that it is swimming in
water and that there is an ocean of something called air beyond that world. The

Systems-person does not consider himself or herself to be such. Escaping from
involvement in a System is like passing over an invisible threshold; one does not
know there is a threshold and one does not know that there is another universe
on the other side until the transition takes place. Then there is the moment of
shock as one Frame of Reference[d. ] collapses and another is installed. After
that everything is quite clear again.
The reader is invited to ask him-or herself, Is it possible that I am seeing the
world from inside a System? Am I, unbeknownst to myself, a Systems-person?
The answer is always, Yes. The relevant question is, simply, Which System?
At that moment one can graduate from being only a Systems-person to
becoming a true Student of Systemantics.
51

10. Systems-People
The preceding considerations have provided convincing evidence that the
System has its effects on the people within it. It isolates them, feeds them a
distorted and partial version of the outside world, and gives them the illusion of
power and effectiveness.[xl]But Systems and people are related in another,
subtler way. Aselective processgoes on, whereby Systems attract and keep those
people whose attributes are such as to adapt them to life in that System:
SYSTEMS ATTRACT SYSTEMS-PEOPLE
Systems-people everywhere share certain attributes, but each specific System
tends to attract people with specific sets of traits. For example, people who are
attracted to auto-racing are likely to be those who enjoy tinkering with highpowered cars, driving fast, and beating other people in fierce competition. The
System calls forth those attributes in its members and rewards the extreme
degrees of them.
However, the particular attributes that a given System fosters can only rarely
be correctly inferred in advance; the actual situation is likely to contain
surprises. And such attributes are not necessarily the attributes required for
successful operation of the System itself; e.g., the qualities necessary for being
elected President are not the qualities needed for properly running the country.
Systems attract not only Systems-people who have qualities making for
success within the System; they also attract individuals who possess specialized
traits adapted to allow them to thrive at the expense of the System; i.e., persons
who parasitizethe System. As the barnacle attaches to the whale, those persons
attach themselves to Systems, getting a free ride and a free lunch as long as the
System survives. But the hidden affinities between the System and the Systemspeople attracted to it extend even further: there is a strange, even paradoxical
effect whereby, for example, the person celebrated as Man or Woman of the Year
or as the town’s Outstanding Citizen has a high probability of making headlines
again within a year or two as a bigamist or impostor, or for some other form of
flamboyantly sociopathic behavior. A religious leader in exile is welcomed home
again, only to reveal a taste for homicide. A motorcyclist arrested on the freeway
for speeding in excess of one hundred miles an hour turns out to be a wellknown psychiatrist, hastening to teach his class on “Inner Peace.”
Efforts to remove parasitic Systems-people by means of screening
committees, competency examinations, or review boards merely generate new
job slots for them to occupy. Successful attempts to control this a problem are

rare.[a. ] We have discovered, to date, only three solutions:
•The ancient Egyptians, with their deep insight into human organizations,
had the courage to provide a radical remedy: a dual bureaucracy in which
each job was represented twice—once by the honorary office-holder, once
by the actual executive.
•The Chinese met the challenge by selecting their high officials only from
those who had passed a stringent examination inancient Chinese Classics.
•The British Empire limited high office to the sons of aristocrats, then made
those jobs so boring, so ill-paid, and so tedious, that no one of flashy
temperament would apply.
Specialized Selection:
When Parkinson noted that people who respond to ads for highly specialized
jobs tend to be off their head, he was re-stating a principle that, in the world of
living creatures, has been recognized at least since the time of Darwin. It is that
of Specialized Selection. A relatively undifferentiated organism, subjected to
such influences for a long enough time, can grow a third eye, learn to fly at night
by sonar, or survive droughts by burrowing in the mud at the bottom of the river
and holding its breath.
SPECIALIZED SYSTEMS SELECT FOR SPECIALIZATION
—or, in plain English:
THE END RESULT OF EXTREME COMPETITION IS BIZARRENESS
A second consequence of such conditions is a peculiar quality of endurance, a
special ability to survive under the conditions of the competition. Paradoxically,
when the trial is finally over and the competitive conditions are relaxed, the
“successful” contenders may exhibit a sudden loss of control or of adaptability.
The cessation of the actual struggle apparently may produce in the survivors a
sudden disorientation, a loss of customary frame of reference, that has the
quality of an hallucinatory response. Presidential candidates, for example, after
winning election to the Presidency, may continue to act as if they were still
struggling to get elected.
Often enough, in real life the conditions of competition never do come to an
end. Under such conditions, the quality finally selected for is the brute ability to
survive:
PROLONGED SELECTION SELECTS SURVIVORS
Classic examples are provided by the grizzled bureaucrats of both East and
West, whose personalities seem indeed to consist of an almost pure culture of

survival instincts, with little else to provide variety or comic relief.
Rohe’s Theorem:
This marvelous Theorem, grasped in a once-in-a-lifetime flash of intuition by
Tom Rohe of Bremerton, Washington[xli], will serve as our introduction to the
grim topic of Systems-exploitation:
DESIGNERS OF SYSTEMS TEND TO DESIGN WAYS FOR THEMSELVES
TO BYPASS THE SYSTEM
We pause only briefly to validate it with a well-known example from
Government:
Example:The Congress of the United States specifically exempts itself from
the Civil Rights Act, the Equal Pay Act, the Fair Labor Standards Act, the
National Labor Relations Act, the Occupational Safety and Health Act, the
Freedom of Information Act, and the Privacy Act.[xlii]
At a slightly less exalted level, we note that even so altruistic a person as
Alex. G. Bell, having invented the telephone, rather promptly retired to a lonely
Atlantic island where no one could ring him up.[b.]
Having thoroughly digested this introduction, we should have notrouble
understanding that:
IF A SYSTEM CAN BE EXPLOITED, IT WILL BE
Nor will we cavil at its twin:
ANY SYSTEM CAN BE EXPLOITED
The Exploitation Theorems are given visceral immediacy by the following
case history, culled from the files of the British Medical Journal:
Stewart McIlroy is presumed dead now, as he has not been heard from for
more than a year. Before he disappeared, he had in 34 years achieved a
grand total of at least 207 and possibly as many as 217 admissions to 68 (or
more) British hospitals, residing in them for a cumulative span of ten years
and costing the British public, through the National Health Service, close to
ten million pounds sterling. It appears that despite his flamboyant
symptoms, Mcilroy was essentially healthy—healthy enough to depart with
great speed and agility when discovery impended. Indeed, it seems certain
that he did not have any of the serious diseases for which he was so
expensively tested.[xliii]
What was the rare and specialized quality so abundantly displayed by
McIlroy? It was the ability, through an appearance of illness, to achieve
admission to National Health Service Hospitals—that is, to exploit the Health

Care System.
Computers and Exploitation:
Are computers immune to exploitation? The short answer is: no more than any
other large System. The proliferation of such exploitation techniques is reflected
in the richness of the jargon used to designate them.
Recent experience suggests that for unknown reasons, computers are
peculiarly vulnerable to infiltration by teenagers. Do computers and teenagers
think alike?
We will not pursue this awful suspicion further in this place.[c.]
54

C. Function and Failure
55

11. Elementary Systems-Functions
“I never ruled Russia. Ten thousand clerks ruled Russia.” Thus spoke the Czar
Alexanderon his deathbed. Was he right? Of course he was! And at what a price
he purchased that deep and depressing insight!Therewas a System designed, if
any System ever was, to be a tool in the hands of one man, to permit that one
man to carry into effect his slightest whim. And what happened? The System
would not work. Worse yet, Alexander, with all his absolute authority, was
unable to make it work.[a.]
If Czar Alexander had been inclined to philosophical reflection, he would
doubtless have meditated upon the functional vagaries of Systems— their
propensity for failing to work when most needed and for working when one
could really do without them. He might even have attained insight into the Basic
Axiom of Systems-function, the one from which all the others are ultimately
derived:
BIG SYSTEMS EITHER WORK ON THEIR OWN OR THEY DON’T. IF
THEY DON’T, YOU CAN’T MAKE THEM
In this regard, scrutiny of various Telephone Systems is informative. The
American Bell Telephone System is—or was[b.]—manifestly a Working System.
The Egyptian Telephone System, by contrast, does not work, and diligent efforts
tomake it workhave had little success. The Russian telephone system, on the
other hand, works very well, butnot for the consumer.[c.]
Ignorance of the Basic Axiom is responsible for the most widespread and
futile of all administrative errors—pushing harder on the nonfunctioning System
to make it work better (Administrator’s Anxiety):
PUSHING ON THE SYSTEM DOESN’T HELP
You might as well try to bring the elevator up to your floor by pulling on the
indicator lever or pounding the call button. In fact, as we shall show in another
place:
EVEN TRYING TO BE HELPFUL IS A DELICATE AND DANGEROUS
UNDERTAKING
We do not deny that occasionally the parts of the nonfunctioning System may
be so disposed that a good swift kick will cause them to fall into place, so that
the System can resume functioning. Ordinarily, however, such a maneuver
merely produces one last spasmodic effort, after which the System subsides into
total immobility.[d.] Even today, the futility of Pushing On The System is widely

unappreciated. Ignorance can hardly be invoked as an excuse, as cautionary
examples abound. Denial, that powerful psychological process by which we
simplynegateany part of Reality that gets in the way of our plans, is probably
responsible. Yet here and there, in piecemeal fashion, the awareness recurs. In
the realm of Computer Technology, for example, where lapses from reality are
rather promptly visited with consequences, grizzled veterans of the Software
Wars have enshrined this insight in a paradoxical Law[xliv] based, not on
contemplation, but on actual measurement:
ADDING MANPOWER TO A LATE SOFTWARE PROJECT MAKES IT
LATER
By way of concrete confirmation, we note the recent experience of the New
York Police Force, where a mandated reduction in the total number of active
police officers actually resulted in an increase in total personnel.
With this by way of introduction, let us proceed to a more detailed analysis of
Systems Function, Malfunction, and Non-function. First off:
A SIMPLE SYSTEM MAY OR MAY NOT WORK
Simple Systems that work are rare and precious additions to the
armamentarium of human technology. They should be treasured. Unfortunately
they often possess attributes ofinstabilityrequiring special skill in their operation
—for example, the common fishing pole with line and hook; the butterfly net;
skis; the safety razor; and (in Western hands) the boomerang.[e. ]But simple
Systems possessing the required attribute of stability do exist: the foot-rule, the
plumb bob, the button and buttonhole System, to name a few. Among simple
Systems involving human associations, thefamilyoccupies a special place.[f. ]
Although many of the world’s frustrations are rooted in the malfunctions of
complex Systems, it is important to remember that
SOME COMPLEX SYSTEMS ACTUALLY FUNCTION
This statement is not an Axiom. It is an observation of a natural phenomenon.
The obverse of the Primal Scenario, it is not a Truism, nor is there anything in
modern philosophy that requires it to be true. We accept it here as a given, for
which we offer humble thanks. The correct attitude of thankfulness leads
naturally to the following Rule of Thumb:
IF A SYSTEM IS WORKING, LEAVE IT ALONE. DON’T CHANGE
ANYTHING
But how does it come about, step by step, that some complex Systems actually
function? This question, to which we as students of General Systemantics attach
the highest importance, has not yet yielded to intensive modern methods of

investigation and analysis. As of this writing, only a limited and partial
breakthrough can be reported, as follows:
A COMPLEX SYSTEM THAT WORKS IS INVARIABLY FOUND TO HAVE
EVOLVED FROM A SIMPLE SYSTEM THAT WORKED
The parallel proposition also appears to be true:[g. ]
A COMPLEX SYSTEM DESIGNED FROM SCRATCH NEVER WORKS
AND CANNOT BE MADE TO WORK. YOU HAVE TO START OVER,
BEGINNING WITH A WORKING SIMPLE SYSTEM
Diligent search for exceptions to these Axioms has yielded negative results.
The League of Nations?No. The United Nations? Hardly. Nevertheless, the
conviction persists among some that a working complex System will be found
somewhere to have been establishedde novo, from scratch. Our friends the
mathematicians and engineers, in particular, may insist that these formulations
are too sweeping; that they set forth as Natural Law what is merely the result of
certaintechnical difficulties, which they propose to overcome in the near future.
[h. ]
Without committing ourselves too strongly to either camp, we will remark that
the mechanism by which the transition fromworking simple Systemtoworking
complex Systemtakes place is not known. Few areas offer greater potential
reward for truly first-rate research.

FIGURE 4. FUNCTIONING LARGE SYSTEMS ARE BORN OF
FUNCTIONING SMALL SYSTEMS
60

12. Advanced Systems-Functions
“Lead me away. . .for all is amiss with that which is in my hands.
. .”
—Sophocles[xlv]
In the preceding Chapter we introduced certain elementary principles relating
to the function or non-function of Systems. We move now to more advanced
concepts, some of which require close attention if they are to be mastered. The
student will remember that our goal is two-fold: first, to present the subject
matter with rigorous logical correctness, moving sequentially from simple to
more advanced ideas; and second, to provide a groundwork for practical mastery
of the subject, so that the attentive student may deal with Systems with the
strength that comes from understanding. Why flounder in unequal struggle when
you can know in advance that your efforts will be unavailing? Nothing is more
useless than struggling against a Law of Nature. On the other hand, there are
circumstances (highly unusual and narrowly defined, of course) when one’s
knowledge of Systems-functions will provide precisely the measure of extra
added ability needed to tip the scales of a doubtful operation in one’s favor.
Those rare moments are, to the serious Systems-student, the reward that makes
worthwhile the entire long period of disciplined study and self-denial involved in
mastery of this complex subject.
In accord with our practice of moving from the simpler concepts to those
which are more profound and impalpable, we present the following Functional
Indeterminacy Theorem (F.I.T.):
IN COMPLEX SYSTEMS, MALFUNCTION AND EVEN TOTAL NONFUNCTION MAY NOT BE DETECTABLE FOR LONG PERIODS, IF EVER
When first propounded, this Theorem often elicits surprise. However,
illustrative examples abound, especially from the field of History. For example,
it would seem reasonable to suppose that absolute monarchies, oriental
despotisms, and other governmentsin which all power is concentrated in the will
of one person would require—as a minimum for the adequate functioning of
those governments—that the will of the despot be intact. Nevertheless, the list of
absolute monarchs who were hopelessly incompetent, even insane, is
surprisingly long. They ruled with utter caprice, not to say whimsicality, for
decades on end, and the net result to their countries was—undetectably different
from the rule of the wisest kings.[a. ]
On the other hand, in strict accordance with the Generalized Uncertainty

Principle, the greatest and wisest Kings have made decisions that proved
disastrous. Charlemagne, for example, in his desire to be fair to his three sons,
divided his empire among them—an act that gave rise to France, Germany, and
Alsace-Lorraine, and to more than a thousand years of strife.
For readers who prefer more contemporary examples we shall let the single
term “Enron” stand for an entire nexus (or plexus) of interlocking corporations
whose enigmatic logos and blandly soaring home office buildings reveal as well
as hide the utter emptiness within.
The problem of evaluating “success” or “failure” as applied to large Systems
is compounded by the difficulty of finding proper criteria for such evaluation.
What is the System really supposed to be doing? Was the Feudal System, for
example, a “success” or a “failure”? Shall it be called a “success” because it
achieved the physical survival of Western Civilization, or shall it be called a
“failure” because in place of the internationalism of Rome it bequeathed us the
doubtful legacy of nationalism and a divided Europe? Some thinkers,
overwhelmed by the difficulties of answering such questions, have taken refuge
in a Theorem of doubtful validity, which is presented here for completeness’
sake, without any commitment as to its ultimate correctness:
LARGE COMPLEX SYSTEMS ARE BEYOND HUMAN CAPACITY TO
EVALUATE
How much complexity is too much for humans to handle? Since little relevant
research has been done on this important question, we shall again resort to our
basic method of Illustrative Anecdote:
•In testimony before Congress in April, 1983, an Air Force General, the
Commander-in-Chief of the Strategic Air Command, was surprised to learn
that submarines actually travel under water.[xlvi]
•When President John F. Kennedy took office, he promptly discovered that
the Red Telephone, his Nuclear-attack-warning Hotline, was missing.
Diligent search of the Oval Office failed to turn it up.[xlvii] [b]
As these examples suggest, it is probably wise to err on the side of simplicity.
Practically speaking, any System with more than two elements should probably
be regarded as complex, at least for purposes of human interaction.[c.] For our
own part, we shall be content to quote the words of one of the wisest of the
Systems-thinkers, as follows:
In general, we can say that the larger the System becomes, the more the
parts interact, the more difficult it is to understand environmental
constraints, the more obscure becomes the problem of what resources

should be made available, and deepest of all, the more difficult becomes the
problem of the legitimate values of the System.[xlviii]
But, however difficult it may be to know what a System is doing, or even
whether it is doing anything at all, we can still be sure of the validity of the
Newtonian Law of Inertia as applied to Systems:
A SYSTEM THAT PERFORMS A CERTAIN FUNCTION OR THAT
OPERATES IN A CERTAIN WAY WILL CONTINUE TO OPERATE IN THAT
WAY REGARDLESS OF THE NEED OR OF CHANGED CONDITIONS
Less technically stated:
WHATEVER THE SYSTEM HAS DONE BEFORE, YOU CAN BE SURE IT
WILL DO IT AGAIN
Or even more informally:
THE SYSTEM CONTINUES TO DO ITS THING, REGARDLESS OF
CIRCUMSTANCES
In accord with this Principle, the Selective Service System continues to
register young men for the draft despite the fact that there is no longer any draft,
and Government tea-tasters continue to taste tea long after the procedure has
ceased to serve any useful purpose.
60

13. The System Knows (System Goals)
Est modus in rebus.
—Horace (Quintus Horatius Flaccus)
No one who has had any intimate experience of large Systems can doubt that
—at times, at least—the System seems to know where it wants to go and seems
determined to get there, no matter where it started from or what others may
want. A dividing cell (a System of astronomical complexity) seems hell-bent to
produce a salamander, a fruit fly, or an oak tree, no matter what hardships the
environment may impose. If not stopped completely it will produce something
recognizably salamander- like, fruitfly-like, or oak-like. Similarly, bureaucratic
Systems grind remorselessly on toward their mature form despite frantic
hackings and trimmings, revisions and reforms.
This powerful Effect is a force to be reckoned with, and the astute Systemsstudent will take it into account. Strangely enough, however, there is no Axiom,
Proverb, or Saying in common circulation that adequately conveys the gist of it.
Ludwig von Bertalanffy himself, the Father of General System Theory, called it
the Principle of Equifinality[xlix], which we predict will not catch on.
Watzlawick and colleagues came up with the following rendition:[l]
THE SYSTEM IS ITS OWN BEST EXPLANATION
—which, in our opinion, is even less enlightening. Even the rough-and-ready
translation:
THE SYSTEM IS A LAW UNTO ITSELF
fails to address the specifics of the phenomenon. We therefore back off a little
and approach the topic more gingerly, one small step at a time.
When a System continues to do its own thing, regardless of circumstances, we
may be sure it is acting in pursuit ofinner goals. This observation leads us, by a
natural extension, to the insight that
SYSTEMS DEVELOP GOALS OF THEIR OWN THE INSTANT THEY
COME INTO BEING
Furthermore, it seems axiomatically clear that:
INTRASYSTEM GOALS COME FIRST
More subjectively stated:
SYSTEMS DON’T WORK FOR YOU OR FOR ME. THEY WORK FOR
THEIR OWN GOALS

The reader who masters this powerful Axiom can readily comprehend why the
United Nations recently suspended its efforts at dealing with questions of
detente, the Middle East, and the drought in North Africa in order to spend an
entire day debating whether UN employes should continue to ride first-class on
airplanes.
Prior to and underlying any other Goal, the System seems to have a blind,
instinctive urge to maintain itself. In Axiomatic form:
THE SYSTEM BEHAVES AS IF IT HAS A WILL TO LIVE
The full strength of this effect will be attested to by anyone who has been
assigned the task of dismantling an operating System, no matter how moribund.
Even in the extreme case where the System seems bent on self-destruction, the
opposing tendency guarantees that the Ghost of the Old System will remain in
evidence to Haunt the New.[a.] These Inner Goals quite obviously bear little or
no relation to the Stated Purpose of the System, which in reality is only the Wish
of the designer or manager. The main usefulness of the Stated Purpose is in
making a realistic assessment of the Delusion System within which, and out of
which, the designers, operators, or managers of the System may be working.
Once the Student learns to quickly identify such phrases as “creating the new
Socialist Man,” “making the world safe for Democracy,”or “better living through
asbestos products,” the less Delusion there will be in his/her own dealings with
Systems.
As for the Ultimate Purpose of the System, above and beyond the Inner Goals
conditioned by the structure of the System: if there is such a thing, it is beyond
the author’s ken, and perhaps unknowable. It is hard enough to find out a few
fragmentary aspects of what the System is really doing.
We therefore retreat from metaphysics to the simple, down-to-earth attitude:
the Purpose of the System is—whatever it can be used for.
62

14. Systems-Failure (Theory of Errors)
In the early days of development of electronic computers, engineers were
startled to observe that the probability of malfunctionwas proportional to
thefourth powerof the number of vacuum tubes in the circuit. That observation
led them to a preoccupation with component reliability that has reached its
current culmination in the microprocessor. But, impressive as that development
may be, it is, from the standpoint of Systems-theory, merely a neurotic
digression from the straight and narrow path. Improvement in component
reliability merely postpones the day of reckoning. As the System grows in size
and complexity, it gradually but inevitably outgrows its component
specifications.Parts(whether human or electronic)begin to fail. The important
point is:
ANY LARGE SYSTEM IS GOING TO BE OPERATING MOST OF THE
TIME IN FAILURE MODE
What the System is supposed to be doing when everything is working well is
really beside the point, because that happy state is rarely achieved in real life.
The truly pertinent question is: How does it work when its components aren’t
working well? How does it fail? How well does it work in Failure Mode?
Not surprisingly, we again encounter at this point a lack of appropriate
terminology, directly traceable to our all-too-human taboo against thinking about
failure. In all the long history of human failures, no one has seen fit to invent a
word for the process we are discussing. We shall therefore make shift with a
term borrowed from the jargon of systems theorists and call it ‘Graceful
Degradation.’[li]It is our sincere hope that someone may soon submit a more
suitable suggestion for a name for the process that surrounds us everywhere and
at all times, and in which we ourselves are intimately involved. “Graceful
degradation,” indeed!
Our basic approach is indicated in the Fundamental Failure Theorem (F.F.T.):
A SYSTEM CAN FAIL IN AN INFINITE NUMBER OF WAYS
An extreme example is the government of Haiti, which, with one exception,
[a.]consists entirely of Departments that do not function. Dozens of national and
international aid agencies, frustrated by the inability of the Haitian Government
to cope with outside assistance, have sent emergency representatives to Haiti, to
teach the government officialshow to fill out requests for aid.[lii]
Purists and theoreticians may argue that the number of ways in which a
System can fail is not truly infinite, but merelyvery large. While conceding the

theoretical interest of such speculations, we stress the practical observation that,
while some kinds of failure may be easily predictable, most are not. In general:
THE MODE OF FAILURE OF A COMPLEX SYSTEM CANNOT
ORDINARILY BE DETERMINED FROM ITS STRUCTURE
Those with an aptitude for Systems work will experience the truth of this
Axiom as a gut conviction. For those others whose intuitions are not quite so
viscerally mediated, we suggest brief daily meditation on the following two
mantras, taken from the Saga of Three Mile Island:
(1) “The core is in a mode that this is just not designed for.”[liii]
(2) “We saw failure modes the like of which had never been analyzed.”[liv]
Beginners in Science and in Politics quite commonly deny the truth of the
Failure-Mode Theorems until their validity has been repeatedly borne in upon
them by repeated disasters attendant upon their own pet schemes. Some, indeed,
in both Professions, persist in their Systems-delusional views to the very end of
life. As a result, it is usually the case that:
THE CRUCIAL VARIABLES ARE DISCOVERED BY ACCIDENT
Example 1. The Pyramid of Snofru.
On the edge of the desert, a few miles south of the Great Pyramids of Egypt,
stands a ruined tower of masonry some two hundred feet high, surrounded by
great mounds of rubble. It is the remains of a gigantic Pyramid. Its ruined state
has been variously attributed to time, weather, earthquake, or vandalism, despite
the obvious fact that none of these factors has been able to affect the other Great
Pyramids to anywhere near the same degree.
Only in our own time has the correct solution to this enigma been advanced.
In conformity with basic Systems Principles (see the “Problem” Problem,
Chapter 31) the answer was provided by an outsider, a physicist unaware that
there was any problem, who, after a vacation in Egypt, realized that the Pyramid
of Snofruhadfallen down. The immense piles of rubble are big enough to
reconstruct the entire Pyramid. It is clear thatthe thing was almost complete
when it fell.[lv]
With this insight, we can now reconstruct the probable sequence of events.
Snofru, jealous of his grandfather Zoser, who had built the first Pyramid,
attempted to build on a larger scale. But he failed to take into account the
behavior of large Systems. Unknown to Snofru, Zoser’s achievement hung by a
thread. It was at the limit of stability for such a structure. Snofru, in expanding
the scale, unwittingly exceeded the engineering limits. It fell down.
Example 2. The Pyramid of Cheops.

Cheops, son of Snofru, vowed not to make the same mistake. With great care
he constructed his Pyramid of finely dressed limestone blocks, carefully
arranged to distribute the stresses. His Pyramid did not fall down, nor did those
of his immediate successors, which were built in the same way. But the Egyptian
State, subjected to unbearable stresses by the building of those monsters of pride,
collapsed into anarchy.Egypt fell down.
The Fail-Safe Theorem
In expounding the science of General Systemantics we have striven to remain
at the level of fundamental theory, providing the reader with basic insights of
broad general validity, and stopping by the wayside only occasionally to pluck a
Paradox or collar a Corollary of special interest for specific situations. We have
not tried to tell the reader how to run his own affairs or those of the particular
community, society, or nation to which he may happen to belong. We will, in
general, continue to adhere to that policy. But at this point in our exposition we
deliberately swerve from our splendid isolation to inject a note of exhortation,
even of urgency, into the discussion. We believe the Fail-Safe Theorem to be of
special immediacy for everyone concerned with the fate ofHomo sapiens, and
we therefore urge all readers to read, mark, learn, and inwardly digest it, to the
end that future policy may not ignore it but rather take it and its implications into
account. Tedious exegesis would be insulting to readers of this work, and, worse,
boring. We give it, therefore, in all its austere and forbidding simplicity:
WHEN A FAIL-SAFE SYSTEM FAILS, IT FAILS BY FAILING TO FAIL
SAFE
—Nuclear strategists please note!
When the Fail-Safe Theorem (above) was first published, there were some
who challenged its validity. While freely conceding that anecdotal evidence is
not the same as rigorous mathematical proof, we nevertheless offer the following
Cautionary Example for serious contemplation by all concerned:
•At Fermi Number One Fast Breeder reactor in Monroe, Michigan, a
special anti-meltdown device was installed to deal with the remote
possibility of a meltdown.[b.] The anti-meltdown device failed, blocking the
flow of molten sodium through the reactor core and initiating a meltdown
sequence. [lvi][c.]
The student is invited to notice that the anti-meltdown device did not fail
while performing its function as a fail-safe device. It failedduring normal
operationsand in so doing it failed to fail safely; in fact, it caused the very
accident it was designed to deal with.

In this connection we note that the proposed Star Wars or Strategic Defense
Initiativeis, in its essence, an attempt to design an infallible Fail-Safe System. It
will infallibly fail, of course. But such a prediction is too easy, too elementary.
What lends special charm to Systemantics is this: it enables us to predict that
Star Wars will fail in atotally unanticipated way.

FIGURE 5. THE CRUCIAL VARIABLES ARE DISCOVERED BY
ACCIDENT.
70

15. Glitches, Gremlins, Bugs
In the early days of movable type, an edition of the Bible was published in
which the word “no” was inadvertently spelled backwards in theadmonition “Sin
no more”, causing the passage to read “Sin on more . . .’[lvii]
Some years later, in 1962, to be exact, as theMariner I Venus probe was rising
successfully off the launching pad, someone realized that a single essential word
had been omitted from the rocket’s programming. The probe had to be blown up
in mid-launch.[lviii]If the earlier event had failed to direct attention to the
importance of program Bugs, the second certainly succeeded. Nevertheless,
seven years later, in 1969, five days before the liftoff of Armstrong, Aldrin, and
Collins for their trip to the moon, it was discovered, purely by accident, that
Gravity had been entered into the flight path program with a minus sign; that is,
as a repulsive force rather than as an attraction.[lix]
We conclude: Yes, Virginia, your programwillcontain Bugs. And they will
surprise you when you find them.
What Are They?
The multiplicity of terms applied to what is obviously the same basic
phenomenon points up its continuing importance. Although “Bugs” is good,
pithy Anglo-Saxon[a.], the lack of a Standard English word for what we are
talking about reflects the powerfulresistanceof our goal-oriented minds towards
admitting the legitimacy or even the reality of impediments to our success. The
thing about Bugs, Glitches, or Gremlinsis that we really don’t want to know
about them, we just want them to Go Away. Studying Bugs for their own sake
has all the charm of studying how the paint cracks on an Old Master or how
many ways a typewriter key can stick. We don’t want to know all that. We just
want our Systems to work as smoothly in real life as they did in our fantasies,
when we were planning to buy or build them. For this powerful psychological
reason, the science of Bugs remains in a chronically underdeveloped state.
The idea that Bugs will disappear as components become increasingly reliable
is, of course, merely wishful thinking. Only the most banal types of Bugs are
related to component reliability. A failure rate of one in a million is regularly
achieved by computers whose parent companies have a failure rate of one in
three, leaving the purchaser with a complete system that lacks a maintenance
function. In general, improving Component Reliability merely pushes lumps of
Anergy out into the joints of the System or into other components, less easily
upgraded. The Rule is:[b. ]

IF IT DOESN’T FAIL HERE, IT WILL FAIL THERE
A special type of Bug is represented by the toasterthatsometimesburns the
toast or the air-conditionerthatsometimesfails to cool, usually on the second day
of a ten-day heat wave. In such cases, it is typical that the repair person can’t
find anything wrong. And after the second or third call for help,youcan no longer
find the repair person. After all, not everyone has the jugular instinct for Glitchhunting. As a case in point, we cite the recent epidemic of Phantom Dialing, in
which cordless telephonesdial the 911 emergency number spontaneously, on
their own initiative. And (as might be expected from the above discussion) the
Federal CommunicationsCommission takes the position that the phenomenon
(being merely anecdotal)does not really exist.[lx]We summarize in the Glitchhunter’s Theorem:
INTERMITTENT FAILURE IS THE HARDEST CASE
Bugs of this type actually prefer to take up residence in the interstices of
sophisticated and complex projects, where they lie dormant, rousing themselves
only at rare intervals in order to disrupt critical sequences such as the maiden
voyage of the Space Shuttle[lxi]or the launching of amultimillion-dollar
communications satellite.
A Bug when discovered may seem to demand just a quick hard-wire fix. This
simplistic approach should be resisted, as it will most likely lead to discovery of
majordistant effects of the Bug (or of the procedure used tocorrect it) under
operating conditions in the field. Unduly philosophical as it may sound, the
prudent Rule of Thumb reads as follows:
A BUG MAY BE PURELY LOCAL, BUT YOU AND I CAN NEVER KNOW
THAT FOR SURE
In similar vein:[c. ][lxii]
ONE DOESNOTKNOW ALL THE EXPECTED EFFECTS OF KNOWNBUGS
Can Bugs Be Useful? Some Famous Bugs.
The very word, “Bug”, suggests something worthless if not actually repulsive,
something suitable only to be eliminated. Yet every Bug, no matter how humble,
always gives us at least one important piece of information; namely, it tells us
one more way in which our System can fail.Since success is largely a matter of
Avoiding the Most Likely Ways to Fail[d. ], and since every Bug advances us
significantly along that path, we may hearken back to the advice given in the
Preface and urge the following Policy:
CHERISH YOUR BUGS. STUDY THEM

But there is a larger sense in which Bugs may be more than merely negatively
involved in our welfare. Sometimes they represent a spontaneous offering of
unsuspected capabilities of the System, a generous revelation of hidden vistas of
alternative functioning not contemplated in the design specifications. We need
only mention, by way of example, the famousPenicilliumfungus that repeatedly
“bugged” Dr. Fleming’s attempts to grow bacteria in Petri dishes. In the very
moment when Dr. Fleming revised his Frame of Reference from “bug” (or
“glitch” or “gremlin”) to “unsuspected behavioral capability,” the world of
Antibiotics was born.
Turning now to the field of Astronomy, the eighteenth-century comet hunter,
Charles Messier, kept encountering fuzzy objects in the sky that were NOT
comets. They distracted him in his search for comets. In order to avoid wasting
his time looking at these celestial blurs (read “bugs”), he made a list of them.
Much later, astronomers realized that those objectswhich Messier had tried to
avoid looking at are the star clusters and galaxies on which our modern
conception of the Universe is based. The famed Messier catalogue is no longer a
list of objects to be shunned.[lxiii]
Being able to switch one’s Frame of Reference confers major advantages in
dealing with Systems and/or their Bugs. Because of its importance, we have
devoted an entire Chapter to Frame-shifting.[e.] In the meantime, when
encountering a Bug, the wise student will remember to ask:
BUG OR BONANZA?
Error Correction (The Importance of OOPS):
The next step is small but crucial. It involves the realization that life isn’t a
matter of just correcting occasional errors, bugs, or glitches. Error-correction is
what we are doing every instant of our lives. The most often used word in any
language is nota, an,orthe, orme, my, ormine. It’s OOPS.
Eyes on the Prize
Our mind works by error-correction, but we don’t want to know about our
errors, we only have eyes for the goal. As Chairman Iacocca has said: we like to
read about success but what we have to deal with in everyday life is failure.
Having swallowed this bitter pill, we must discipline ourselves to a new
approach that involves constant attention to the error of the moment—the error
that is currently before us.
Then, as true Systems-students, we must go on to learn to take pride in our
mastery of the art of making error-corrections. After all:
ERROR CORRECTION IS WHAT WE DO

70

16. Form, Function, Failure
Way back in 1950, a pioneer Cyberneticist asserted[lxiv]that:
THE STRUCTURE OF A MACHINE OR AN ORGANISM IS AN INDEX OF
THE PERFORMANCE THAT MAY BE EXPECTED OF IT
Common sense? Of course. But. . .
Shortly thereafter, the world was informed that one of the largest and most
sophisticated computers was regularly going into convulsions—garbled memory
banks, disrupted calculating ability—whenever certain personnel walked nearby.
A frantic search eventually traced the effect to electrostatic charges from silk or
Nylon hose.[a.] In the light of this experience, our question for the Cyberneticist
is simply: Which structure? Which performance? and whose expectations?
On the basis of experiences such as that one, we prefer the more pragmatic
formulation of the seasoned Systems-student, as follows:
FORM MAY FOLLOW FUNCTION, BUT DON’T COUNT ON IT
To dismiss such an event as a mere Bug or Growing Pain is to miss the point.
The effect was not due to an error in circuit design, nor was it the result of a
workman’s mistake. It was an inherent performance capability, builtin but
unsuspected by the very designers who had created it, and only brought to light
by the accident that surrounded the computer with a specific environment
capable of eliciting that response. The designers had built a machine with that
capability, but they knew not what they had wrought. . . until Experience
demonstrated it to them.
We therefore generalize, in terms that emphasize that this process will happen
routinely:
NEW STRUCTURE IMPLIES NEW FUNCTIONS
—many of which will be unexpected, and some of which will be discovered only
at some later date, under new circumstances.
The point is that real novelty in the world increases as complexity increases.
As the necessary richness of underlying structure is attained, the new property
emerges, seemingly out of nowhere. A higher-level pattern of organization has
suddenly become a reality.[lxv]
AS SYSTEMS EXPAND, NEW FUNCTIONS APPEAR SUDDENLY, IN
STEPWISE FASHION
And, we may add, the new function typically bears no more resemblance to
the old than a soufflé resembles the humble egg from which it is derived.

If this Principle seems vaguely familiar, that is as it should be. It is simply the
Generalized Uncertainty Principle, stated inoptimisticterms.
As if to offset this tendency, the reverse process—loss of established functions
—also tends to occur. As the System becomes ever more highly specialized, the
simplest tasks mysteriously become too difficult. A delightful example is offered
by Supertankers (an inexhaustible source of Climax Design lore), which have
lost the ability to come into port. They are ships, but they can’t dock. In similar
fashion, the giant U.S. Postal Service has almost, but not quite, lost the power to
deliver an ordinary letter. The process is clearly exemplified in the field of
Aeronautics, where the evolution of complexity has proceeded from the simple
biplane of the nineteen-twenties, that could land in a plowed field, to the 747,
that needs a mile of reinforced concrete, and finally to the Concorde and
theSpace Shuttle, which can hardly land at all. In summary:
AS SYSTEMS GROW IN SIZE AND COMPLEXITY, THEY TEND TO LOSE
BASIC FUNCTIONS
71

17. Colossal Errors
Large Lumps of Liability:
In this Text our primary emphasis is upon the antics of large Systems— upon
those aspects of Systems-behavior that are peculiar, unexpected, paradoxical.
Nowhere are those aspects more prominent than in the area of large-scale errors
and failures. We begin with an Axiom whose validity is so self-evident that it
barely escapes being a Truism:
WHEN BIG SYSTEMS FAIL, THE FAILURE IS OFTEN BIG
Self-evident or not, this cautionary Axiom is often overlooked or forgotten in
the excited pursuit of grandiose goals by means of overblown Systems. What is
ignored is the fact that big Systems represent a lumping-up of catastrophic
potential. Thus (for example) Nuclear Power Plants require more capital
investment than most countries—even large nations—can conveniently spare. If
anything goes wrong, the accumulated wealth of an entire region goes down the
drain.[a.]
A similar example is provided by those developing countries that commit all
their health budget to buildingone medical schoolandone hospital. Very little is
left over to meet the ongoing health needs of the people.
Even more unsettling, however, is the propensity of Colossal Systems for the
actual instigation or promotion of Colossal Errors. Warfare, being perhaps the
most grandiose of mankind’s enterprises, offers many prime examples of this
effect. One may argue that Hitler’s failure to supply his troops with boots and
winter overcoats for the invasion of Russia was not really a Colossal Error but
merely a miscalculation based on overoptimism. But what are we to say of
America’s military planners, who simplyforgotthat German submarines could
cross the Atlantic and who therefore failed to arm American merchant ships
steaming up and down the East Coast laden with the supplies of war? Four
hundred such ships, unable even to fire back at their attackers, were sent to the
bottom by U-boats in the first six months of the war.
One must resolutely shake off the temptation to believe that, even though such
Colossal Errors may have happened to others, and at remote historical distances
of time, they could never happen again, especially not to us. Consider:
In forty years of imagining the various scenarios of Nuclear Warfare, the
Defense Planners seem to have forgotten to consider the effects of the
Electromagnetic Pulse (E.M.P.), which at the instant of the very first nuclear
explosion will black out all communications and short-circuit practically all

electrical installations over the entire continent. The Planners seem also to have
overlooked the fact that nuclear explosionsstir up dust, which blots out the sun,
thereby producing cold weather, darkness, and failure of crops: i.e., Nuclear
Winter. Finally: physicists have only recently realized that the detonation of a
nuclear warhead on top of a nuclear power plantwould produce a multi-megaton
explosion with devastating amounts of long-lasting radioactivity. A single such
eventcould render a nation the size of England, France, or Germany largely
uninhabitable for fifty years.[lxvi] The Student is invited to consider the element
of delusion involved in burying missiles to protect them from enemy attack
while leaving nuclear power plants on the surface, conveniently located near
large cities.[b.]
Shifting now to Peacetime Affairs, we note the same tendency towards
production of Colossal Errors in large Peacetime enterprises:
•Shortly after World War II, the British, in order to relieve a shortage of
cooking oil, embarked on a gigantic plan to grow groundnuts (peanuts) in
East Africa. The plan came to grief after eight years of fighting hostile soil
and adverse climatic conditions. Eighty million dollars were lost. The
project was abandoned when someone finally remembered that it was West
Africa, not East Africa, where peanuts thrive.[lxvii]
•Less well-known than the Aswan Dam, the great Bakolori Dam on the
Sokoto River, 80 miles south of Lagos, Nigeria, has had equally surprising
and unexpected consequences. Three miles long, 165 feet high, it was built
to bring irrigation water to the dry valley below. But the 13,000 villagers
who lived above the dam were not taken into account. When ordered to
leave their homes to be resettled in the barren uplands, they refused, and
hundreds died in the resulting riots. The planners had also neglected to
consider the farmers living downstream, who insisted on growing their
staple crop, millet, rather than wheat as the government had intended. In the
outcome, the farmers use and pay for much less water than planned for, the
revenues fall short of the operating costs of the dam, and the Nigerian
government has to make up the annual loss.[lxviii]No wheat gets grown.
We conclude:
COLOSSAL SYSTEMS FOSTER COLOSSAL ERRORS
Indeed, in such settings:
COLOSSAL ERRORS TEND TO ESCAPE NOTICE
—and, if noticed, may even be excused. If the error is grandiose enough, it
may not even be comprehended as an error, even when brought to attention.

•Thus, the loss of 50,000 American lives per year in auto accidentsis seen,
not as a mortal flaw in our Transportation System, but merely as afact of
life.[c. ][lxix]
•The dismantling of the American street railway system and its replacement
by privately owned automobiles, at a thousand-fold increase in traffic
density and energy consumption, has hardly been noticed. Some, indeed,
have even called itProgress.[lxx]
•In Military Affairs: When a Military Systems-person reported from
Vietnam, “We had to destroy the village in order to save it,” half the
population of the United States experienced the shock of direct encounter
with a Colossal Systems-Error. The other half nodded approvingly,
enmeshed in the Delusion itself.
The Nuclear Age seems to spawn such errors and delusions in special
abundance. Thus:
•It has been proposed that Western Civilization can be preserved by stuffing
it under a mountain in Colorado, where nuclear bombs can’t get at it.
•In the field of Nuclear Weaponry, the power to exterminate one’s enemy
(and concomitantly oneself) ten times over is regarded asnot quite enough.
•The Antiballistic Missile System, pushed through Congress on the grounds
that it was essential for national security, was abandoned as unworkable one
year after completion. The taxpayers were then informed that it had been
unnecessary all along.
•The Russians, subject to the same delusional pressures, built a similar
Antiballistic Missile Systemto correspond to that of the West and
abandonedtheirswhen we abandonedours.
•A new generation of nuclear missiles—the MX—have been rushed into
production, despite the fact that no one could suggest a suitable place to
hide them. Designed to constitute an invulnerable retaliatory force, they are
vulnerable and therefore useless for retaliation.
Such delusions are by no means restricted to Nuclear matters. In Medicine, for
example:
•Medical Science, in its studies of the relationship between heart disease
and fats in the bloodstream, for twenty years focused its attention on the
wrong fats.[d.][lxxi]Still reeling from this shock, researchers were informed
thatObesity May Be Healthy After All.[lxxii] And what may be the coup de
grace for cherished theories was administered when it was recently reported
that a little dietary salt may be a Good Thing.[lxxiii]

•In the field of Human Behavior, an enormous research effort is being
directed to proving that Mental Illness is literally a disease of the brain.
This conviction appears to stem at least in part from a Systems-delusion,
namely:
IF IT’S TREATED BY DOCTORS IT MUST BE A DISEASE
However, the salient feature of most mad and eccentric behavior is not its
defectiveness but rather its incredible ingenuity, such that merely rational
persons—doctors, for example—can’t deal with it.[e. ][lxxiv] Further, while
drenching the human brain with drugs or jolting it with electricity may cause
some temporary improvement in some areas of functioning (See Vending
Machine Fallacy), the tasteful intervenor prefers more specific, more physiologic
methods. Dipping a watch in honey may slow it down so it keeps better time, but
a more elegant method is to adjust the escapement.[f.]More to the point: a
century of advances in electronics has failed to produce any improvement in the
quality of thecontentof the messages broadcast over the air waves. There is
equally little reason to suppose that tinkering with brain metabolism will
improve the quality of people’s thoughts, feelings, and behavior.
Total Systems
It is no doubt gratuitous in the Twentieth Century, the Age of Totalitarianism,
or even in the Twenty-first, to provide a formal definition of a Total System. We
shall therefore merely mention that a Total System is a Colossal System carried a
few steps further to that final state in which everything is involved in the
System. As such, a Total System can be expected to display all the bizarre
phenomena of Colossal Errors and Delusions, but at an even higher pitch of
grandiosity. We begin with a classic example from History:
Example:
For uncounted centuries, Egyptian Kings and dignitaries were buried beneath
simple rectangular brick structures, called mastabas (“tables”), which slowly and
gradually became larger and more elaborate. Then, at a certain moment in
Egyptian history, the mastaba tombs suddenly underwent a massive development
into the monstrous Pyramids of the Pharaohs. What triggered that sudden plunge
into grandiosity? Professor Mendelssohn has suggested[lxxv] that the tombbuildingSystem had reached a certain levelof involvement of the entire social
order such that it became impossible to stop the process without disrupting the
State. The System had expanded to involve the vital functions of the Nation as a
whole. It could no longer be taken down without immense suffering in terms of
unemployment, hunger and dislocation. Furthermore, it had to grow larger and

more grandiose with each turn of the cycle, since the fate of all the people
hadbecome tied in with its continued operation. It had, in fact, become a Total
System and had gone into a Runaway Sequence.[g.]
At least since the days of the Pharaohs, there has persisted for many a certain
ambivalence about Total Systems—a mental attitude that is part fascination, part
deep suspicion. The siren call of Utopia; the appeal of the City of God (pure,
clean through); or the thrill of power at being associated with a giant social
machine that can roll over all obstacles—these attractions compete with the
uneasy feeling that things could get out of control, that one might possibly get
hurt if one fell afoul of such a System. The sudden disappearance of entire
civilizations, such as that of the Maya, with no evidence of foul play, lends a
certain credibility to such uneasiness.
We suggest, as a basis for further theoretical investigations, the following
proposition:
A TOTAL SYSTEM THAT GOES INTO A RUNAWAY SEQUENCE MAY BE
FORCED TO GROW OR TO DISINTEGRATE IN CHAOS
and as a Corollary, we suggest:
TOTAL SYSTEMS TEND TO RUN AWAY (GO OUT OF CONTROL)
After all, if there’s no Environment to provide corrective feedback, what’s to
stop them?

FIGURE 6. WHEN BIG SYSTEMS FAIL, THE FAILURE IS OFTEN BIG.

79

18. Unexpected Interactions
Electric Turtles:
These devices, consisting of a small metal carapace mounted over three
wheels (one swiveled) and operated by flashlight batteries, seem unlikely
candidates for providing deep insight into Systems-behavior. Placed on a
tabletop, they roll here and there, making quick turns when they come to the
edge. A simple switch causes them to head back to a little barn-like recharging
structure when their batteries get low. They have nothing corresponding to a
brain—perhaps two neurons at most.
Nevertheless, two such toys placed on a table top exhibit a startling
interaction. If their batteries begin to run low at the same time, they will both
head for the recharging shed. When they reach the entrance they begin bumping
into each other and knocking each other around until one or both is knocked off
the table or otherwise incapacitated. Totally lackingin brains, they nevertheless
fight each other.[a. ]
The concreteness of this example should not distract us from the awareness
that, in essence, two Systems were fighting with each other. At a slightly more
complex level, we report the experience of Mr. W. Evert Welch, who during
World War II was involved in the design of control systems for high-altitude
bombers:
“. . . the engine temperature control had a nasty habit of overpowering the
automatic pilot, the cabin airflow control seldom saw eye-to-eye with the
engine control and the cabin temperature control came up with more side
effects than some of our wonder drugs.’[lxxvi]
Needless to say, these Unexpected Interactions were discovered after the fact,
while the bombers were actually flying.
With apologies to William Blake as well as to Gregory Bateson, we have
designated this particular type of Unexpected Interaction as FEARFUL
SYMMETRY.[lxxvii]Examples range from Sibling Rivalry to the Nuclear Arms
Race. The feature of FEARFUL SYMMETRY that is of outstanding interest to
us as Systems-students is its built-in tendency to Escalation, which can progress
to the point of Meltdown and Explosive Release of Poisonous Vapors.[b.]
FEARFUL SYMMETRY can be avoided—a state of affairs desirable enough in
itself—if System B is unable or simply unwilling to respond in kind to System
A. But the day of reckoning is thereby merely postponed, as the impact of A on
B will eventually be transmitted, perhaps through C and D, back to A. The

System eventually Kicks Back, no matter what. As an example: when the British
National Health Service recently cut down on hospital beds in order to save
money, other support services and welfare agencies were swamped with sick
people whose needs for such services had skyrocketed precisely because their
medical problems were not being dealt with. The increased budgetary demands
upon those support agencies far outran the original money savings on hospital
beds.
The Electric Turtle Effect is regularly re-discovered by elected officials whose
anti-systems bias keeps them from learning the elementary survival lore of
systems-operation. The implications are clear:
IN SETTING UP A NEW SYSTEM, TREAD SOFTLY. YOU MAY BE
DISTURBING ANOTHER SYSTEM THAT IS ACTUALLY WORKING
79

D. Communication Theory
80

19. Communication Theory
How many of us have observed that the most brilliant generalizations are
sometimes dropped almost unnoticed in casual conversation? We owe our
awareness of one of the most sweeping, most satisfyingly self-evident
Aphorisms to a young woman who wears hiking boots and who has chosen the
self-effacing profession of Movie Projectionist. The other day, apropos of
nothing in particular, she observed that:
EXPERIENCE ISN’T HEREDITARY—IT AIN’T EVEN CONTAGIOUS
—thereby establishing herself, with one stroke, as the equal of such immortal
Systems-pioneers as K. Marx, A. Korzybski, and Captain Murphy.
Since Experience is transmitted, not by genes nor by virus particles, some
method must be devised to ensure that it is imparted from one person (or
System) to another. That method is Communication.
Communication Theory has had a somewhat checkered history. Most people
intuitively understand that there is a fundamental difference a between kicking a
stone and kicking a sleeping dog.[a. ][lxxviii]Science, which explains the former,
has had suspiciously little to say about the latter. Yet, in our daily life, we are
constantly encountering situations of thesecondkind. This is perhaps the basis for
our uneasy feeling that Science Does Not Have All the Answers. To fill the void,
Communication Theorywas invented. In the case of the sleeping dog, it is clearly
not enough to analyze the situation in terms of masses, energies, velocities, and
vectors. It is themeaning of the kick, i.e., the message received by the dog via the
kick, that determines the reaction. And plainly enough it is thedogwho decides
that meaning.
This leads directly to the perception that[lxxix]
THE MESSAGE SENT IS NOT NECESSARILY THE MESSAGE RECEIVED
Dunn’s Indeterminacy:
“A lecturer gave a talk on the tsetse fly and illustrated his remarks by
reference to an eighteen-inch model of the fly. Following the lecture, one of
those attending said he quite understood that such flies could pose a
problem, but the local variety were much smaller . . .”[lxxx]
On the basis of this experience, Professor P .D. Dunn was led to the following
felicitous formulation of the same insight, which we shall call Dunn’s
Indeterminacy:[lxxxi]
EVERY PICTURE TELLS A STORY—BUT NOT THE SAME STORY

This being the case, a moment’s reflection will make it intuitively clear that,
try as we may,
IT IS IMPOSSIBLE TO NOT COMMUNICATE
Think of the eighteen-inch tsetse fly without any explanatory lecture. It
continues to tell a story, even though the story is different for each viewer. Or
think, as Bateson reminded us, of “the letter which you do not write. . . the
income tax form which you do not fill in . . .” which nevertheless elicit vigorous
responses.[b. ][lxxxii]
The Student should pause briefly at this point to allow the full significance of
the preceding Theorems to sink in. He or she will then be mentally prepared for
the quantum leap of understanding that will take place as the next Axiom is
assimilated:[lxxxiii]
THE MEANING OF A COMMUNICATION IS THE BEHAVIOR THAT
RESULTS
This Axiom, which flies in the face of vulgar Common Sense, is basic. It is a
nettle that must be grasped, and the sooner the better. Simply put: Are we willing
to subject our communications to the test of actual outcomes?
Once we clear this hurdle, the rewards are great: the dispelling of Illusion;
stark clarity in our relations with other people and other Systems; the pride of
acting responsibly. In place of the passive luxury of complaining and blaming
others or external circumstances, we can have the dignity that comes of knowing
that we ourselves did it, that is, that we ourselves participated in producing the
outcome. And, having identified ourselves as responsible, we shall more
promptly get on with changing our strategies of communication to more
promising approaches. Success, rather than the doubtful pleasures of
complaining about failure, will then be our reward.

FIGURE 7. THE MEANING OF A COMMUNICATION IS THE
BEHAVIOR THAT RESULTS.
87

20. Information
“Knowledge is power,” wrote Francis Bacon. But Bacon’s vast knowledge did
not keep him from taking bribes and falling into disgrace. Clearly, Bacon’s
knowledge did not have the power to save him from himself.[a.]
What Bacon overlooked, we now make explicit: Knowledge is useful in the
service of an appropriate Model of the Universe[b.], and not otherwise. We are
indebted to Robert S. Lynd for the definitive aphorism on the subject:[lxxxiv]
KNOWLEDGE FOR WHAT?
The pursuit of Information-as-such confuses means and ends. Best
exemplified by those Government Agencies that carry the word Information or
Intelligence in their titles, it typically results in huge mountains of accumulated
data of which only a tiny fraction ever sees application to relevant questions—
and that often too late.
Information Theory
Readers who appreciate the importance of Communication Theory are
sometimes puzzled to run across references to Information Theory. Information
Theory is a mathematical treatment of what is left after the meanings have been
removed from a Communication.[c.] Information is defined as a bulk commodity
like potatoes, to be weighed out without reference to the quality of individual
units. Within this framework, a message such as, “Let there be light!”, if
enunciated without mumbling, has exactly equal weight with, “Winston tastes
good, like a cigarette should.”
We’ve nothing against Information Theory, really. It’s just a little too basic for
our purposes. We therefore exercise our right to be selective, presenting those
Axioms from Information Theory that are directly pertinent to our own
discipline of Systemantics. We begin with the Basic Information Theorem
(B.I.T.):[lxxxv]
INFORMATION DECAYS
or, as Professor Whitehead has so aptly put it:
KNOWLEDGE DOES NOT KEEP ANY BETTER THAN FISH
The reader whose copy of last month’s Committee Meeting notes has faded to
a purplish blur has a gut feeling for the problem being considered here.[d.]
Furthermore, and even more poignantly:
THE MOST URGENTLY NEEDED INFORMATION DECAYS FASTEST

Thus, at certain large banking headquarters in London, Zurich, and New York,
the useful half-life of a quotation of (say) the dollar value of gold may be as
short as thirty seconds. In truly large Systems such as National governments,
even higher levels of urgency may be attained. The coordinates of a nucleararmed space satellite, for example, may need to be tracked at millisecond
intervals.
What happens to Information that has outlived its useful half-life? Before
answering this question, we pause to note that Usefulness is always relative to
the System being considered:
ONE SYSTEM’S GARBAGE IS ANOTHER SYSTEM’S PRECIOUS RAW
MATERIAL
We pass over in silence the Systems represented by Gossip Columnists, Secret
Agents, and a certain type of Journalists, respectively, where the Axiom appears
to have literal validity, involving real garbage cans.[e. ]
In short, Information that has outlived its usefulness in one System may be
just maturing (or getting ripe) with reference to another.
Information that no longer has any conceivable usefulness for anyone is
commonly regarded as legitimate raw material for History. In this transmuted
form, Information enjoys a ghostly Golden Age of indefinite duration, enriching
the fantasies of readers who savor the vicarious thrills of crises safely past, and
who tuck away the knowledge of howthosebattles were won or lost, just in case
the future should bring a similar adventure for them.
For most of us, however, the Decay Rate of Information remains merely an
interesting abstraction, for our efforts at Coping are limited by an even more
drastic law, the Inaccessibility Theorem:[lxxxvi]
THE INFORMATION YOU HAVE IS NOT THE INFORMATION YOU
WANT.
THE INFORMATION YOU WANT IS NOT THE INFORMATION YOU
NEED.
THE INFORMATION YOU NEED IS NOT THE INFORMATION YOU CAN
OBTAIN.
Purists may object that the Law as thus stated is too extreme, too black-orwhite, too all-or-nothing, too pessimistic, too sweeping. After all, one does
sometimes have the needed information. But few, surely, will complain that the
emphasis is not properly placed.
The typical scenario is as follows: the reference you are seeking today was in
the throwaway journal you hurled into the wastebasket last Friday, and the

cleaners emptied the wastebaskets over the weekend. We summarize in the Rule
of Thumb for missing information:
DON’T BOTHER TO LOOK FOR IT. YOU WON’T FIND IT
It will turn up later—when you no longer need it.
Messages
We have already noted that the Message is the Medium by which the System
knows the outside world—and, we now hasten to add—its own internal
functioning, too. In a smoothly-functioning System, the number of formal
messages is near minimum. The tasks get done and the System moves on to new
tasks. In contrast, a poorly-functioning System begins to generate increasing
numbers of messages, often shaped around such questions as “What went
wrong?”, “How far along is Task X?”, and especially, “Why don’t we have better
feedback?” As the System sinks deeper and deeper into the morass of unfinished
tasks, the business of exchanging messages expands exponentially, until at last
the non- functioning System is completely occupied with its own internal
communication processes. Like a catatonic schizophrenic, it is now preoccupied
with a fantasy life that is completely internal. This seems to be a major pitfall for
religious and social movements, which may begin as dynamic new systems for
better living and end up as elaborately self-referential thickets of other-worldly
dogma.[f.]
In accord with these observations, and mindful of our intended future
development of this topic, we further expand the B.I. T. to read as follows:
IN A CLOSED SYSTEM, INFORMATION TENDS TO DECREASE AND
HALLUCINATION TENDS TO INCREASE
87

21. Talking to the System
Up to this point, we have considered communication with the System in
objective terms, as a phenomenon viewed from the outside, as it were. We now
take a more personal and subjective approach. As Systems-students, what should
we know about talking to the System?
Whole Dog Spot:
The first thing to note is that talking to a System is not like talking to a person
or even to a pet. The command, “Here, Spot!” can reliably be counted on to
produce not merely an approach response of the four legs, but also appropriate
accommodative reactions of head, ears, tail, and body. Thewhole doghears and
responds. If Spot chooses not to obey, a repetition of the command will very
likely produce unmistakable body language suggesting that Spot has heard and
feels guilty (or not, as the case may be). One may be upset with Spot, but one
has no problem with the communication processper se.
Not so with Systems. Our message may have been seen by only one person in
only one department, and that person may not have understood it. The Systemas-such may be totally ignorant of the receipt of the message, let alone its
content, and whatever response organs the System might have may remain
totally unactivated.
This is the point at which we go astray. Having sent our message,
weimaginean integrated organizational brain capable of responding in an
integrated way to our message. In all likelihood, we imagine wrongly.
Technically, our imagining is a mere Delusion, the result of mental habits
engendered by our childhood experiences of communicating with people and
pets—that is, with unified entities.
If we are to avoid this source of Delusion, we must avoid the naive
expectation that a System can respond like a person. We must not assume that a
message sent will automatically go to a central Thinking Brain, there to be
intelligently processed, routed to the appropriate sub-centers, and responded to.
As Professor Edward T. Hall has reminded us, “By their very nature
bureaucracies have no conscience, no memory, and no mind.”[lxxxvii]Although
Professor Hall perhaps goes too far, the lesson for us as Systems-students is
clear. In communicating with Systems, we must take upon ourselves a far greater
degree of responsibility and initiative than we are accustomed to do when
conversing with a person or a pet. Or, if we remain loyal to the pet metaphor, let
us consider our System to be like apet Dinosaur, and let us keep in mind the

Dinosaur Effect:[a. ]
EXTRA BRAIN IN TAIL, TAIL WAGS ON OWN SCHEDULE
System-semantics
Mindful of the response of the average person to mention of the word
“semantics,” we promise to use it as little as possible, Nevertheless, we cannot
avoid some discussion of what is, after all, a Key Concept of Systemantics. Of
the many ways of recognizing a true Systems-person, language remains the best
diagnostic tool. Related to Bureaucratic Jargon but distinct from it, Systemsemantics is best defined ostensively; i.e., by example. We choose for our
examples two classic responses, both of them from the field of Government:
1. “That statement is no longer operative.”
This first example reminds us that the Systems-student must be prepared to
make, at short notice, a rough-and-ready translation into Martian.[b. ][lxxxviii]
2. “We are not in the mode of answering questions like that.”
Here the student is invited to appreciate the elegance of the Magisterial (or
possibly Royal) “We” employed in conjunction with the term “mode” in such a
way as simultaneously to imply (1) high authority and (2) the helplessness of a
computer whose Function button has been pre-set and locked into place.
By paying attention to such verbal offerings, the astute Systems-student will
be able to detect, not merely whether the individual before him is operating in
Systems-mode, but also certain specifics of the System involved. In brief, the
student will be able to infer something of the speaker’s Frame of Reference.
Such information can be useful.[c.]
Finally, in the Computer Age, one must be prepared, or even braced, for
semantic structures rarely if ever previously encountered. Thus, a routine request
for Address Correction produced the following response from thecomputer:
[lxxxix]
Mrs. Hillary Jones
Eliminate R.F.D. 2
Westport, Conn.
89

Part Two: Applied Systemantics
90

A. Systems and Self-Defense (MetaStrategies)
91

22. How Not to Solve Problems
Up to this point our development of the subject has been rigorously logical,
austerely theoretical. We have made few if any concessions to mere expediency
or to the demands of the market-place. The earnest Systems-student who has
toiled thus far may justifiably ask: Is this all, this handful of abstractions? Is
there to be no word of practical advice? Did not the Author, way back in the
Preface, promise that we would gain, not merely in understanding, but also in
practical know-how, if we but applied ourselves to mastery of this difficult
science?
The answers to the preceding questions are, “No,” “Yes,” and “Yes,”
respectively, and therefore, in accordance with our promise, we now leave
behind the pleasant meadows and lowlands of Academe and head for the hills,
where we shall toil up the slopes of Pragmatic Systemantics as far as our
strength and skill can take us.
We have already mastered the hard lesson of the Operational Fallacy, with its
dreary implication that Systems Never Do What We Really Want Them To Do.
What is now offered is a primer of What Can Be Done, given the existence of
such built-in limitations.
Briefly, what can be done is to Cope and, on rare and satisfying occasions, to
Prevail. The mature and realistic Systems-student asks no more than this of Life,
taking contentment primarily from the knowledge of having lived in harmony
with Nature, and only secondarily from the fact that no one else can get any
more, either.
Problem-Solving:
How to achieve success in dealing with Systems is, of course, a Problem. Up
to this point we have addressed this Problem implicitly, by providing basic
information relevant to the lawful behavior of Systems. Our assumption has been
that such information almost automatically leads to correct responses in a wide
variety of situations, and so it does. But not all situations are so easy. What is the
correct course of action to take when the correct course is not apparent? What
shall we do when we don’t know what to do? Even worse, what shall we do
when the obvious course has obviously made things worse? This is the domain
of Problem-solving in its more general formulation. We shall therefore devote a
few pages to the formal strategies of Solving Problems. We shall begin by noting
that Mankind, in its long history of grappling with Problems, has until recently
failed to take sufficient time out to work on the larger problem—the meta-

problem—of How To Solve Problems.[xc]And by way of introduction we shall
dispose of those approaches that donotlead to resolution of our problems.
A. “No Problem”:
Curiously, the literature of Altered Mental States makes little mention of the
most common Altered Mental State of all, the condition of a person (or System)
who has a problem and doesn’t yet realize (or denies) that there is a problem.[a]
The strange and uncomfortable things that are happening are explained in all
sorts of implausible ways. As this topic is primarily one of Psychology rather
than of Systems, we shall pause only long enough to note that persons or
Systems in this unblessed state often adhere strongly to a bizarre Systemsdelusion, the Inevitability-of-Reality Fallacy, the belief that:
THINGS HAVE TO BE THE WAY THEY ARE AND NOT OTHERWISE
BECAUSE THAT’S JUST THE WAY THEY ARE[a. ]
Thus, our ancestors must have spent a lot of time being cold during the Ice
Ages, but until someone noticed, little could be done.[b. ][xci] Similarly, until
Franklin Roosevelt mentioned that one-third of a nation were ill-housed, ill-fed,
and ill-clothed, the nation as a whole (especially the other two- thirds) assumed
we were in a state of normalcy.
Actually, the person (or System) who has a problem and doesn’t realize it
hastwoproblems, the problem itself and the meta-problem of Unawareness:
IF YOU’RE NOT AWARE THAT YOU HAVE A PROBLEM, HOW CAN
YOU CALL FOR HELP?
B. Information, Please!
Basic information and common sense enable the prudent man or woman to
solve many problems, and the premise of this book is that such basic information
is worth having. But the problems that try our souls are those that donotyield to
such simple measures. In the face of such problems, persistence in informationgathering can be self-defeating. Prolonged data-gathering is not uncommonly
used as a means ofnotdealing with a problem: for example, the thirty-year study
of whether Standard Oil was really a monopoly. When so motivated,
information-gathering represents a form of Passivity.[c. ][xcii]
A more recent example is that of Acid Rain. Whereas the Canadian
Government has undertaken to reduce the emissions that cause Acid Rain, the
United States has elected tostudy the problem indefinitely.
C. Hopeful Traveling.
Ever since the famous essay of Eric Berne, entitled, “Away From A Theory Of

The Impact Of Interpersonal Interaction On Non-verbal Participation,” it has
been understood that anyone who announces a program beginning with the word
“Toward. . .” probably does not intend to get any where.[xciii] As Berne puts it,
real people will not get on an airplane whose flight plan calls for it to fly
“toward” New York. Nor will those who intend to get to a solution abide a
program that merely aims “toward” the goal.
D. Getting Rid of. . .
This method of dealing with pesky problems, learned by almost everyone at a
tender age, is deeply ingrained by its apparent success in the short term. But
while it may seem only common-sensical, if not actually instinctive, to swat a
bloodthirsty mosquito on one’s arm, one need only spend a few warm evenings
in Canada to understand that one cannot thereby alter the Mosquito System to
one’s lasting advantage. When applied to problematical Systems of any size, the
strategy called Getting Rid Of simply doesn’t work. We have already noted that
the attempt to Get Rid Of insect pests through toxic chemicals has resulted in the
poisoning of the food chain and the death of eagles, not to mention the pollution
of the environment. A few years ago the Chinese attempted to Get Rid Of local
village markets, which in some way offended against current orthodoxy. The ban
was successful, but within a few weeks the flow of basic necessities such as rice
and vegetables had ceased. To prevent mass starvation, the markets had to be
reinstituted.[xciv]
Getting Rid Of sets off self-corrective mechanisms that cause the entire
System to oscillate, reverberate, and readjust as it compensates for the sudden
loss of components whose unsuspected vital functioning suddenly becomes
obvious. No, students of Systemantics, we trust that you will not reach for this
bludgeon. To do so is to signal the abandonment of the very Spirit of
Systemantics. We do not need, we cannot afford, the Angry Upright Ape with
the Spear.
For dealing with one mosquito, a good swat may work, but for comfortable
and elegant accommodation to the Mosquito System, something more is needed.
94

23. The Tao of Problem Avoidance
On the wintry morning of January 28, 1986, frost had crept as far south as the
Everglades of Florida. The space shuttleChallengersat on the launching pad,
completely encased in ice. The authorities, aware that President Reagan was
about to give a speech mentioning the successful lift-off, gave the go-ahead. Had
there been at the top of the command chain at that moment a Chinese scholar,
steeped in the nuances of the Tao, he might have said: “Friends, today is not a
good day to fly. Let the schedule go, let the ice melt, and live to fly some other
day.”
Problem Avoidance is the strategy of avoiding head-on encounter with a
stubborn Problem that does not offer a goodpoint d’appui, or toe-hold. It is the
most under-rated of all methods of dealing with Problems. Little wonder, for its
practitioners are not to be found Struggling Valiantly against Staggering Odds,
nor are they to be seen Fighting Bloody but Unbowed, nor are they observed
Undergoing Glorious Martyrdom. They are simplysomewhere else, successfully
doingsomething else. Like Lao-tzu himself (the earliest known practitioner of the
method), they have slipped quietly away into a happy life of satisfying obscurity.
[xcv] Similarly, to ask for a list of successful applications of the technique of
Problem Avoidance is nugatory. One would be, in effect, asking for a list of
Difficult Situations that never actually materialized.[a.]
One could quite easily, however, make a long list of Difficult Situations that
could have been avoided by application of this technique. For example,
Napoleon could certainly have saved himself a lot of bother had he decided not
to attempt to take Moscow.[b.]
Teaching Problem Avoidance is rendered even more difficult by the lack of an
elegant Axiomatic formulation. There simply isn’t in current circulation a
sufficiently short, pithy aphorism to convey this idea in compelling fashion. The
nearest approach uncovered so far runs:
IF YOU’RE NOT THERE, THE ACCIDENT CAN HAPPEN WITHOUT YOU
As usual, the lack of a well-honed proverb to cover the situation reveals a
blind spot in the popular culture, and this in turn is probably the reason why so
few of us actively practice Problem Avoidance.
So alien is this strategy to our ingrained habits of thinking and acting that it is
sometimes rejected out of hand as unworthy. It has even been confused with
Passivity. But Problem Avoidance is not a form of Passivity. The opposite of
Passivity is Initiative, or Responsibility—not Energetic Futility. Problem

Avoidance is in fact the most elegant form of Problem-solving, since it actively
and responsibly avoids the entire Meta-problem of Dealing With the Problem.
Furthermore, since many of the world’s biggest problems involve dealing with
the wreckage of old failed Solutions cluttering the landscape, Problem
Avoidance has the additional merit of avoiding further additions to that
wreckage.
On Not Joining the Coast Guard
What has been said with regard to Problem Avoidance is perhaps most
pertinent with respect to the most poignant issue of all—that of becoming
involved with a particular System in the first place. A form of Fatalism or
sleepwalkingtends to supervene at the point where this most crucial decision is
made. The decision is often allowed to occur by default. True, involvement in
certain Systems may seem almost unavoidable, and a large part of this book has
been devoted to Coping after involvement has occurred. But one is not
absolutely required, for example, to join the Coast Guard, and if one chooses
one’s occupation and geographical location aptly, one need not be involved with
the Coast Guard in any immediate way. Not Joining the Coast Guard, then, can
be the paradigm for the Meta-strategy here advocated.[c.]
The decision to become involved with a particular System should be made
carefully, on the basis of a balanced judgment of one’s interests. One need not
drift (or sail, or barge) into Systems uncritically:
CHOOSE YOUR SYSTEMS WITH CARE
Remember:
DESTINY IS LARGELY A SET OF UNQUESTIONED ASSUMPTIONS
Creative Incompetence
Intimately linked with Not Joining The Coast Guard is the technique of
Creative Incompetence, so delightfully and insightfully expounded by Dr. L. J.
Peter.[xcvi]This is a powerful method for achieving certain goals, notably those
goals involvingnot doingsomething. For example, Japan in the years after World
War II was spared many tedious requests because of her lack of a standing army.
The savings to the nation’s budget was astronomical, permitting Japan to achieve
industrial parity with Western nations. In all fairness, however, we should give
credit for invention of this technique to the Egyptian peasant of five thousand
years ago, who discovered that the best way to avoid conscription into Pharaoh’s
grandiose schemes was to be a hopelessly unpromising recruit.
Could this Principle be applied by citizens the world over? Could we ordinary
human beings becomesimply unableto support the grandiose enterprises of our

leaders? The author leaves this interesting topic for contemplation by others—
it’s too deep for me.
96

24. The Creative Tack
Allied to Problem Avoidance but distinct from it, the Creative Tack is the
maneuver of finding Problems that can be neatly and elegantly solved with the
resources (or Systems) at hand.[a. ]Curiously, popular lore seems not to offer a
Proverb or Watchword that precisely designates this maneuver. Indeed, folk
wisdom urges:
IF AT FIRST YOU DON’T SUCCEED, TRY, TRY AGAIN
—a dangerous, two-edged precept which, if wrongly understood, can become
the basis for a lifetime career of Struggling-and-Failing. More in line with the
spirit of the Creative Tack is the newer admonition:
IF SOMETHING ISN’T WORKING, DON’T KEEP DOING IT. DO
SOMETHING ELSE INSTEAD
Readers with a background in Systems, especially in Family Systems, will
nod in agreement with the Addendum:
DO ALMOST ANYTHING ELSE
But even these formulations miss something of the agile, flexible spirit of the
Creative Tack. The Creative Tack is not passive, it does not wait until an impasse
is reached. It is, rather, the active fitting together of the right problem with the
right resources and the right timing. It is the choosing of problems in such a way
as to increase the percentage of problems successfully attacked. The student
proficient in the Creative Tack asks such questions as: What can I do right now
and succeed at it? For which problem do my current resources promise an
elegant solution?
FOR MAXIMUM SUCCESS, FEEL FREE TO SWITCH SYSTEMS AND
EVEN TO SWITCH GOALS
Otherwise stated: the formula for success is not commitment to the System but
commitment toSystemantics.

97

B. Practical Systems-Design
98

25. Design Don’ts
Not surprisingly, the art of Systems-design is best approached through a series
ofcaveats. Since, by the Fundamental Theorem, New Systems Mean New
Problems, the very first principle of Systems-design is a negative one:
DO IT WITHOUT A NEW SYSTEM IF YOU CAN
The scholar will recognize this as Occam’s Razor in modern form:
AVOID UNNECESSARY SYSTEMS (SYSTEMS SHOULD NOT BE
MULTIPLIED UNNECESSARILY)
Two immediate Corollaries, with significant implications for Management, are
as follows:
(I) DO IT WITH AN EXISTING SYSTEM IF YOU CAN
(2) DO IT WITH A SMALL SYSTEM IF YOU CAN
For those who need reasons for such a self-evident proposition, we offer the
following concise summary of the entire field of General Systemantics:
Systems are seductive. They promise to do a hard job faster, better, and more
easily than you could do it by yourself. But if you set up a System, you are likely
to find your time and effort now being consumed in the care and feeding of the
System itself. New Problems are created by its very presence.[a.] Once set up, it
won’t Go Away; it Grows and Encroaches.[b.] It begins to do Strange and
Wonderful Things[c.] and Breaks Down in Ways You Never Thought Possible.
[d.] It Kicks Back, Gets In The Way and Opposes Its Own Proper Function.[e.]
Your own perspective becomes distorted by being In The System.[f.] You
become anxious and Push On It To Make It Work.[g.] Eventually you come to
believe that the misbegotten product it so grudgingly delivers is What You
Really Wanted all the time[h.]. At that point, Encroachment has become
complete. You have become absorbed. You are now a Systems-person.
One New Problem that is almost certain to appear rather promptly is that of
dismantling the New System when it demonstrates its inability to perform. At
this point one should be mindful of Agnes Allen’s Law:[i.]
ALMOST ANYTHING IS EASIER TO GET INTO THAN OUT OF
More specifically:
TAKING IT DOWN IS OFTEN MORE TEDIOUS THAN SETTING IT UP
For example, the decommissioning of old, broken-down Nuclear Power Plants
(including those that never quite managed to get activated in the first place) is a

Growth Industry that is guaranteed to thrive into the twenty-first century and
probably beyond.[j.]
The same tendency is apparent even when the flaws in the New System are
not thought to justify total dismantling: from the Leaning Tower of Pisa to the
Sagging Bridge of Zilwaukee[xcvii], painful experience has demonstrated that
the time and effort expended in trying to correct the new problem eventually
threaten to exceed the original cost estimate for the whole thing.
The New Problem does not necessarily make itself known immediately. A
prime example is the System of Insulation in homes, schools, and factories by
means of asbestos products. By the time—years later—when the power of
asbestos to cause lung cancer had been generally realized, it had already
metastasized as sheathing along the billions of pipes and ducts that are the
nerves, arteries, and veins of industrial civilization. Whereas installing asbestos
insulation had been a simple matter, its removal requires trained personnel
wearing masks and using special vacuum cleaners, leak-proof collecting bags,
etc.[xcviii]But even that task turned out to be simple compared to the New
Problem of finding out where the stuff had been put.[j.] To cap the climax, the
insurance rates for workers engaged in asbestos removal have been set so high
that few if any companies are willing to undertake the work. The asbestos
remains unremoved.[xcix]
Unfavorable Settings:
Anyone who has ever tried to manipulate an umbrella in a high wind has an
intuitive understanding that
SOME THINGS JUST CAN’T BE DONE WELL BY A SYSTEM
Technically, this seems to have something to do with rapid and irregular
fluctuations in the parameters.[k.] The pragmatic Systems-designer will steer
clear of such situations.[l.]
Summarizing once more:
AVOID UNFAVORABLE SETTINGS
Occasionally one encounters a System that seems to succeed—or at least
survive—in an Unfavorable Setting. The basis for such success seems to lie in
one or more paradoxical or extremely specialized features. The history of
attempts to master the rapids of the Colorado River in the Grand Canyon is
instructive in this regard. The first method to offer a reasonable chance of
survival, the Galloway Technique, consists—briefly, andin toto—of entering the
rapids backwards, stern first, and pulling with all strength in theupstream
direction.[c]The second and to date final advance in running the rapids came

with the use of very large rubber rafts, which, in effect, damp out the wildly
fluctuating parameters (waves).[m.]
Uphill Configurations: The S.L.O.G. Factor
If, despite all efforts at avoidance, it appears inevitable that a new System is
going to be designed and built, serious attention should be paid to the Systems
Law of Gravity (S.L.O.G.), otherwise known as the Vector Theory of Systems:
SYSTEMS RUN BEST WHEN DESIGNED TO RUN DOWNHILL
More briefly formulated:
AVOID UPHILL CONFIGURATIONS
—or, in the vernacular:
GO WITH THE FLOW
In human terms, this means workingwithhuman tendencies rather than against
them. For example, a State-run lottery flourishes even in times of economic
depression because its function is aligned with the basic human instinct to
gamble a small stake in hopes of a large reward. The Public School System, on
the other hand, although founded with the highest and most altruistic goals in
mind, remains in a state of chronic failure because it violates the principle of
spontaneity in human learning. It goes against the grain and therefore it does not
ever really succeed. It has made literacy universal, but not truly popular.
Looseness:
When Charles Babbage, early in the Nineteenth Century, attempted to build
the world’s first large calculating machine, he made the parts of wood and
promptly discovered the importance of Internal Friction. Briefly, his machine
wouldn’t go—and he couldn’t Push It hard enough to Make It Go without
breaking it (see Pushing On The System, Chapter 11). This was not a Planned
Discovery, and it was not one that Babbage enjoyed making. Nevertheless, the
experience taught Babbage (and us) that the System must not be built too tight
nor wound up too tightly or it will (1) seize up (2) peter out, or (3) fly apart:
LOOSE SYSTEMS LAST LONGER AND FUNCTION BETTER
Since most of modern life is lived in the interstices of large systems, it is of
practical importance to note that
LOOSE SYSTEMS HAVE LARGER INTERSTICES
and are therefore generally somewhat less hostile to human life forms than
tighter Systems.
As an example of a System attuned to the principles of Systems-design

enunciated thus far, consider the System of the Family. The Family has been
around for a long time. Our close primate relatives, the gorillas, form family
units consisting of husband and wife and one or more offspring. As Jane Goodall
has shown, gorillas take naps after meals. (Every day is Sunday for large
primates.) The youngsters wake up too soon, get bored and start monkeying
around the nest. Father gorilla eventually wakes up, leans on one elbow, and
fixes the errant youngster with a penetrating stare that speaks louder than words.
The offending juvenile thereupon stops his irritating hyperactivity, at least for a
few minutes.
Clearly, this is a functioning family System. Its immense survival power is
obvious. It has weathered vicissitudes compared to which the stresses of our own
day are trivial. And what are the sources of its strength? In brief: extreme
simplicity of structure; looseness in everyday functioning; “inefficiency” in the
efficiency-expert’s sense of the term; and a strong alignment with basic primate
motivations.
Bad Design:
The discovery that a large System, newly hatched, won’t fly, is always a
shock. There is a natural tendency to patch it up, to try tomake it go, by adding
new features, accessories, jury-rigged appendages, etc. This tendency must be
resisted. It is the equivalent, at the Design level, of Pushing On the System, and
it works about as poorly. Extending Gresham’s Law (Bad Money Drives Out
Good)[m] to its General Systems formulation, we conclude:
BAD DESIGN CAN RARELY BE OVERCOME BY MORE DESIGN,
WHETHER GOOD OR BAD
In Scientific Research, this Principle has been appreciated by a few perceptive
souls in the slogan:
ADDING NUMBERS TO A BAD STUDY DOESN’T CLARIFY IT
or, as enunciated by Spodick:[ci]
LARGE AMOUNTS OF POOR DATA TEND TO PREEMPT ANY AMOUNT
OF GOOD DATA
In the field of Computer Design, battle-scarred veterans understand Gresham’s
Law at a visceral level. So well have they learned their lesson that they follow
the only prudent course,[cii] the Bitter Bidding of Frederick Brooks:
PLAN TO SCRAP THE FIRST SYSTEM: YOU WILL ANYWAY
Bad design is sometimes apparent on simple inspection. An outstanding
example is the automobile. Built to travel at eighty miles per hour, it has

bumpers designed to withstand impact attwomiles per hour. Powerful brakes can
bring it to a screeching halt, but the occupants, unrestrained, continue to hurtle
forward, where a twelve-mile-an-hour impact with the windshield is fatal. The
rear-view mirror (a design unchanged in three generations) has a blind spot on
each flank large enough to hide a twenty-ton truck.
For bad design of truly grandiose proportions, one naturally examines
grandiose Systems. The Doomsday Airplane, for example, whose function is to
fly high above the radioactive debris of a stricken United States and transmit the
final orders to fire nuclear missiles, is equipped for this purpose with a special
radio antenna. Unfurled from the rear of the airplane, it is over five miles long,
weighs more than a ton, and tends to snap like a whip. A crew member can cut it
loose with a special pair of shears, thereby saving the airplane[n. ] but inhibiting
the war effort, as there is no spare.[ciii]
The point of the whole arrangement is obscure, as the submarine commanders
have their orders tofire anyway.
102

26. Catastrophe Theory[a.]
Avoiding Terminal Instability
In the lengthy Annals of Misadventure, few tales outrank that of the English
warship Mary Rose,pride of King Henry VIII. On Sunday, July 19, 1545, newly
outfitted with heavy bronze cannon on the upper decks in addition to the 91 guns
she was originally designed to carry, she sailed forth with the English fleet from
Portsmouth to meet the invading French. The day was bright, clear, almost
windless.
A breeze sprang up. TheMary Roseheeled over. The breeze freshened. She
heeled still farther. At that moment the King and other spectators realized with
awful clarity that the open gun ports had dipped under water and the sea was
rushing in.Mary Rosetipped still more, then sank.
Eighty-three years later, on August 10, 1628, the battleship Vasa,pride of King
Gustavus II Adolphus of Sweden and mightiest battleship ever built up to that
time, slid down the ways and into the calm waters of the bay at Stockholm. A
gentle breeze filled her sails. She heeled over. The breeze freshened. She heeled
still farther. At that moment the dignitaries on board realized—yes, with awful
clarity—that the open gun-ports weretaking in water. The sea poured in.
TheVasatipped still more, then sank.[civ]
Three hundred and fifty-some years later, not far from the same spot, on
another fine day in a calm sea, a two-billion-dollar floating oil-drilling platform
was cut loose from her seagoing tugs. With majestic disregard for man’s plans
and calculations, the rigslid beneath the waves and straight to the bottom, never
to rise again. TheVasa,like theMary Roseand the oil rig,was a victim
ofinstability, an affliction that can plague systems of any size from smallest to
largest.[cv]
A ship or an oil rig that sinks in fair weather is a pretty obvious case of
Unstable Design. A harder task is that of sailing those less tangible ships, the
large organizations that characterize our age. A sailboat floating with keel in air
adequately signals its problem. An organization sailing full speed ahead but
upside down, metaphorically speaking, may fail to attract any notice.
[b.]Corporate Mergers represent a special case, analogous in some aspects to the
welding together of two, three or more ships of differing size, purpose, and
speed, and attempting to navigate the resulting product.[cvi] We confine
ourselves to our earlier observation that basic laws of Systems-design and
management can rarely be flouted with impunity.

As the topic of sailing such entities is, properly speaking, a task of
Management, we shall defer further treatment to a later Chapter. However,
mindful of theVasa, we offer the following personal advice in the form of Edsel’s
Edifying Admonition:
DON’T PUT YOUR NAME ON IT UNTIL YOU ARE SURE IT WILL FLOAT
103

C. Management and Other Myths
104

27. Wishful Feedback
The Potemkin Village Effect
Our previous encounter with Czar Alexander and the Impotent Potentate
Syndrome has alerted us already to the pitfalls of Systems-management. Should
we actually find ourselves, against our better judgment, in a managerial or
executive position, we should remember the dread effects of the F.L.A.W., of
Hireling’s Hypnosis, and of the pervasive Systems-delusions. The combined
effect of these forces is such as to render very doubtful any form of Management
Science. If there is no way of being sure what the real effect of your managerial
actions has been, how can you know whether you have done well or ill?
The F.L.A.W. may even operate in such a way as to hide from the
Administrator the operation of the G.U.P. In such situations, the Administrator
sinks into complacency while the System careens from disaster to disaster. In
recognition of major Russian contributions to our experience of this
phenomenon, it is known as the Potemkin Village Effect. The P.V.E. is especially
pronounced in Five-Year Plans, which typically report sensational
overachievement during the first four and a half years, followed by a rash of
criminal trials of top officials and the announcement of a new and more
ambitious Five-Year Plan, starting from a baseline somewhatlowerthan that of
the preceding Plan, but withhigher goals.[a. ][cvii]
Output Phobia:
The P.V.E. is perhaps more common in those countries where there is a need
for showcase projects and where face-saving is an important social reality. The
more usual situation is that in which the System protects itself by not actually
producing anything and by not claiming to have produced anything, according to
the maxim:
OUTPUT IS DANGEROUS
—sometimes transcribed as:[cviii]
2 KEEP IT IN THE STUDY PHASE
The Suppressing of WASH-740:
Examples are legion. Our current favorite is the “WASH-740” Report,
authorized by the Atomic Energy Commission for the purpose of proving in
advance that nuclear power plants would not have serious accidents. When the
Report was submitted, the estimated risk was far too high for comfort. A second
Report was therefore commissioned, thereby Keeping It In The Study Phase. But

the second Report produced risk figures even worse than the first. At this point
the decision was made to Suppress the Report. A third estimate was sought from
another source, which (for a fee) obliged. Reviewing the 6 meltdowns that had
occurred in the 54 trials that had been conducted to date, that source estimated
the risk to be one in a hundred million. Requesting this third study was a tactical
error, as the reassuring figures arrived just in time for the meltdown sequence at
Three Mile Island.[cix]The conclusion that was drawn from all this was not that
Nuclear Power itself had emerged too soon from the Study Phase, but that
theStudyhad emerged too soon.[b.]
The P.V.E. at T.M.I.: Wishful Feedback:
At Three Mile Island, the alarm signal that indicated a valve stuck in the
“open” position was connected to the control panel in such a way that merely
pressing the “close” button was enough to silence the alarm signal, even when
the valve actually remained in the “open” position.[cx]That is to say, the control
panel was designed to register what the operatorwishedthe state of the System
might be, rather than what it actually was.[c. ]
Clearly, a System whose controls are so arranged is going to spend most of its
time deeply mired in the Potemkin Village Effect. As events get further and
further ahead of the System’s inappropriate responses, the Model of the
Universegenerated in the control room by such Wishful Feedback bears less and
less resemblance to outside reality. The Systemhallucinates its way to Terminal
Instability. In summary:
JUST CALLING IT “FEEDBACK” DOESN’T MEAN THAT IT HAS
ACTUALLY FED BACK
To speak precisely:
IT HASN’T FED BACK UNTIL THE SYSTEM CHANGES COURSE
Up to that point, it’s merely Sensory Input.
The Model of the Universe
The main control panel at Three Mile Island was equipped with more than six
hundredindicator dials, alarm signals, klaxons, sirens, and bells. But when they
all went off on that fateful day, no one could tellwhat had gone wrong. Six
hundred alarm signals clanging in unison did not add up to a comprehensible
picture of the problem.
We have already absorbed the sobering information that Reality Is What Is
Presented To The System, and (as a Corollary) that A System Is No Better Than
Its Sensory Organs. We now face the fact that those somber insights,
fundamental as they are, are not enough. They are necessary but not sufficient.

The Reality that is presented to the System must alsomake senseif the System is
to make an appropriate response. The Sensory Input must be organized into a
Model of the Universe that by its very shape suggests the appropriate response.
We summarize in the Face-of-the-Future Theorem:
IN DEALING WITH THE SHAPE OF THINGS TO COME, IT PAYS TO BE
GOOD AT RECOGNIZING SHAPES
106

28. Fear of Feedback
For those in charge of a large system, a main concern is often how to find a
stable configuration—preferably in the design stage. Once launched, the
pitching, bucking unstable system threatens to carry its riders into catastrophe,
and the efforts of one and all must be diverted away from trying to get useful
output and into the struggle for mere survival.
How to find stable configurations? A weighty problem, worthy of the most
ingenious Systems-student! The pioneer Cyberneticist, W. Ross Ashby, devoted
much of his book,Design for a Brain, to this topic.[cxi] Alas, clean, handy Rules
of Thumb for this topic are hard to come by. We offer here one such Rule, drawn
from Ashby’s own researches:
The Jell-O Principle:
WHEN EVERYTHING CORRELATES WITH EVERYTHING ELSE,
THINGS WILL NEVER SETTLE DOWN
The reader with an agricultural background may picture a flock of guinea hens
trying to settle down to sleep on a moonlit night. Every slight sound, every leaf
turning, sets off at least one fowl, which sets off the entire flock, which then
continues to set itself off in endless sequence until each and every member is too
sleepy to continue giving the alarm. If even one fowl remains alert enough to
cluck once, the entire process is triggered off again.[a.] No one, including the
weary farmer and his family, gets any sleep.[b.]
We trust that the analogy with a large flock of committee-members is obvious.
This type of massive, hair-trigger feedback with total-system involvement also
occurs in some human families, thus the appropriateness of Brinkley’s
Breakthrough:
TOGETHERNESS IS GREAT, BUT DON’T KNOCK GET-AWAY-NESS
Parkinson’sfamous observation that national governments falter when their
Privy Council exceeds eight persons is a special example of this Rule.[c.]
Clearly, total feedback is Not a Good Thing. Too much feedback can
overwhelm the response channels, leading to paralysis and inaction. Even in a
system designed to accept massive feedback (such as the human brain), if the
system is required to accommodate to all incoming data, equilibrium will never
be reached. The point of decision will be delayed indefinitely, and no action will
be taken.
Fear of Feedback

More commonly, the system is designed in blissful ignorance of how much
feedback is appropriate, or even of how much feedback there will be. Such
under-design leads promptly to a state of Fear of Feedback and thence, by wellknown psychological mechanisms, to a Systems-delusion in which the sources
of feedback are regarded as hostile, even dangerous, to the system.
The First Law of Systems-survival
In the infancy of mankind, kings could perhaps afford the luxury of Killing
the Bearer of Bad News. Today we regard this as a poor way of dealing with
needed but unwelcome information. Instead, we face reality and recognize the
First Law of Systems-Survival:
A SYSTEM THAT IGNORES FEEDBACK HAS ALREADY BEGUN THE
PROCESS OF TERMINAL INSTABILITY
This is not merely the expression of our personal bias. It is a general
cybernetic law. It cannot be repealed by those who dislike its implications. A
system that ignores feedback will eventually be shaken to pieces by repeated
violent contact with the environment it is trying to ignore.
True, responding adequately to feedback, particularly to undesired feedback
that makes unexpected demands upon the existing system, is a difficult and
taxing assignment. It demands initiative. Refusing to pay attention to feedback,
refusing to respond to it, is thus seen as a special form ofpassivity, as an attempt
to make the environment do the adjusting. To try to force the environment to
adjust to the system, rather than vice versa, is truly to get the cart before the
horse.
108

29. Feedback and the Future
“. . .progress is always a transcendence of what is obvious.”
—Alfred North Whitehead.[cxii]
Feedback must be reasonably prompt or, by the Basic Information Theorem,
what it brings us will be of little value. As Boulding has astutely remarked:[cxiii]
NATURE IS ONLY WISE WHEN FEEDBACKS ARE RAPID
Not only Nature, but Systems generally, cannot be wise when feedbacks are
unduly delayed. Feedback is likely to cause trouble if it is either too slow or too
prompt. It must be adjusted to the response rhythms of the system as well as to
the tempo of the actual events—a double restriction.
But however timely feedback may be, it has intrinsic limitations. It cannot
predict the future.
FEEDBACK ALWAYS GIVES A PICTURE OF THE PAST
Those who seek to use data (necessarily from the past) to enable them to
predict the future are evidently putting their faith in a Pseudo-theorem of
doubtful validity, named by Gerald Weinberg as The Axiom of Experience:
[cxiv]
THE FUTURE WILL BE LIKE THE PAST, BECAUSE, IN THE PAST, THE
FUTURE WAS LIKE THE PAST
As Professor Weinberg aptly notes, this is merely an article of faith. Or, as
Helen Harte has put it:[cxv]
The complexity consultants can no more predict the future than the clients
can.
Mindful of Chaos Theory, we propose our own Emendation:
THE FUTURE IS NO MORE PREDICTABLE NOW THAN IT WAS IN THE
PAST, BUT YOU CAN AT LEAST TAKE NOTE OF TRENDS
Escape from Predestination:
Of what use, then, is Feedback, if it cannot predict the future? To answer this,
we note that
WHEN THE SYSTEM ACTS, IT PARTICIPATES IN THE CREATION OF
THE FUTURE
—that is:
THE FUTURE IS PARTLY DETERMINED BY WHAT WE DO NOW

—and what we do can be more appropriate with up-to-date feedback.
Eventually the feedback we get is determined in part by how we responded
previously. The feedback we get is a kind of image of the behavior of our own
system, modified and reflected back to us in the behavior of the other system(s).
Pursuing this same topic with grim determination to see it out to the end, we
come at last to the realization that The System and that other System, its
Environment, are engaged in a dance with each other. The output of one is the
input of the other. We have at last reached the point of understanding what
Bateson meant by Co- evolution. The two (or more) systems dance together into
the future, each responding to the other, each helping to shape what both of them
are tobecome.
It’s at this point that genuine Leadership becomes relevant. The Leader sees
what his/her System can become. S/he has that image in mind. It’s not just a
matter of Data, it’s a matter of the Dream. With apologies to Emerson, a System
is more than the lengthened shadow of one man. It is the embodiment of a dream
—a thought, a wish, a hope—made real. A Leader is one who understands that
our Systems are only bounded by what we can dream.
Dreams and Nightmares
One may dream a nightmare. The resulting System then has a strong tendency
to be, or to become, a nightmare for others. As this is properly a topic of
Psychology, we limit ourselves to a single Example, drawn from a treasury of
many thousands, nay millions:
•Kaiser Wilhelmof Germany, when still a boy, on a visit to his uncle, the
King of England, saw the mighty English fleet and promptly dreamed of
having one of his own,like Uncle Bertie’s, only bigger.
Summary and Recapitulation:
Not just ourselves, but our Systems also, are such stuff as dreams are made on.
It behooves us to look to the quality of our dreams.
110

30. Catalytic Managership
Briefly, Catalytic Managershipis based on the premise thattrying to make
something happenis too ambitious and usually fails, resulting in a great deal of
wasted effort and lowered morale. On the other hand, it is sometimes possible
toremove obstaclesin the way of something happening. A great deal may then
occur with little effort on the part of the Manager, who nevertheless (and rightly)
gets a large part of the credit. The situation is similar to that of the lumberjack
who picks the key log from a log-jam, or the chemist who adds the final pinch of
reagent to an unstable mixture. But a warning is in order: Catalytic Managership
will only work if the System is so designed that something can actually happen
—a condition that commonly is not met.
Catalytic Managership has been practiced by leaders of genius throughout
recorded history. M. Gandhi is reported to have said: “There go my people. I
must find out where they are going, so I can lead them.”[a.] Choosing the correct
System is crucial for success in Catalytic Managership. Consider, for example,
the probable career of W. Churchill had he been Prime Minister of Albania,
Andorra, or Angola.
Utilization:
The principle underlying Catalytic Managership is that ofUtilization.Give a
normally bright toddler a new toy such as a ball and the toddler will chew it,
pound it, sit on it and quickly discover what it can be used for. The toddler will
then Utilize it for those purposes.
The astute Systems-Manager will do well to emulate the toddler. Any given
System has many functions which it can perform only poorly and a few that it
performs well. Our task, correctly understood, is to find out which tasks our
System performs well and use it for those. In summary, we recommend for
elegant Managership:[cxvi]
UTILIZE THE PRINCIPLE OF UTILIZATION
For those to whom this formula seems unduly abstract, we offer the following
Rule, drawn from the Engineering Profession:
(A) IF IT’S FOR DIGGING A HOLE IT SHOULD PROBABLY LOOK
SOMETHING LIKE A SHOVEL
(B) IF IT LOOKS LIKE A SHOVEL, TRY USING IT FOR DIGGING A HOLE
Unfortunately, most of the Systems we have to deal with in daily life are more
like the Civil Service than a shovel, and it is hard to know which end to grasp to

carry out which tasks. Skill in recognizing and grasping the appropriate handles
remains largely intuitive.
Careful study of Systemantics may be of some help.
111

31. The “Problem” Problem
For the practicing Systems-manager, a major pitfall lies in the realm of
Problems and Problem-solving. Systems can do many things, but one thing they
emphatically cannot do is to solve Problems. A System represents someone’s
solution to a Problem. The System itself does notsolveProblems. Yet, whenever a
particular problem is puzzling enough to be considered a Capital-P Problem,
people rush in to design Systems which, they hope, will solve that Problem.
Once a problem is recognized as a “Problem,” it undergoes a subtle
metamorphosis. Experts in the “Problem” area proceed to elaborate its
complexity. They design complex Systems to attack it. This approach guarantees
failure, at least for all but the most pedestrian tasks. The problem is a Problem
precisely because it is incorrectly conceptualized in the first place, and a large
System for studying and attacking the Problem merely locks in the erroneous
conceptualization into the minds of everyone concerned. What is required is not
a large System, but adifferent approach. Trying to design a System in the hope
that the System will somehow solve the Problem, rather than simply solving the
Problem in the first place, is to present oneself with two problems in place of
one.
A System that is sufficiently large, complex, and ambitious can reduce output
far below “random” levels, since everyone’s attention is now focused on making
the existing System (i.e., the wrong answer) work. Thus, a Federal Program to
Conquer Cancer may tie up all the competent researchers in the field, leaving the
Problem to be solved by someone else, typically a graduate student from the
University of Tasmania doing a little recreational entomology on her vacation.
Solutions usually come from people who see in the Problem only an interesting
puzzle, and whose qualifications would never satisfy a select committee.[a.]
•When Pasteur accepted the challenge of the French silk producers to
discover the cause of silkworm disease, he had never seen, much less
studied, a silkworm. He was not even a biologist.
•The Wrightbrothers, who built the first successful heavier-than-air
machine, werebicycle makers.
•The molecular structure of the gene—closest thing to the true “secret of
life”—was revealed through X-ray crystallography, a technique having little
to do with biology. And James Watson, who solved the puzzle, was not an
X-ray crystallographer. He was not even a chemist. Furthermore, he had
been refused a renewal of his research grant because his sponsors felt he

wasn’t sticking to the point.
•A fourteen-year-old farm boy, plowing long furrows in the earth of the
Great Plains, dreamed of sending pictures composed of closely-spaced rows
of radio waves. Philo Farnsworth invented television. A giant New York
corporation claimed the credit. (See Manager’s Mirage, Ch. 9)
As these examples make clear, great advances may be achieved by individuals
working essentially alone or in small teams. But what of the reverse situation?
What is the track record of large Systems designed for the express purpose of
solving a major problem? A decent respect for our predecessors prevents us from
dwelling upon the efforts of successive governmental administrations to
eradicate poverty, reduce crime, or even get the mail delivered on time. The
bankruptcy of the railroad System, already far advanced under private
management, has further accelerated with government assistance. And in the
field of Science, a famed research center recently screened over twenty thousand
different chemical substances, at great expense, for anti-cancer activity, with
negative results.[b.]
We conclude:
GREAT ADVANCES DO NOT COME OUT OF SYSTEMS DESIGNED TO
PRODUCE GREAT ADVANCES
—and furthermore:
COMPLICATED SYSTEMS PRODUCE COMPLICATED RESPONSES TO
PROBLEMS
—or, as stated by Ashby:[cxvii]
COMPLEX SYSTEMS HAVE COMPLEX BEHAVIORS
Indeed, it is clear from our discussion of Catalytic Managership that at best,
and under ideal conditions:
MAJOR ADVANCES TAKE PLACE BY FITS AND STARTS
Even more disastrous than the “Problem” approach to Problems is the “Crash”
approach, which combines the adverse dynamics of the “Problem” approach
with elements of Administrator’s Anxiety (Pushing On The System To Make It
Work) and plain hysteria. Under the pressures of such an approach, scientists
themselves (normally the most tranquil and reflective of people) may begin to
crack, cutting off tails and painting the skins of mice in desperate efforts to meet
the artificial but pressing goals of the System. The prevention of such disasters
clearly calls for Catalytic Managership of the highest order.
Remember, Students, the “Crash” approach tends to crash.[c. ][cxviii]

113

32. The Limits to Grandiosity
Anyone who has ever tried to manipulate a kaleidoscope in such a way as to
move the green triangle from left to right or from top to bottom has an intuitive
understanding of the twin Limit Theorems:
(A) YOU CAN’T CHANGE JUST ONE THING
—and at the other extreme:
(B) YOU CAN’T CHANGE EVERYTHING
Pragmatically, it is generally easier to aim at changing one or a few things at a
time and then work out the unexpected effects, than to go to the opposite
extreme. Attempting to correct everything in one grand design is appropriately
designated as Grandiosity. Without further apology we offer the following Rule:
A LITLE GRANDIOSITY GOES A LONG WAY
Although the field of Politics offers many striking examples of Grandiosity, it
should be stressed that Grandiosity is not limited to any one Party, nor is it the
prerogative of either Conservatives or Liberals. A Return To Basic Principles
may be as grandiose as any Five-Year Plan for the Creation of the New Socialist
Man. The diagnosis of Grandiosity is quite elegantly and strictly made on a
purely quantitative basis: How many features of the present System, and at what
level, are to be corrected at once? If more than three, the plan is grandiose and
will fail.
Perfectionism:
Legend has it that one of the lesser-known museums of Middle Eastern
Archeology contains an ancient baked brick from the city of Ur of theChaldees
upon which, five thousand years ago, a scribe had incised in cuneiform symbols
the cryptic message:[a.]
THE FINAL TRUTH IS JUST AROUND THE CORNER
Although the original author of this insight is unknown, the belief remains
alive to this day, being widely held with all the fixity of Revealed Religion, that
WHEN THE CURRENT REVISION IS COMPLETE, THE SYSTEM WILL
BE PERFECT
Alternatively:
PERFECTION CAN BE ACHIEVED ON THE DAY AFTER THE FINAL
DEADLINE
Needless to say, this idea, no matter how elegantly formulated, remains a

Delusion. The truth of the matter is summarized inPerfectionist’s Paradox:
IN DEALING WITH LARGE SYSTEMS, THE STRIVING FOR
PERFECTION IS A SERIOUS IMPERFECTION
—and one which convicts the striver ofunawarenessof paradox. Such a person
is not yet ready for serious Systems-coping. Only one who has endured and
survived the fiery furnace of actual immersion in large Systems can appreciate
the poignancy ofSurvivors’ Souffle (sometimes pronounced “Shuffle”):[b. ][cxix]
IF IT’S WORTH DOING AT ALL, IT’S WORTH DOING POORLY
Striving for Perfection produces a kind of tunnel-vision resembling a hypnotic
state. Absorbed in the pursuit of perfecting the System at hand, the striver has no
energy or attention left over for considering other, possibly better, ways of doing
the whole thing. The result is exemplified by the spectacle of Napoleon in
Moscow, with the fate of his Army and his Empire hanging in the balance,
spending his days and nights writing out the detailed regulations for the
administration of the Paris Opera; or Philip II of Spain, engrossed in the details
of administering his Empire, failing to notice that the rivers of gold pouring into
his Treasury from the New World were suffocating industry in Spain and thus
destroying the very basis of his power.[c. ][cxx]

FIGURE 8. ESCHEW GRANDIOSITY.
117

33. Disaster Control
Almost by definition, one is rarely privileged to “control” a disaster. Yet the
activity somewhat loosely referred to by this term is a substantial portion of
Management, perhaps the most important part. Nipping disasters in the bud,
limiting their effects, or, better yet, preventing them, is the mark of a truly
competent Manager. A Manager who can do this is worth his/her salt, even if
nothing else appears to have gotten done.
What is required is something that might be termed “imagination in
disaster”—something akin to the “imagination in evil” recommended by
Professor Jung[a. ][cxxi] [cxxii]—that is to say, the ability to visualize the many
routes of potential failure and to plug them in advance, without being paralyzed
by the multiple scenarios of disaster thus conjured up. It is the business of a good
Manager to ensure, by taking timely action in the real world, that scenarios of
disaster remain securely in the realm of Fantasy.
By exercising the requisite degree of Imagination in Disaster one might avoid,
for example, the placement of a toxic chemical manufacturing plant just upwind
of a city of 900,000 people, as in Bhopal, India, or nestled in a populous valley
with limited air circulation, as in Institute, West Virginia. At the humblest level
of design and management, one might be moved to plan that no single storage
tank contain enough agent to poison everyone, nor be so large that the assigned
crew could not control it in event of a failure. This requirement is summarized in
Minsky’s Admonition:[b. ][cxxiii][cxxiv]
IN ORDER TO SUCCEED IT IS NECESSARY TO KNOW HOW TO AVOID
THE MOST LIKELY WAYS TO FAIL
We have previously noted that Large Systems Seem To Have Goals of Their
Own, but that we humans can only guess as to what those goals might be. This
poses a special problem for the Administrator. As a guide to more educated
guessing we offer the following Runic Riddle, dredged up by Professor Jung
from the depths of his studies of the Collective Unconscious:[cxxv]
IF IT PUTS A WEAPON IN YOUR HAND, IT IS AIMING AT SOME KIND
OF VIOLENCE
Some of our more psychoanalytically-oriented colleagues have suggested that
the true goals of large Systems are drawn from the Collective Unconscious. We,
according to policy, decline to enter such murky waters. Instead, we limit
ourselves to a simple direct question:
Managers: Is your System putting a weapon in someone’s hands?

117

D. Intervention
118

34. Where’s the Problem?
No treatise on Systems would be complete without some mention of those
professional Systems-people who call themselves “change agents.” The belief
that constructive change in a System is possible throughdirect intervention is an
optimistic view that dies hard. The alert Systems-student will recognize this as
the common psychological phenomenon ofdenial of unpleasant reality. In fact, it
may be viewed as a classic example of aSystems-delusion. Even more insidious,
however, is the implicit assumptionthat there is (somewhere) aScience of
Systems-interventionwhich any diligent pupil can master, thereby achieving
Competence to intervene here and there in Systems large and small, with results
objectively verifiable and of consistent benefit to mankind. Such a belief is
clearly in conflict with the Generalized Uncertainty Principle.[a.]
We do not take an absolutely pessimistic stand. It is possible, we believe, to
exert some limited influence on large Systems. But we resolutely assert that any
such influence must occur within the framework of, and in accordance with, the
general laws of Systems-function enunciated in this Treatise.
The work of change-agents is made enormously more delicate and uncertain
by the fact that the mere presence of a change agent (recognizable as such) has
about the same effect on an organization as an efficiency expertseen strolling
across the factory floor with stopwatch in hand: it promptly induces bizarre and
unpredictable alterations in the behavior of the System as the System begins to
Kick Back against real or imagined intrusions upon its current equilibrium.
Because of this effect, anyone who identifies him/herself publicly as a “change
agent” is self-convicted of incompetence. Changes will certainly occur as a
result, but they are not likely to be the changes desired.
Systems Are Like That: Parts Versus Whole
An Airplane has been defined as a collection of parts having an inherent
tendency to fall to earth, and requiring constant effort and supervision to stave
off that outcome. The System called “airplane” may have been designed to fly,
but the parts don’t share that tendency. In fact, they share the opposite tendency.
And the System will fly—if at all—only as a System.
Needless to say, this discussion is not restricted to airplanes, and the idea of an
airplane was introduced only to make palatable an otherwise somewhat
distasteful but necessary understanding. Our point is thatSystems are like that:
that is to say, their parts are unlikely to share, as parts, any tendency to
spontaneously do what the System is designed to do. If we add that most of the

parts are needed primarily as correctives to the vicious tendencies of other parts,
the analogy is even more precise.
Eating the Menu Card; or, Errors of Logical Level
This simple but elusive distinction—between the Parts and the Whole—has
caused endless difficulty down through the ages. It seems clear enough that
changing actors does not improve the dialogue of a play, nor can it influence the
outcome. Punishing the actors is equally ineffective. Control of such matters lies
at the level of the script, not at the level of the actors. In general, and as a
minimal requirement:
IN ORDER TO BE EFFECTIVE, AN INTERVENTION MUST INTRODUCE
A CHANGE AT THE CORRECT LOGICAL LEVEL[cxxvi]
Unfortunately, the human mind seems to be so constituted that Stepping Up
and Down the Ladder of Logical Levels is only achieved with great reluctance
and difficulty. History, not to speak of current affairs, is replete with examples of
failure to make the elementary distinction between one level and another. Stated
otherwise, our Problem will remain intractable until we first solve the Metaproblem entitled, “Where’s the Problem?”; i.e., until we have correctly located
the Problem on the Ladder of Logical Levels:
IF YOUR PROBLEM SEEMS UNSOLVABLE, CONSIDER THAT YOU MAY
HAVE A META-PROBLEM
In what follows, we shall consider three logical possibilities:
(1) that the Problem lies in the inadequacy of our own efforts to elicit the
desired behavior from our System (“The Problem in the Probe”);
(2) that the Problem is in fact a consequence of the correct (designed-in)
functioning of our System (“The Problem in the Solution”);
(3) that the Problem lies in an inadequate formulation of the Problem in the
first place (“The Problem in the Question”).
120

35. Probing the System
The Laboratory Rat Scandal:
The scientific world had hardly recovered from the announcement of the
Harvard Law of Animal Behavior when it was rocked by another sensation. This
was the realization that the common laboratory rat does not stop poking its nose
into boxes just because some of them are wired with electric shocks. In fact, the
occurrence of a shock causes it to explore even more urgently than before. Since
modern learning theory is based upon the dogma (or article of faith) that
creatures quickly learn to avoid painful stimuli, this behavior is nothing less than
a scandal. However, from the rat’s point of view, it is clearly important to learn
which boxes are safe and which are not. The rat, never having been instructed in
modernlearning theory, simply acts according to its own best interests as it
perceives those interests.[a.]Itprobes its environmentin order to learn the
operating characteristics of the System it is in.[cxxvii]
To call such behavior “trial and error” is merely to reveal our own
misapprehension of what the rat is doing. Exploratory behavior constitutes a
series of probes, each of which elicits a piece of behavior from the System. The
accumulation of those pieces of behavior allows the rat (or person) eventually to
obtain a perspective as to the range of behaviors the System is capable of
exhibiting in response to typical probing behaviors. If we are sufficiently
ingenious in the design of new probes, we may elicit something like the desired
outcome. We have encountered this strategy before. It is our old friend, the
Principle of Utilization.
Shall we then imitate the rat in our approach to understanding large Systems?
Of course. Like the rat, we must continue to probe. If we continue to probe, we
may get what we want. If we do not generate new probes, we certainly will not
get what we want. This Principle, known in Cybernetics as The Law of Requisite
Variety, states that, in any System:
CONTROL IS EXERCISED BY THE ELEMENT WITH THE GREATEST
VARIETY OF BEHAVIORAL RESPONSES[cxxviii]
With this Law in mind, some well-intentioned Cyberneticists have proposed a
Rule of Thumb, known as von Foerster’s Ethical Imperative:
ALWAYS ACT SO AS TO INCREASE YOUR OPTIONS[cxxix]
Unfortunately, this Rule is approximately equivalent to the classic advice
given to the mouse community tobell the cat. It’s all very well if you can do it.
One might as well advise:

ALWAYS MAKE CORRECT DECISIONS
What we, as students of Systemantics, aim for, is less grandiose, more
humble. We are grateful if we can avoid the error of drastically limiting our
future options. And we are not surprised to learn that the Probing System, too,
has its limits and exacts its price, as follows.
Cubology:
All over the world, millions of devotees[b] are twisting Rubik’s Cube® , a
“toy”that asks no more than the alignment of certain colored faces on a cube
composed of 26 smaller cubes mounted on a central core. For our purposes, what
is important about the Cube is that, given any specified starting configuration,
most other configurations are completely impossible[c. ] no matter how
ingeniously nor how long the Cube is twisted. You have to start over from a
different initial state.[cxxx] In other words:
IN THE MAJORITY OF CASES, YOU CAN’T GET THERE FROM HERE
—or, in language more directly relevant to our present approach:
PROBING WILL GET YOU ONLY SO FAR
Even if the starting configuration is one for which ultimate success is possible,
a further discouraging feature awaits the tyro Cubologist, who, in order to reach
the goal, must repeatedly undo almost completely whatwas achieved up to that
point.[cxxxi]Thus,over large stretches of the course, one must appear to be
progressing backwards.[c. ][cxxxii]
We cite this sobering example at the very outset of our discussion of
Interventions in order to dispel any notion of facility or slickness in dealing with
complex Systems. As usual, our tack will be to emphasize whatcannotbe done in
order to avoid the futility of struggling against Natural Laws of Systems, with
resultant waste of energy.
When is the probing phase finished? When is our picture of the System
complete? When have we elicited the total response repertoire of the System?
Merely to ask these questions is to realize the stark and depressing reality: that
the answer is, “Never.” Never can we say with any assurance, “This is the
complete list of possible behaviors of this System.” Such an assertion would
imply that all possible probes had been tried out under all conceivable
circumstances. No, students. Once more we encounter the limitations imposed
by Reality itself. We cannot know all the potential behaviors of the System.
We needn’t have been surprised. After all, we have encountered this fact
before, in different guises, in the Generalized Uncertainty Principle, in the
Kantian Hypothesis, and elsewhere. The feature of a Limitation is that one keeps

bumping up against it. And the distinguishing mark of the resolute Systemsstudent is the determination to make the most of what can be done, given the
limitations of reality.

FIGURE 9. THE SYSTEM IS ALTERED BY THE PROBE USED TO
TEST IT.
130

36. The Problem in the Solution
The Observer Effect
We have already noted the unpredictable, sometimes almost hysterical,
response of a System to the mere appearance of a Change Agent or Efficiency
Expert upon the scene. Vast and previously unsuspected reserves of Anergy are
suddenly mobilized and made available for preservation of the Status Quo.
Though known and deplored since ancient times, this effect has only in our own
day received the scientific study it deserves. In a famous experiment conducted
less than a year after Heisenberg’s (1925) enunciation of the Principle of
Indeterminacy, Winnie- the-Pooh (1926) probed the depths of his honey-potto be
certain that it was truly honey within, all the way to the bottom. The probe was
successful. On completion of the probing, however, the honey-pot nolonger
contained honey. Furthermore, Pooh’s head was stuck in the pot.[cxxxiii]
We conclude, with Pooh and Heisenberg:
THE SYSTEM IS ALTERED BY THE PROBE USED TO TEST IT
—and, mindful of Pooh’s head, we add:
THE PROBE IS ALTERED ALSO
Unfortunately, the experience of Pooh was not reported in those prestigious
journals that sway the thinking of scientists and it was therefore largely ignored.
Nevertheless, the Observer Effect would not Go Away. It Persisted, it
Encroached. And as probes became more sophisticated, it Expanded to Fill the
Observable Universe. When pioneering Primate researchers looked through the
peephole of the cage and saw a large round eye staring back, they were made
uneasily aware of the Observer Effect. And when Anthropologists began to
study tribes in their native habitats, they increasingly began to notice that the
typical New Guinea family consisted of father, mother, three children, and one or
more Anthropologists. In brief, there can be:
NO SYSTEM WITHOUT ITS OBSERVER
and
NO OBSERVATION WITHOUT ITS EFFECTS
Systems and Self-Reference:
We have previously noted that Systems do not solve problems; they represent
attempted solutions. But even today one still occasionally hears a slogan,
asserted as if it were a genuine Systems-Axiom, to the effect that:

IF YOU ARE NOT PART OF THE SOLUTION, YOU ARE PART OF THE
PROBLEM
—Catchy, but specious. The correct form of the Theorem is as follows:
THE SOLUTION IS OFTEN PART OF THE PROBLEM
—and usually the hardest part, we might add. Were it not for that elusive
beast, the Problem-in-the-Solution, the task of troubleshooting complex Systems
might eventually become a matter of checking lists in a Technical Manual. Let
us, therefore, take a closer look at the example we have just cited from Primate
Studies:
PRIMATE PEEPER PEEPS, SEES PRIMATE PEEPING AT PRIMATE
PEEPER
Stated thus, the self-referential quality of the interaction is apparent[cxxxiv]
[cxxxv]
Self-reference is often signaled by a momentary confusion or double-take, a
fleeting urge to laugh, or a feeling of exasperation that somehow just fails to
come to a specific focus. We (or some of us) feel it on being asked to watch a
movieentitled THE MOVIES. The feeling returns in force when our television
schedule announces a special programentitled “TV Guide—the First 25
Years.”[cxxxvi]
Now, when a Primatologist observes Primate behavior, there is one piece of
behavior that the Primatologist doesnotwant to observe and that is the Primate
observing the Observer as the Observer tries to observe the Primate. That sort of
thing Gets In The Way. And if escalating the effort to observe merely escalates
the Primate’s level of observing the Observer, the System has gotten locked into
a Positive Feedback Trap, where Trying Harder merely produces more of the
unwanted behavior—on both sides.
Example:
When a freshman college student fails several courses the first semester, it is
assumed, generally with reason, that s/he does not know how to study. With
impeccable logic, administrators have therefore set up college courses in HOW
TO STUDY. Typically such courses follow the standard format of college
courses, with lectures, reading assignments, and a measure of performance such
as a letter or numerical grade.
In such a setting, predictably, substantial numbers of students fail their course
in HOW TO STUDY. After all, they don’t know how to study. Since this is
usually a credit course, the standard rules apply: the student who fails HOW TO
STUDY is entitled to take the make-up course, REMEDIAL HOW TO STUDY.

Since this is also a credit course. . . the student eventually becomes entitled to
take REMEDIAL REMEDIAL. At some point the students (and perhaps also the
Professor) may feel that they have become trapped in a hall of mirrors, a
situation of infinite regress.Designed to help them, the System now locks them in
perpetual failure.
Lest the reader conclude that this is fanciful and unrealistic, we end with a
quotation from the Blue Ribbon Committee on Excellence in Education, whose
report, published in 1983, states: “Remedial math courses now constitute 25% of
all college mathematics.”[cxxxvii]
Even a small System that becomes significantly self-referentialis in for
trouble. The parent who urges a sleepless child to “try harder” to get to sleep
may fail to realize that “trying harder” makes getting to sleepmore difficult, not
easier. At this point one has created a small System called “trying to get to sleep”
in which the functioning of the System (i.e., trying, etc.) produces wakefulness,
not sleep. The stage is now set for the Systems-delusion that past failures are the
result of Not Trying Hard Enough, or—worse yet—are Somebody’s Fault. Such
a Delusion leads directly to Escalation, which, in theory at least, can progress to
the point of Meltdown and Explosive Release of Poisonous Vapors.
We therefore advise, when Systems malfunction:
LOOK FOR THE SELF-REFERENTIAL POINT—THAT’S WHERE THE
PROBLEM IS LIKELY TO BE
—or, more succinctly:
STAY AWAY FROM SELF-REFERENCE—THIS MEANS YOU
We are now in better position to comprehend the paradoxical aspect of some
of the Horrible Examples cited throughout this book:
•Aswan Dam generates increased need for electricity.
•Government of Haiti requires emergency assistance in filling out requests
for emergency assistance.
•Large space-rocket shelters produce own weather hazards.
•Safety equipment now a major source of sports injuries.
These are Systems that have become self-referential in a big way. The most
poignant example, of course, is in the field of Nuclear Weaponry, where the
danger of nuclear destruction exists because—and only because—the nations of
the world have armed themselves with nuclear weapons in order to prevent—
nuclear destruction.
The following assertion deserves special attention:

THIS SYSTEM IS THE ONLY CORRECT SYSTEM
The Student who has followed our reasoning to this point will promptly
recognize that this statement is both self-referential and a Systems-delusion.
There is no way, within the framework of the System in question, that this
statement can be corrected. It is liable to produce a Runaway at any moment.[c.]
The Nasal Spray Effect:
The universal experience of Mankind has been that, after the Rascals get
Thrown Out, only a short time elapses before the new office-holders begin to
look like a fresh set of Rascals. Clearly, this kind of change is only a change of
actors.
Failure of such “reform” to produce the desired effect leads to various types of
delusional behavior. A Scapegoat may be identified and blamed for the fiasco.
More commonly, failure is ascribed to lack of vigor in carrying out the reform;
i.e., the failure is considered to be due to too little of the erroneous remedy being
applied. The corrective prescription is thereforeMore Of The Same; that is, to
Escalate. [cxxxviii][d.]
At this point the reformers are locked into a vicious circle. Each new
catastrophe is no longer a signal that the policy isn’t working; rather, it becomes
the occasion for a demand for redoubled vigor in the application of the failing
remedy. The System makes ever more escalated lunges toward the ever-receding
goal. The Solution has become part of the Problem.
We have encountered this process before. It is our old friend, Positive
Feedback.
IF THINGS SEEM TO BE GETTING WORSE EVEN FASTER THAN
USUAL, CONSIDER THAT THE REMEDY MAY BE AT FAULT
—or, more succinctly:
STAY OUT OF THE POSITIVE FEEDBACK TRAP
This phenomenon will be referred to as the Nasal Spray Effect in tribute to the
millions of hay fever and “sinus” sufferers the world over who use nasal sprays
to shrink their stuffy noses, only to discover that the rebound stuffiness that
occurs when the spray wears off is worse than the original stuffiness.
In the modern world some reformers, exasperated by their inability to produce
lasting change by this method, have escalated to the level of Terrorism, where
they continue to prove again and again that
ESCALATING THE WRONG SOLUTION DOES NOT IMPROVE THE
OUTCOME

—or more briefly, that the Nasal Spray Effect cannot be cured by using more
nasal spray.
Finding the Thermostat
Let us imagine a native of Tierra del Fuego transported to the lobby of a
modern, air-conditioned hotel in a large city. Fuegians are used to living in a
very cold climate. They are in the habit of carrying fire around with them to keep
warm. As our Fuegianenters the lobby of the air-conditioned hotel, he feels
chilly, so he puts his fire in the middle of the lobby and adds a few sticks of
wood. For a moment he feels warmer, but the fire triggers the thermostat in the
lobby and the air-conditioning goes on “high.” The Fuegian shivers and adds
more wood to his fire. The air-conditioning goes even higher. Icicles begin to
form on the chandelier, our subject shivers even more and begins to break up the
furniture in the lobby to make a real bonfire. What he is experiencing, from his
point of view, is that in big citiesfires make you cold, and bigger fires make you
colder.
We hasten to add that, empirically speaking, the Fuegian is right. Under the
circumstances described, fires do make you cold, and the bigger the fire the
colder you get. Commonsense cause-and-effect has been suspended.
Borrowing somewhat freely from Quantum Mechanics, we designate this
effect as Strangeness [c.], and we propose that the presence of Strangeness
provides a pragmatic guide to the locus of the problem:
IF THINGS ARE ACTING VERY STRANGELY, CONSIDER THAT YOU
MAY BE IN A FEEDBACK SITUATION
Alternatively:
WHEN PROBLEMS DON’T YIELD TO COMMONSENSE SOLUTIONS,
LOOK FOR THE THERMOSTAT
Finally, to integrate this with our previous knowledge, we observe that a
thermostat is the point at which Self-reference is deliberately designed into the
System.
Examples of Strangeness can be found all around us. A little practice in
identifying them is all that is needed: soon they will be recognized everywhere.
•A classic example is provided by the so-called Green Revolution, which,
by using high technology to increase the amount of food grown per acre in
Third World countries, has made it possible for large fractions of the human
race to starveat much higher levels of population densitythan were
previously attainable. [cxxxix][cxl]In such settings, the provision of more
food merely allows the population to grow until people are again starving.

What is needed is todisengage the thermostat, in this case the linkage
between nutritional status and reproductive rate.
•Again: as cities grow larger, commuters must travel farther and faster to
reach the pleasant suburbs where they like to live. More cars and trains are
needed to carry them. The Transportation System must expand, and as it
grows, the city necessarily grows, too—thus increasing the need for more
and faster trains and cars traveling even farther to get to the ever-receding
suburbs.
•In the field ofMedicine: Researchers must race to invent an unending series
of new antibiotics to fight off supermicrobes that have become resistant to
all the old ones.
•And inEcology: New and ever more elaborate sheltered environments must
be developed to keep alive fragile species that can no longer survive in the
wild.
Recognition that room temperature is controlled by a thermostat and that the
action in a play is controlled by the script, may lead the student to inquire:
perhaps, then, the key to mastery of Systems lies in finding the Control Unit?
Alas! Would that the situation were so simple! In this respect, the simplified
examples we have chosen for illustrative purposes are misleading. More typical
is the example of a Family System, in which the control function is distributed
amongst the family members, each member having some degree of control over
the others, the particular degree varying with respect to differing activities as
well as with a variety of other factors.
How, then, can one influence a control function that is neither here nor there,
so to speak, but more or less everywhere in the System? To address this knottiest
of problems, we move on to our final encounter, in which we shall grapple with
the context, or Frame of Reference, within which the System iscomprehended.

FIGURE 10. WATCH OUT FOR SELF-REFERENCE.
130

37. Taming Systems
Despite the built-in difficulties of Change-agentry, there are a few examples
on record of situations in which a recalcitrant System has beenTamed, i.e., the
worst features of its behavior have been tempered so as to produce a tolerable
result. How such interventions have come about is not at all clear. Most are
shrouded in the obscurity of the distant past. What is clear is that the remedy
must strike deeply at the roots of the System itself in order to produce any
significant effect. Furthermore, an uncanny element of Paradox is prominent in
the few examples so far reported. Thus, the long survival of the British
Monarchy is probably attributable to the fact that the King reignsbut does
notrule. The cohesion of the far-flung Dominions of the Empire is based on the
paradoxical fact of Voluntary Association. Previously acquired by force of arms,
Dominions are now required to submit applications in order to get in.
An even more challenging example is the TOKEN SYSTEM, with which
mankind has been having trouble ever since the Phoenicians invented it. K.
Marxwas perhaps the first to point out its defectsas a System, thereby qualifying
himself as a pioneer Systems-thinker.
Now the Token System itself had evolved as a solution for the problems
connected with the earlier System of Barter. It was designed specifically to
alleviate the inconvenience of trying to carry around loose change in the form of
live animals and of trying to decide how many clay pots are equal to one heifer.
But the Token System soon revealed problems of its own, intrinsic to the nature
of the new System and not to be eliminated by superficial remedies. Collecting
Tokens began to assume the proportions of a craze. People now struggled, not
for cattle or crops, but for Tokens. And aptitude for collecting the Tokens was
found to correlate poorly with farming ability, or with anything else, for that
matter. The Token System began to Encroach, to Expand to Fill the Known
Universe. And as it grew, it Acted Up, Kicked Back, and Began to Fail in strange
and unexpected ways. The Modern Age had begun.
A recital of the schemes devised by Mankind to correct, or at least to
neutralize, these intrinsic difficulties makes tedious and depressing reading
indeed. There are some who go so far as to assert that Modern History is mainly
the story of those efforts. Governments everywhere, whether capitalist, socialist,
or communist, have struggled to Tame the Token System. Only one society,
located in a far-off corner of the world, has had the imagination and daring to
achieve success in this effort. For the sake of our industrial civilization, sunk in
the miseries of the operation of the Token System, we here present our findings.

On the Island of Yap in the South Pacific, money is in the form of stone
coins, as big as cartwheels, with a hole in the center. The value of a coin is
based, not on size, but on the number of people who died bringing it across
the open sea, lashed to the bow of a frail canoe, from the limestone quarries
of the Island of Palau, 250 miles away from Yap.[cxli]
No Yapese person can reasonably hope to accumulate any large number of
such coins. In fact, whenpossessionof a coin changes, thepositionof the coin
itself does not change. It continues to lie wherever it has always lain, along a
path or on the edge of a village. Only the abstract title changes, and nothing of
consequence has changed for the Yapese people. Clearly, there is no problem of
theft or of hoarding. The assignment of value on the basis of men lost on the
journey is an additional stroke of genius. The coin cannot be used as a symbolic
substitute for human labor. It does not represent so many coconuts collected, so
many pounds of copra produced, or so many head of cattle or chickens. No one
can, by accumulating tokens, hold the community to ransom.
Critics may argue that this cure of the faults of the Token System is too radical
—that by depriving coinage of the two attributes of portability and symbolic
representation of human labor, the Yapese have in fact demonetized their
currency, so that it is no longer money. Against this hyperfine argument we place
the simple observation that everyone, everywhere immediately recognizes the
Yapese coins for what they are—real money. It will take more than the quibbles
of specialists to convince average people that what they see with their own eyes
is not the truth.

132

38. The Problem in the Question
A Monetary System in which coins are as large as cartwheels, have prestige
value only, and can only be collected by a long and dangerous canoe trip over
the open ocean is unlikely to generate the usual types of response. In such a
System, people willthink, feel and actdifferently. Stated otherwise, people’s
Mental Model of the System will be different, and their Behavioral Response
will be different.
Changing the System so that people will think, feel, and behave differently is,
of course, what we are interested in at this point. But as we have just seen,
actually changing the structure of the System so as to Tame it is a difficult and
rather obscure art. Could one perhaps bypass that difficult sequence, going
directly to the Mental Model within people’s heads and changingthatwithout
doing anything physical to the System itself?
We begin with a Transitional Example:
Shortly after a rescue team had drilled a deep borehole to provide safe
drinking water for a village in Ethiopia, the team was dismayed to learn that
the borehole was being repeatedly vandalized by being filled with rocks.
Previously, certain men of the village had made their livelihood by carrying
water from a distant waterhole in skin containers on the backs of donkeys.
Now they were out of a job. When those men were appointed as guardians
of the new borehole, at a good salary, the vandalism ceased.[cxlii]
In the old Model of the Universe, the men had been “criminals” and
“vandals.” In the New Model, they were “policemen.” A small change in the
actual structure of the System had caused a very significant change in the Mental
Model held by the participants, and thus in their behavior.
We are now ready to consider the case of a purely mental restructuring of the
System, in which the only change is in the Mental Model. We begin with a
deliberately simplified Example; the case of a Jet Pilotwhose plane breaks
through the clouds on approach to a strange airport at an unfamiliar destination.
The pilot is suddenly faced with the problem of putting down his plane on a
runway fifty feet long and half a mile wide. As we have previously noted, [a.]
until the pilot solves the Meta-problem of restating his Problem in solvable
terms, he will experience some frustration.
Clearly, the Airport System, existing OUT THERE in the form of concrete
runways, tower, personnel, etc., does not change one iota as the pilot ponders his
dilemma. But in the moment when the pilot reorganizes his perception of the

System—when he revamps the Model of the Universe IN HERE, inside his own
head—in that moment his problem is resolved. What is needed is a new Model
—in this case achieved by simply rotating the old Model by ninety degrees.
The actual moment of shifting from one Model of the Universe to another is
highly unsettling. There is a pronounced sense of disorientation, which is only
relieved when the new Frame of Referenceclicks into place. In the next moment
the old Frame is so thoroughly suppressed that we usually can’t retrieve it even
if we try—but of course we don’t want to try. Who wants to look at the world
through the eyes of old error and illusion? And as for the possibility that
thenewModel will ever be rejected as error and illusion—how could that be?
This is the way the world is. And so itis—until the next time.[cxliii]
Creative Reframing (The Joy of Sets):
The old understanding was a metaphor; the new frame is also a metaphor.
Creative reframing is the art of substituting useful metaphors for limiting
metaphors.
Many years ago Abraham Lincoln observed that the best way to get rid of
one’s enemies is to make friends of them. This observation has been wrongly
regarded as merely another example of Lincoln’s charitable nature and for that
reason has failed to achieve recognition for the major intellectual contribution
that it is. What is involved here is the concept called Reframing. If any
intellectual tool offers hope of providing some degree of active mastery of
systems, this is it. But it is subtle, even more subtle than the Operational Fallacy,
which is strictly speaking but one example of it. Let us therefore familiarize
ourselves with this concept by our usual method of studying striking examples:
•At the Congress of Vienna in 1815, when the Great Powers met to decide
how to punish France for a generation of aggressions against Europe, the
French Foreign Minister Talleyrand pointed out that France was just one
more victimof Napoleonic oppression. Indeed, France was the one who had
suffered the most and therefore, he insisted, she should be treated as an
equal party to the Congress.[cxliv]
The Great Powers were momentarily upset by this demand. What? Give up
the opportunity to punish the aggressor and force reparations? But as they
thought about what Talleyrand was saying, they realized that he was only
pointing out to them the truth of the situation. Whereas earlier they had been
wandering in error, attempting to cope with the situation on the basis of a
misconception, they now understood correctly. Talleyrand had graciously
provided them with the new insight. They had been irritated at first, but that was
before they understood. They should feel grateful to him for his patience in

explaining it to them. In fact, theyweregrateful.
Thus did it come about that the Congress of Vienna concentrated its attention
onrestoring the legitimate rightsofallthe European powers— including France—
rather than on “punishing” the entity called “France.”
•Half a century later, Bismarck, the ultraconservative Iron Chancellor of
Germany, was unalterably opposed to anything that smacked of Socialism.
But when someone pointed out to him that a million loyal Civil Servants
represented a Standing Army in disguise, he bought the whole thing,
including sickness benefits and pensions.
As these examples demonstrate, a successful Reframing has the power to
invalidate such intractable labels as “crime”, “criminal,” “oppressor,”
“aggressor,” “socialism,” and “vandalism,” and to render them as obsolete and
irrelevant as “phlogiston” in Chemistry or “ether” in Modern Physics.
When Reframing is complete, the Problem is not “solved”—it doesn’t even
exist any more. There is no longer any Problem to discuss, let alone a Solution.
In the fleeting moment of transition from the old Model to the New, one has a
brief opportunity to realize consciously what most of us seldom think about,
namely, that labels such as the above areartifactsof terminology, not permanent
attributes of the Universe or of Human Nature. With that awareness we are no
longer locked into models that offer no solution. We are free to seek out ever
more appropriate Models of the Universe.[cxlv]
What has been said so far could be summarized in one deceptively simple
Rule of Thumb:
IF YOU CAN’T CHANGE THE SYSTEM, CHANGE THE FRAME—IT
COMES TO THE SAME THING
But a word of warning is in order. The novice Reframer, having discovered
the hammer, so to speak, is likely to consider that almost everything needs
hammering. This tendency should be resisted. We do not deny that occasionally
one may encounter—or, even more happily, initiate—a successful Reframing.
But we insist resolutely upon the Reality Principle, which states that such
occurrences are the exception, not the rule. Tempered,moderatepessimism is the
hallmark of the seasoned Systems-student.
In practice, truly suitable new Frames remain elusive. There is no surefire
program for devising them. Even mathematicians do not understand how it
comes about that they suddenly “see” the elegant way to solve a problem. There
is no formula for creativity other than the mandate, “Be creative!” Nor can our
computers surpass us in this respect unless we can teach them what we ourselves

do not know—a difficult task. In brief:
THE AUTOMATIC PILOT IS NOT MUCH HELP WITH HIGHJACKERS
Furthermore, the old System may stubbornlyresistthe new Frame, even when
it is clearly superior. Thus, Napoleon turned out to be incapable of understanding
that the term “enemy” is merely a provisional attribution, applicable perhaps in
one Frame of Reference but not necessarily in others. He could not get it through
his head that there was no need to actually liquidate the government and armies
of Austria—that they would be splendid allies under the right conditions, and
essential, as well, to the stability of a postwar Europe. More briefly stated:
Talleyrand could reframe the entire Congress of Vienna, but (on this one point at
least) he could not reframe Napoleon.
The Use and Misuse of Reframing
The Sorcerer’s Apprentice (in one version looking remarkably like Mickey
Mouse) peers into his master’s book of Magical Incantations for something to
help him get his chores done. Using his newly acquired power, he commands
bucket and mop to perform, only to realize, too late, that he can’t stop them. The
resulting flood is monumental, catastrophic.
It would be wise to keep this story in mind as one considers the uses of
Reframing. Reframing is a powerful tool, difficult to activate in just the desired
way and probably impossible to stop once set in motion.
The proposed Reframing must be genuinely beneficial to all parties or it will
produce a destructive Kickback. A purported Reframing which is in reality an
attempt to exploit will inevitably be recognized as such sooner or later. The
System will go into Defense Mode and all future attempts to communicate will
be viewed as attempts to exploit, even when not so motivated (Systemsparanoia).
No, students. The technique of Reframing, as powerful as it is, is not a
panacea. It is still a System and as such is subject to all the Laws expounded in
this Text, plus, no doubt, others yet undiscovered. It will be found by actual
experience to Act Up, Kick Back, and Fail Unexpectedly just as insidiously and
as enthusiastically as any other System. But within those limitations, it does
offer the power to move constructively into areas hitherto considered
unapproachable.
If diligently practiced and wisely used, it can permit a new and higher level of
competence in dealing with Systems.
135

39. The Net of Indra
In Hindu legend the Net of Indra is infinitely large. At every intersection of
the meshes of the net is a precious jewel. The net consists of an infinity of
precious jewels, each of which reflects the entire net, including theinfinity of
other jewels.[cxlvi]We believe the Hindu sages were trying to give expression to
a fundamental principle of Systems-thinking, as follows:
ANY GIVEN ELEMENT OF ONE SYSTEM IS SIMULTANEOUSLY AN
ELEMENT IN AN INFINITY OF OTHER SYSTEMS
Having digested or otherwise accommodated this morsel of insight into our
own System of comprehending the universe, we can sympathize with the
sophomore college student who is still reeling from the realization that
EVERYTHING CORRELATES
—but as dedicated Systems-students we are obliged to struggle on to the next
insight, namely:
THERE IS NO SUCH THING AS NONINVOLVEMENT
At the very least,
NONINVOLVEMENT HERE MEANS INVOLVEMENT THERE
Taking these admonitions to heart, we can be spared the extreme inanity of
asking, “Why should we bail? It’stheirend of the boat that’s sinking!”
The fact of linkage provides a unique, subtle, and powerful approach to
solving otherwise intractable problems. As a component of System A, element x
is perhaps inaccessible. But as a component of System B, C, or D . . . it can
perhaps be affected in the desired direction by intervening in System B, C, D . . .
Thus, a Space Probe fired at Pluto would require enormous amounts of fuel to
reach the required velocity. But a quick swing around Jupiter, utilizing Jupiter’s
gravitational field as a kind of slingshot, neatly solves the problem. System “A”
(the Space Probe) ducks into System “B” (Jupiter) to borrow a little velocity.
Perhaps your children are reluctant to Brush Their Teeth before going to bed.
You begin reading the Bedtime Story to them while they are still Brushing Their
Teeth. Soon they are rushing to Brush Their Teeth after supper, because that’s
when the Bedtime Story begins. You are using the Bedtime Story as a slingshot
(like Jupiter) to speed them through BrushingTheir Teeth and into bed.[a.]
Finding helpful systems is much like Reframing, with which, indeed, at some
deeper level it may be identical. Both are chancy arts. But when one succeeds in
finding or defining the right system, the results can be spectacular and, to the

Systems-student accustomed to five-per-cent returns, soul-satisfying indeed.
136

40. Beyond Stability
Designing a system so that it will tend to come to equilibrium somewhere
within the realm of achievable environmental conditions is a neat trick. Indeed, it
is an art. But the history of large systems demonstrates that, once the hurdle of
stability has been cleared, a more subtle challenge appears. It is the challenge of
remaining stablewhen the rules change. Machines, like organizations or
organisms, that fail to meet this challenge find that their previous stability is no
longer of any use. The responses that once were life-saving now just make things
worse. What is needed now is the capacity to re-write the procedure manual on
short notice, or even (most radical change of all) to change goals.
The Second Law of Systems-Survival
We are now deep in the realm of Paradox. This being the case, we fearlessly
propound the Second Law of Systems-Survival in its most provocative and
paradoxical form:
IN ORDER TO REMAIN UNCHANGED, THE SYSTEM MUST CHANGE
Specifically, the changes that must occur are changes in thepatterns of
changing(orstrategies) previously employed to prevent drastic internal change.
The capacity to change in such a way as to remain stable when the ground rules
change is a higher-order level of stability, which fully deserves its designation as
Ultra-stability.[cxlvii]
During the Battle of Britain, it was noted that fighter pilots who in diving
accelerated their craft beyond a certain speed experienced severe buffeting and
then, with dismaying regularity, crashed. One such pilot was able to pull out and
survive. When interviewed, he remarked, “Pulling back on the stick with all my
might was just making things worse, so I shoved the stick forward and the plane
responded.” His plane had gone supersonic, at which point the reaction to the
stick becomes reversed. By throwing away the rule book, by assuming that a
new set of rules was in effect, he survived.
Closer to home, the National Foundation, whose goal was to Conquer Polio,
came perilously close to instability when Poliowas actually conquered. A quick
change of goal to the Conquest of Genetic Defects was adopted, one that enabled
the organization to continue to do with undiminished zeal and
efficiencyeverything that it had previously been doing, but now in pursuit of an
up-to-date goal.
The administrative artistry involved is revealed in the choice of a goal that is
not likely to become out-of-date in the foreseeable future.

137

41. After the Solution, What? (The Next
Problem)
The word “Solution” is only a fancy term for the Response of System “A”
(ourselves) to System “B” (the Problem). And it’s a misleading word, because it
implies something that can be done once and for all. But System “B” is sure to
Kick Back in response to our Response, and then we must respond once again.
Clearly this a dynamic process, a back-and-forth interaction that can proceed as
long as the two Systems exist. We shall call it the Dance of Accommodation.
But let us not be charmed by the imagery of a perfect dance in which both
partners execute their steps flawlessly, where each communicates to the other
just what nuances and modifications are about to take place and the other
comprehends perfectly and responds elegantly, making the transitions creatively
and without missing a beat. Such dancing may occur in the movies, but seldom
in real life. What usually happens is more like the experiences of adolescence,
where two awkward beginners make all the standard errors and some new ones,
fail to pick up their partner’s cues, and forget to send their own signals. The
images which constitute our spontaneous metaphors of the System are more
likely to be those we have encountered in previous pages: the customer kicking a
recalcitrant vending machine; the lumberjack laboring to clear a log-jam; the
technician trying to make sense of six hundred clanging alarm bells.
Nevertheless, with long-continued practice in interacting with familiar
Systems, moments can come when our interactions can take on the qualities
suggested—when the partners are no longer simply dancing, but also
communicating about changing the dance itself to make it more satisfying for
both. At such rare moments we have reached the level called Cybernetics of
Cybernetics[cxlviii] or Ultrastability,[cxlix] the level of Autonomy, of
Spontaneity, of Creative Change.
Such moments are the reward of those who recognize the dance for what it is
and who persist in the dance.
138

42. Envoi: Beyond Expertise
We have come to the end of our presentation: why not simply stop? Does
Euclid bother to round off his Axioms with a polished little essay on a the
significance of the whole work?[a. ]But, lest readers feel that they have been left
hanging in air, so to speak, this Coda is appended. We shall not review the
purposes set forth in the Preface that motivated us to undertake this work, nor
shall we describe at length how the intervening chapters have neatly covered all
aspects of the topic. Instead, we shall speak to the necessity of a New Breed of
Systems-student—one who, having absorbed the Axioms here collected and,
more importantly, thespiritinfusing them, can progress beyond technology to the
kind of wisdom the world needs. The world already suffers from too many
experts. They tell us more than we need to know or dare to ask about ingenious
machines, fusion bombs, and management science. What we really need to know
is much more subtle.
We need to know if setting up Management by Objectives in the Universities
will bring on another Dark Age; if placing a microphone in the Oval Office can
bring down the government; if permitting men and women everywhere the
freedom to choose their own way of life and to make their own decisions can
lead to a better world. For such questions your run-of-the-mill expert is of little
value. What is required is a special, elusive talent, really an intuition—a feel for
the wild, weird, wonderful, and paradoxical ways of Large Systems.
We offer no formula for recognizing or cultivating such a talent. But we
suggest that its possessor will, more likely than not, have cut his/her eyeteeth on
the Axioms of General Systemantics.
139

43. Appendix I. Annotated Compendium
ANNOTATED COMPENDIUM OF
BASIC SYSTEMS AXIOMS,
THEOREMS, COROLLARIES, ETC.
For convenience and ready reference of both scholar and casual reader, we
here summarize the results of our researches on General Systemantics, tabulated
in order of appearance. This is by no means an all-inclusive listing of all possible
Systems-propositions. Only the most basic ones are included. Now that the trail
has been blazed, readers will surely find many additional formulations in every
field of Science, Industry, and Human Affairs. Some may be motivated to
translate certain well-known Laws in various fields into their completely general
Systems-formulations. Readers are invited to share their findings (see Readers’
Tear-out Feedback Sheet, Appendix III).

PREFACE II:
CHERISH YOUR EXCEPTIONS. CHERISH YOUR SYSTEM-FAILURES.
Cognate Theorem:
CHERISH YOUR BUGS. STUDY THEM.
Meta-strategy I:
THE MOST EFFECTIVE APPROACH TO COPING IS TO LEARN THE
BASIC LAWS OF SYSTEMS-BEHAVIOR.
Satir’s Summation:
PROBLEMS ARE NOT THE PROBLEM; COPING IS THE PROBLEM.

HISTORICAL OVERVIEW:
Primal Scenario or Basic Datum of Experience:
SYSTEMS IN GENERAL WORK POORLY OR NOT AT ALL.
Alternative Formulations:
NOTHING COMPLICATED WORKS.
COMPLICATED SYSTEMS SELDOM EXCEED FIVE PER
EFFICIENCY.
IF ANYTHING CAN GO WRONG, IT WILL (MURPHY’S LAW).

CENT

CHAPTER 1: FIRST PRINCIPLES:
Fundamental Theorem:
NEW SYSTEMS GENERATE NEW PROBLEMS.
Corollary (Occam’s Razor):
SYSTEMS SHOULD NOT BE UNNECESSARILY MULTIPLIED.
Law of Conservation of Anergy:
THE TOTAL AMOUNT OF ANERGY IN THE UNIVERSE IS CONSTANT.
Corollary:
SYSTEMS OPERATE BY REDISTRIBUTING ANERGY INTO DIFFERENT
FORMS AND INTO ACCUMULATIONS OF DIFFERENT SIZES.

CHAPTER 2: LAWS OF GROWTH:
SYSTEMS EXPAND, AND AS THEY EXPAND, THEY ENCROACH.
Big-Bang Theorem:
SYSTEMS TEND TO EXPAND AT 5-6% PER ANNUM.
SYSTEMS TEND TO EXPAND TO FILL THE KNOWN UNIVERSE

CHAPTER 3: THE GENERALIZED UNCERTAINTY
PRINCIPLE:
The Generalized Uncertainty Principle (G.U.P.):
SYSTEMS DISPLAY ANTICS.
Alternatively:
COMPLEX SYSTEMS EXHIBIT UNEXPECTED BEHAVIOR
West’s Wisdom:
REALITY IS MORE COMPLEX THAN IT SEEMS.
Climax Design Theorem (Non-Additivity Theorem):
A LARGE SYSTEM PRODUCED BY EXPANDING THE DIMENSIONS OF
A SMALLER SYSTEM DOES NOT BEHAVE LIKE THE SMALLER
SYSTEM.

CHAPTER 4: A...B...C...DISASTER (FEEDBACK):
Le Chatelier’s Principle:
THE SYSTEM ALWAYS KICKS BACK.
Alternatively:

SYSTEMS GET IN THE WAY
SYSTEMS TEND TO OPPOSE THEIR OWN PROPER FUNCTIONS

CHAPTER 5: THE POWER OF POSITIVE FEEDBACK: A
WARNING:
BEWARE OF POSITIVE FEEDBACK

CHAPTER 6: WHAT NEXT? THE LIFE CYCLE OF
SYSTEMS:
SYSTEMS TEND TO MALFUNCTION CONSPICUOUSLY JUST AFTER
THEIR GREATEST TRIUMPH.
Fully Prepared For The Past (F.P.F.P.):
THE ARMY IS NOW FULLY PREPARED TO FIGHT THE PREVIOUS WAR.
PERFECTION OF PLANNING IS A SYMPTOM OF DECAY.
A TEMPORARY PATCH WILL VERY LIKELY BE PERMANENT.
THE OLD SYSTEM IS NOW THE NEW PROBLEM.
Alternatively:
THE GHOST OF THE OLD SYSTEM CONTINUES TO HAUNT THE NEW.

CHAPTER 7: THE GRAND ILLUSION:
Functionary’s Falsity:
PEOPLE IN SYSTEMS DO NOT DO WHAT THE SYSTEM SAYS THEY
ARE DOING.
Operational Fallacy:
THE SYSTEM ITSELF DOES NOT DO WHAT IT SAYS IT IS DOING.
Corollary:
THE FUNCTION (OR PRODUCT) IS DEFINED BY THE SYSTEMSOPERATIONS
THAT OCCUR
IN
ITS
PERFORMANCE
OR
MANUFACTURE.
Corollary:
THE LARGER THE SYSTEM, THE LESS THE VARIETY IN THE
PRODUCT.
A Systems-Delusion:
IF DETROIT MAKES IT, IT MUST BE AN AUTOMOBILE.
The Naming Fallacy:

THE NAME IS MOST EMPHATICALLY NOT THE THING.

CHAPTER 8: INSIDE SYSTEMS:
The F.L.A.W. (Fundamental Law of Administrative Workings):
THINGS ARE WHAT THEY ARE REPORTED TO BE.
Alternative Forms of the F.L.A.W.:
THE REAL WORLD IS WHAT IS REPORTED TO THE SYSTEM.
IF IT ISN’T OFFICIAL, IT HASN’T HAPPENED.
IF IT DIDN’T HAPPEN ON CAMERA, IT DIDN’T HAPPEN.
And Conversely:
IF THE SYSTEM SAYS IT HAPPENED, IT HAPPENED.
Corollary #1:
A SYSTEM IS NO BETTER THAN ITS SENSORY ORGANS.
Corollary #2:
TO THOSE WITHIN A SYSTEM THE OUTSIDE REALITY TENDS TO
PALE AND DISAPPEAR.
Corollary #3:
THE BIGGER THE SYSTEM, THE NARROWER
SPECIALIZED THE INTERFACE WITH INDIVIDUALS.

AND

MORE

Harte’s Haunting Theorem:
INFORMATION RARELY LEAKS UP
Memory Joggers:
THE CHART IS NOT THE PATIENT
THE DOSSIER IS NOT THE PERSON

CHAPTER 9. DELUSION SYSTEMS VERSUS SYSTEMS
DELUSIONS:
The Jet Travel Paradox:
WHEN YOU GET THERE, YOU’RE STILL NOT THERE.
Stein’s Extension:
WHEN YOU DO GET THERE, THERE’S NO THERE THERE.
Manager’s Mirage:
THE SYSTEM TAKES
EVENTUALITY).

THE

CREDIT

(FOR

ANY

FAVORABLE

CHAPTER 10. SYSTEMS-PEOPLE:
SYSTEMS ATTRACT SYSTEMS-PEOPLE.
SPECIALIZED SYSTEMS SELECT FOR SPECIALIZATION.
Corollary:
THE END RESULT OF EXTREME COMPETITION IS BIZARRENESS.
Corollary:
PROLONGED SELECTION SELECTS SURVIVORS.
Rohe’s Theorem:
DESIGNERS OF SYSTEMS TEND TO DESIGN WAYS FOR THEMSELVES
TO BYPASS THE SYSTEM.
The Exploitation Theorems:
IF A SYSTEM CAN BE EXPLOITED, IT WILL BE.
ANY SYSTEM CAN BE EXPLOITED.

CHAPTER 11. ELEMENTARY SYSTEMS-FUNCTIONS:
Basic Axiom of Systems-Function:
BIG SYSTEMS EITHER WORK ON THEIR OWN OR THEY DON’T. IF
THEY DON’T, YOU CAN’T MAKE THEM.
Administrator's Anxiety:
PUSHING ON THE SYSTEM DOESN'T HELP.
Corollary:
EVEN TRYING TO BE HELPFUL IS A DELICATE AND DANGEROUS
UNDERTAKING.
Corollary:
ADDING MANPOWER TO A LATE SOFTWARE PROJECT MAKES IT
LATER.
A SIMPLE SYSTEM MAY OR MAY NOT WORK.
Observation:
SOME COMPLEX SYSTEMS ACTUALLY FUNCTION
Rule of Thumb:
IF A SYSTEM IS WORKING, LEAVE IT ALONE. DON'T CHANGE
ANYTHING. (IF IT AIN'T BROKE, DON'T FIX IT.)
A COMPLEX SYSTEM THAT WORKS IS INVARIABLY FOUND TO HAVE
EVOLVED FROM A SIMPLE SYSTEM THAT WORKED.

A COMPLEX SYSTEM DESIGNED FROM SCRATCH NEVER WORKS
AND CANNOT BE MADE TO WORK. YOU HAVE TO START OVER,
BEGINNING WITH A WORKING SIMPLE SYSTEM.

CHAPTER 12. ADVANCED SYSTEMS FUNCTIONS:
Functional Indeterminacy Theorem (F.I.T.):
IN COMPLEX SYSTEMS, MALFUNCTION AND EVEN TOTAL NONFUNCTION MAY NOT BE DETECTABLE FOR LONG PERIODS, IF EVER
Kantian Theorem:
LARGE COMPLEX SYSTEMS ARE BEYOND HUMAN CAPACITY TO
EVALUATE. (LARGE SYSTEMS KANT BE FULLY KNOWN).
Systems Law of Inertia:
A SYSTEM THAT PERFORMS A CERTAIN FUNCTION OR THAT
OPERATES IN A CERTAIN WAY WILL CONTINUE TO OPERATE IN THAT
WAY REGARDLESS OF THE NEED OR OF CHANGED CONDITIONS.
Alternatively:
WHATEVER THE SYSTEM HAS DONE BEFORE, YOU CAN BE SURE IT
WILL DO IT AGAIN.
Briefly:
THE SYSTEM CONTINUES TO DO ITS THING, REGARDLESS OF
CIRCUMSTANCES.

CHAPTER 13. THE SYSTEM KNOWS (SYSTEM GOALS):
SYSTEMS DEVELOP GOALS OF THEIR OWN THE INSTANT THEY
COME INTO BEING.
Equifinality:
THE SYSTEM IS ITS OWN BEST EXPLANATION.
Alternatively:
THE SYSTEM IS A LAW UNTO ITSELF.
INTRA-SYSTEM GOALS COME FIRST.
SYSTEMS DON’T WORK FOR YOU OR FOR ME. THEY WORK FOR
THEIR OWN GOALS.
THE SYSTEM BEHAVES AS IF IT HAS A WILL TO LIVE.
THE SYSTEM BEHAVES AS IF IT HAS A WILL OF ITS OWN.

CHAPTER 14. SYSTEMS-FAILURE (THEORY OF

ERRORS):
ANY LARGE SYSTEM IS GOING TO BE OPERATING MOST OF THE
TIME IN FAILURE MODE.
Fundamental Failure Theorem (F.F. T .):
A SYSTEM CAN FAIL IN AN INFINITE NUMBER OF WAYS.
THE MODE OF FAILURE OF A COMPLEX SYSTEM CANNOT
ORDINARILY BE DETERMINED FROM ITS STRUCTURE.
Corollary:
THE CRUCIAL VARIABLES ARE DISCOVERED BY ACCIDENT.
The Fail-Safe Theorem:
WHEN A FAIL-SAFE SYSTEM FAILS, IT FAILS BY FAILING TO FAIL
SAFE.

CHAPTER 15. GLITCHES, GREMLINS, BUGS:
IF IT DOESN’T FAIL HERE, IT WILL FAIL THERE.
Glitch-Hunter’s Theorem:
INTERMITTENT FAILURE IS THE HARDEST CASE.
A BUG MAY BE PURELY LOCAL, BUT YOU AND I CAN NEVER KNOW
THAT FOR SURE.
ONE DOES NOT KNOW ALL THE EXPECTED EFFECTS OF KNOWN
BUGS.
CHERISH YOUR BUGS. STUDY THEM.
ERROR CORRECTION IS WHAT WE DO.

CHAPTER 16. FORM, FUNCTION, FAILURE:
Wiener’s Wish:
THE STRUCTURE OF A MACHINE OR AN ORGANISM IS AN INDEX OF
THE PERFORMANCE THAT MAY BE EXPECTED OF IT.
Emended Form:
FORM MAY FOLLOW FUNCTION, BUT DON’T COUNT ON IT.
NEW STRUCTURE IMPLIES NEW FUNCTIONS.
AS SYSTEMS EXPAND, NEW FUNCTIONS APPEAR SUDDENLY, IN
STEP- WISE FASHION.
Specialized Incapacity Theorem:
AS SYSTEMS GROW IN SIZE AND COMPLEXITY, THEY TEND TO LOSE

BASIC FUNCTIONS.

CHAPTER 17. COLOSSAL ERRORS:
Large Lumps of Liability Theorem:
WHEN BIG SYSTEMS FAIL, THE FAILURE IS OFTEN BIG.
COLOSSAL SYSTEMS FOSTER COLOSSAL ERRORS.
Corollary:
COLOSSAL ERRORS TEND TO ESCAPE NOTICE.
(A Systems-Delusion):
IF IT’S TREATED BY DOCTORS IT MUST BE A DISEASE.
Total Systems Theorems:
TOTAL SYSTEMS TEND TO RUN AWAY (GO OUT OF CONTROL)
A TOTAL SYSTEM IN A RUNAWAY SEQUENCE MAY BE FORCED TO
GROW RAPIDLY OR DISINTEGRATE IN CHAOS.

CHAPTER 18. UNEXPECTED INTERACTIONS:
IN SETTING UP A NEW SYSTEM, TREAD SOFTLY. YOU MAY BE
DISTURBING ANOTHER SYSTEM THAT IS ACTUALLY WORKING.

CHAPTER 19. COMMUNICATION THEORY
The Inherent Limitation:
EXPERIENCE ISN’T HEREDITARY. IT AIN’T EVEN CONTAGIOUS.
THE MESSAGE SENT IS NOT NECESSARILY THE MESSAGE RECEIVED.
Dunn’s Indeterminacy:
EVERY PICTURE TELLS A STORY-BUT NOT THE SAME STORY.
YOU CAN’T NOT COMMUNICATE.
THE MEANING OF A COMMUNICATION IS THE BEHAVIOR THAT
RESULTS.

CHAPTER 20. INFORMATION:
Lynd’s Lemma:
KNOWLEDGE FOR WHAT?
The Basic Information Theorem (B.I.T.):
INFORMATION DECAYS.
Whitehead’s Variation:
KNOWLEDGE DOES NOT KEEP ANY BETTER THAN FISH.

Rate-of-Decay Theorem:
THE MOST URGENTLY NEEDED INFORMATION DECAYS FASTEST.
Law of Interconvertibility:
ONE SYSTEM’S GARBAGE IS ANOTHER SYSTEM’S PRECIOUS RAW
MATERIAL.
Inaccessibility Theorem:
THE INFORMATION YOU HAVE IS NOT THE INFORMATION YOU
WANT.
THE INFORMATION YOU WANT IS NOT THE INFORMATION YOU
NEED.
THE INFORMATION YOU NEED IS NOT THE INFORMATION YOU CAN
OBTAIN.
Rule of Thumb for Missing Information:
DON’T BOTHER TO LOOK FOR IT. YOU WON’T FIND IT.
IN A CLOSED SYSTEM, INFORMATION TENDS TO DECREASE AND
HALLUCINATION TO INCREASE.

CHAPTER 2I. TALKING TO THE SYSTEM:
Deregulated Dinosaur Effect:
EXTRA BRAIN IN TAIL, TAIL WAGS ON OWN SCHEDULE.

CHAPTER 22. HOW NOT TO SOLVE PROBLEMS:
Inevitability-of-Reality Fallacy:
THINGS HAVE TO BE THE WAY THEY ARE AND NOT OTHERWISE
BECAUSE THAT’S JUST THE WAY THEY ARE.
Unawareness Theorem:
IF YOU’RE NOT AWARE THAT YOU HAVE A PROBLEM, HOW CAN
YOU CALL FOR HELP?

CHAPTER 23. THE TAO OF PROBLEM AVOIDANCE:
IF YOU’RE NOT THERE, THE ACCIDENT CAN HAPPEN WITHOUT YOU.
Meta-strategy II:
CHOOSE YOUR SYSTEMS WITH CARE.
DESTINY IS LARGELY A SET OF UNQUESTIONED ASSUMPTIONS.
Peter’s Creative Incompetence Theorem:
IF YOU OBVIOUSLY CAN’T DO IT YOU PROBABLY WON’T BE ASKED.

CHAPTER 24. THE CREATIVE TACK:
IF SOMETHING ISN’T WORKING, DON’T KEEP DOING IT. DO
SOMETHING ELSE INSTEAD.
Afterthought:
DO ALMOST ANYTHING ELSE.
Meta-strategy III:
FOR MAXIMUM SUCCESS, FEEL FREE TO SWITCH SYSTEMS AND
EVEN TO CHANGE GOALS.

CHAPTER 25. DESIGN DON’TS:
DO IT WITHOUT A NEW SYSTEM IF YOU CAN.
Occam’s Razor Again:
AVOID UNNECESSARY SYSTEMS (SYSTEMS SHOULD NOT BE
UNNECESSARILY MULTIPLIED).
Corollary:
DO IT WITH AN EXISTING SYSTEM IF YOU CAN.
Corollary:
DO IT WITH A LITTLE SYSTEM IF YOU CAN.
Agnes Allen’s Law:
ALMOST ANYTHING IS EASIER TO GET INTO THAN OUT OF.
Specifically:
TAKING IT DOWN IS OFTEN MORE TEDIOUS THAN SETTING IT UP.
AVOID UNFAVORABLE SETTINGS (SOME THINGS JUST CAN’T BE
DONE WELL BY A SYSTEM)
S.L.O.G. Factor (Systems Law of Gravity):
AVOID UPHILL CONFIGURATIONS (SYSTEMS RUN DOWNHILL MORE
EASILY THAN UPHILL).
Alternatively:
GO WITH THE FLOW.
Internal Friction Theorem:
LOOSE SYSTEMS LAST LONGER AND FUNCTION BETTER.
Corollary:
LOOSE SYSTEMS HAVE LARGER INTERSTICES.

Gresham’s Law:
BAD DESIGN CAN RARELY BE OVERCOME BY MORE DESIGN,
WHETHER GOOD OR BAD.
Spodick’s Modification:
ADDING NUMBERS TO A BAD STUDY DOESN’T CLARIFY IT.
That is:
LARGE AMOUNTS OF POOR DATA TEND TO PREEMPT ANY AMOUNT
OF GOOD DATA.
Brooks’ Bitter Bidding:
PLAN TO SCRAP THE FIRST SYSTEM. YOU WILL ANYWAY.

CHAPTER 26. CATASTROPHE THEORY:
The Jell-O Principle:
WHEN EVERYTHING CORRELATES
THINGS WILL NEVER SETTLE DOWN.

WITH

EVERYTHING

ELSE,

Brinkley’s Breakthrough:
TOGETHERNESS IS GREAT, BUT DON’T KNOCK GET-AWAY-NESS.
Edsel’s Edifying Admonition:
DON’T PUT YOUR NAME ON IT UNTIL YOU ARE SURE IT WILL FLOAT.

CHAPTER 27. WISHFUL FEEDBACK:
Output Phobia:
OUTPUT IS DANGEROUS.
Corollary:
KEEP IT IN THE STUDY PHASE.
Subcorollary Rule:
KEEP THE STUDY UNDER STUDY.
Wishful Feedback Theorem:
JUST CALLING IT ‘FEEDBACK’ DOESN’T MEAN THAT IT HAS
ACTUALLY FED BACK.
Alternatively:
IT HASN’T FED BACK UNTIL THE SYSTEM CHANGES COURSE.
The Face-of-the-Future Theorem:
IN DEALING WITH THE SHAPE OF THINGS TO COME, IT PAYS TO BE

GOOD AT RECOGNIZING SHAPES.

CHAPTER 28. FEAR OF FEEDBACK:
The First Law of Systems-Survival:
A SYSTEM THAT IGNORES FEEDBACK HAS ALREADY BEGUN THE
PROCESS OF TERMINAL INSTABILITY.

CHAPTER 29. FEEDBACK AND THE FUTURE:
Boulding’s Law:
NATURE IS WISE ONLY WHEN FEEDBACKS ARE RAPID
(Relativistic Law of Information Transfer):
FEEDBACK ALWAYS GIVES A PICTURE OF THE PAST. (INFORMATION
TRAVELS AT FINITE VELOCITY)
Weinberg’s Axiom of Experience (a Pseudodoxy):
THE FUTURE WILL BE LIKE THE PAST, BECAUSE, IN THE PAST, THE
FUTURE WAS LIKE THE PAST
Gall’s Emendation:
THE FUTURE IS NO MORE PREDICTABLE NOW THAN IT WAS IN THE
PAST, BUT YOU CAN AT LEAST TAKE NOTE OF TRENDS.
(Escape from Predestination):
WHEN THE SYSTEM ACTS, IT PARTICIPATES IN THE CREATION OF
THE FUTURE.
THE FUTURE IS PARTLY DETERMINED BY WHAT WE DO NOW.

CHAPTER 30. CATALYTIC MANAGERSHIP:
Catalytic Managership Rule:
USE THE SPONTANEOUS OFFERINGS OF THE SYSTEM.
Utilization Meta-Strategy:
UTILIZE THE PRINCIPLE OF UTILIZATION.
Vernacular Variants:
IF IT’S FOR DIGGING A HOLE IT SHOULD PROBABLY LOOK
SOMETHING LIKE A SHOVEL.
IF IT LOOKS LIKE A SHOVEL, TRY USING IT FOR DIGGING A HOLE.

CHAPTER 31. THE ‘PROBLEM’ PROBLEM:
GREAT ADVANCES DO NOT COME OUT OF SYSTEMS DESIGNED TO

PRODUCE GREAT ADVANCES.
Alternatively:
COMPLICATED SYSTEMS PRODUCE COMPLICATED RESPONSES TO
PROBLEMS.
Ashby’s Formulation:
COMPLEX SYSTEMS HAVE COMPLEX BEHAVIORS.
MAJOR ADVANCES TAKE PLACE BY FITS AND STARTS.

CHAPTER 32. THE LIMITS TO GRANDIOSITY:
The Limit Theorems:
(A) YOU CAN’T CHANGE JUST ONE THING.
(B) YOU CAN’T CHANGE EVERYTHING.
A LITTLE GRANDIOSITY GOES A LONG WAY.
Perfectionist’s Paradox:
IN DEALING WITH LARGE SYSTEMS,
PERFECTION IS A SERIOUS IMPERFECTION.

THE

STRIVING

FOR

Alternative Formulation:
PERFECTION CAN BE ACHIEVED ON THE DAY AFTER THE FINAL
DEADLINE.
Sometimes Stated As:
WHEN THE CURRENT REVISION IS COMPLETE, THE SYSTEM WILL
BE PERFECT.
Or Even As:
THE FINAL TRUTH IS JUST AROUND THE CORNER.
Rule of Thumb (Survivors’ Souffle):
IF IT’S WORTH DOING AT ALL, IT’S WORTH DOING POORLY.
Bateson’s Whimsy:
IF IT’S NOT WORTH DOING, IT’S WORTH DOING WELL.

CHAPTER 33. DISASTER CONTROL:
Minsky’s Admonition:
IN ORDER TO SUCCEED IT IS NECESSARY TO KNOW HOW TO AVOID
THE MOST LIKELY WAYS TO FAIL.
Jung’s Runic Riddle:

IF IT PUTS A WEAPON IN YOUR HAND IT IS AIMING AT SOME KIND
OF VIOLENCE.

CHAPTER 34. WHERE’S THE PROBLEM?
IN ORDER TO BE EFFECTIVE, AN INTERVENTION MUST INTRODUCE
A CHANGE AT THE CORRECT LOGICAL LEVEL
Meta-strategy V:
IF A PROBLEM SEEMS UNSOLVABLE, CONSIDER THAT YOU MAY
HAVE A META-PROBLEM

CHAPTER 35. PROBING THE SYSTEM:
The Law of Requisite Variety:
CONTROL IS EXERCISED BY THE ELEMENT WITH THE GREATEST
VARIETY OF BEHAVIORAL RESPONSES.
But:
PROBING WILL GET YOU ONLY SO FAR.
In Fact:
IN MOST CASES, YOU CAN’T GET THERE FROM HERE.

CHAPTER 36. THE PROBLEM IN THE SOLUTION:
THE SYSTEM IS ALTERED BY THE PROBE USED TO TEST IT.
In Pharmaceutics:
THE PILL THAT IS TESTED IS NEVER CONSUMED (AND VICE VERSA).
Addendum:
THE PROBE IS ALTERED ALSO.
Corollary:
THERE CAN BE NO SYSTEM WITHOUT ITS OBSERVER.
Corollary:
THERE CAN BE NO OBSERVATION WITHOUT ITS EFFECTS.
Pseudodoxy:
“IF YOU ARE NOT PART OF THE SOLUTION, YOU ARE PART OF THE
PROBLEM.”
Correct Form of the Above:
THE SOLUTION IS OFTEN PART OF THE PROBLEM.

Rule:
LOOK FOR THE SELF-REFERENTIAL POINT. THAT’S WHERE THE
PROBLEM IS LIKELY TO BE.
More Briefly:
STAY AWAY FROM SELF-REFERENCE—THIS MEANS YOU.
Pseudodoxy:
“THIS SYSTEM IS THE ONLY CORRECT SYSTEM.”
IF THINGS SEEM TO BE GETTING WORSE EVEN FASTER THAN
USUAL, CONSIDER THAT THE REMEDY MAY BE AT FAULT.
Translated:
STAY OUT OF THE POSITIVE FEEDBACK TRAP.
Nasal Spray Axiom:
ESCALATING THE WRONG SOLUTION DOES NOT IMPROVE THE
OUTCOME.
IF THINGS ARE ACTING VERY STRANGELY, CONSIDER THAT YOU
MAY BE IN A FEEDBACK SITUATION.
Or:
WHEN PROBLEMS DON’T YIELD TO COMMONSENSE SOLUTIONS,
LOOK FOR THE THERMOSTAT.

CHAPTER 38. THE PROBLEM IN THE QUESTION:
THE AUTOMATIC PILOT IS NOT MUCH HELP WITH HIGHJACKERS.
IF YOU CAN’T CHANGE THE SYSTEM, CHANGE THE FRAME—IT
COMES TO THE SAME THING.
Meta-Strategies:
I. THE MOST EFFECTIVE APPROACH TO COPING IS TO LEARN THE
LAWS OF SYSTEMS-BEHAVIOR.
II. CHOOSE YOUR SYSTEMS WITH CARE.
YOU DON’T ACTUALLY HAVE TO JOIN THE COAST GUARD.
III. FOR MAXIMUM SUCCESS, FEEL FREE TO SWITCH SYSTEMS OR
EVEN TO SWITCH GOALS.
IV. UTILIZE THE PRINCIPLE OF UTILIZATION.
V. IF YOUR PROBLEM SEEMS UNSOLVABLE, CONSIDER THAT YOU
MAY HAVE A META-PROBLEM

CHAPTER 39. THE NET OF INDRA:

ANY GIVEN ELEMENT OF ONE SYSTEM IS SIMULTANEOUSLY AN
ELEMENT IN AN INFINITY OF OTHER SYSTEMS.
EVERYTHING CORRELATES.
THERE IS NO SUCH THING AS NONINVOLVEMENT.
Or at least:
NONINVOLVEMENT HERE MEANS INVOLVEMENT THERE.

CHAPTER 40. BEYOND STABILITY:
The Second Law of Systems-Survival:
IN ORDER TO REMAIN UNCHANGED, THE SYSTEM MUST CHANGE.
151

44. Appendix II. Self-Evaluation Quizzes
First Readers’ Self-Evaluation Quiza For Testing Mastery of Basic General
Systemantics
This Quiz consists of a series of brief examples illustrating basic principles of
the operation of large Systems. You are asked to read each example and then to
indicate (in the space provided) as many as possible of the applicable SystemsAxioms. Advanced students may indicate the Axioms by number rather than by
name.
1. You dial the telephone number of a friend in a nearby suburb. A recorded
voice comes on the line, informing you that you have dialed incorrectly and
instructing you to re-read the directions at the front of the telephone book.
Resisting the urge to answer back, you mutter to yourself, “Axioms number ___,
___ , ___ and ___; also ___ and ___.”
2. The Titanic, designed to be unsinkable, had multiple bulkheads, each of
which ran the full width of the ship. When she grazed an iceberg, however, the
rents in the hull ranlengthwise, breaching the six forward compartments. Axioms
number ___, ___, ___, ___ and ___.
3. You are taking an examination in College Economics. The first question
reads, “Was President Franklin D. Roosevelt’s Gold Policy a success or a
failure?” As a Systems-student, you immediately think of Axioms Number ___,
___, perhaps also ___ .
4. On a bright April morning you receive a Christmas card in the mail. It is
postmarked December 20,two years ago. Before handing it to you, the carrier
demands two cents postage due, because the price of a stamp has gone up since
it was mailed. Axioms Number ___, ___, and ___.
5. A child psychiatrist, wishing to be both modern and efficient, as well as to
gather research data on his practice, develops a questionnaire for parents to fill
out. It includes questions on the nicknames, hobbies, and personal idiosyncrasies
of relatives out to the level of third cousin. He presents the questionnaire to Mrs.
Ept, whose son, Newton N., has been brought in for difficult behavior in school.
When confronted with thequestionnaire, Mrs. Ept refuses to fill it out, announces
that the doctor is an idiot, and takes her child home.[b]The psychiatrist has failed
to take account of Axioms Number ___, ___, and ___.
6. A computerized study of funds managed by institutional
investmentcounselors over the past thirty years demonstrates that such funds
have grown (and shrunk) at precisely the rate predicted on the basis

ofrandomdecisions to buy and sell stocks. Axioms Number ___, ___, and ___.
7. Graduate schools train people for intellectual leadership by keeping them in
the role of submissive students until middle age. Axioms Number ___, ___, and
___.
8. Medical students, many of whom are destined to become family doctors,
are trained in great centers of tertiary-level medical care, where common
ailments are rare and rare entities are common. They learn to treat almost
everything that they will never see again. They do not learn to treat what they
will encounter every day. They never see a patient as physician of first resort,
and thus they never learn how to function as family doctors. Axioms Number
___, ___, and ___.
9. Sir William Osler, greatest of modern physicians, warned against the above
situation, but was ignored. Axioms Number ___, ___, and ___.
Second Readers’ Self-evaluation Quiz
(This Second Quiz has been designed especially for readers of the Second
Edition, using practical examples drawn from recent events. The rules are the
same as for the First Quiz.)
1. Computers are larger, faster, and more reliable than ever; yet one of the
best, employed for National Defense, mistook the rising Moon for a flight of
hostile missiles and sent an attack warning to the nuclear-missile silos. More
recently, on June 3, 1980, three false alarms of enemy missile attack were issued
in rapid sequence, prompting the Secretary of Defense to announce that “the
System is working the way it is supposed to.” The false alarms were later traced
to a malfunctioning 46-cent computer chip. It was also revealed that the System
did not critique its own alarms to evaluate their believability. Indeed, the alarms
could not even be monitored at their point of origin.[cl]
Assignment for the Student:
Cite pertinent Axioms. Discuss the meaning of the phrase, “working the way
it is supposed to.” Pick one Axiom for detailed discussion in terms of Hireling’s
Hypnosis.
2. For the first time in its 42-year history, the Hoover Dam on the Colorado
has experienced flood waters pouring over the top of the dam (July 2, 1983). In
reply to critics who said the flood control authorities should have seen it coming,
Interior Secretary James Watt asserted: “The system is working the way it is
supposed to work.”
Assignment:
Same as for (1) above.

3. In an effort to increase revenues, the government of Brazil is officially
encouraging its citizens to smoke more tobacco.[cli]
Assignment:
A simple calculation[clii]demonstrates that the cost of supporting old people is
much greater than having them die early of lung cancer and emphysema. The
government’s action is thusvery rational. Using elementary algebra, show that a
Government can reduce its expenses to zero by a sufficient reduction in the
numbers of its citizens. List several cost-effective ways of accomplishing a quick
die-off of older people.
4. The Inheritance Tax, intended to discourage the accumulation of great
wealth in a few favored hands, has been found to work in favor of the very rich
by forcing the inheritors of small businesses to sell them to large corporations in
order to pay the inheritance tax.
Assignment:
Discuss in terms of Le Chatelier’s Principle. Find the Self-referential Point.
5. “A new 40-bed hospital near Karachi recently had three physicians and
eight inpatients, but no drugs, nurses, cafeteria, or morgue.”[cliii]
Assignment:
Cite relevant Axioms, particularly those relating to Systems-design, Large
Scale, and Grandiosity.
6. Faced with the enormous cleanup bill for Three Mile Island, the utility
company is suing the Nuclear Regulatory Commission—for Improper
Regulation. If the suit is successful, the utility company will have succeeded in
pushing the cost of the cleanup ($4.3 billion) on to thetaxpayers of the United
States, to the tune of about $40 per taxpayer.[cliv]
Assignment:
Discuss in terms of Encroachment and the Electric Turtle Effect.
7. Among the followers of a great leader, the outstanding quality or aptitude is
likely to be:
(a) leading
(b) following
Assignment:
Choose one. Apply appropriate Axioms.
8. “The Arkansas Power and Light Company had to shut down a nuclear
generating plant for three weeks—at a cost of more than $15 million—to clean
out Asian clams from its water lines and cooling equipment.”[clv] Meanwhile, in

Japan, six of that nation’s twelve nuclear reactors were shut down at one time in
June of 1975 for reasons “ranging from radiation leakage to clogging of cooling
pipes from jellyfish.”[clvi]
Assignment:
Discuss nuclear power plants as a source of new ecological niches. Which
organisms presently known to science appear to be good possible candidates as
parasites on nuclear power plants?
(For advanced students):
Once before, in the distant past, life on earth responded to the appearance of a
potent toxin—oxygen—by learning to thrive on it by extracting energy from it.
Could microorganisms learn to take their energy for growth and development
from nuclear radiation? If so, what would be their competitive position with
respect to the rest of us?
Third Readers’ Self-evaluation Quiz
1. The demand for cat-food in the United States has caused the nearextinction of the Canadian Inland Eskimos from starvation.
Assignment:
Explain. Cite relevant Axioms.
2. The Gross National Product goes up every time someone has an auto
accident.[clvii]
Assignment:
Discuss in terms of the Operational Fallacy and Systems-Delusions.
3. When Philo Farnsworth dreamed up the concept of Television, the first
response of his teachers was to send him to another state for sanity testing.
Assignment:
Discuss in terms of the Sociology of Scientific Knowledge (SSK).[a][clviii]
4. When an unbreakable World-Wide Web, based on the concept of packetswitching, was proposed to 140 communications executives, they unanimously
rejected it.
Assignment:
Analyze in terms of the Sociology of Scientific Knowledge (SSK), then in
terms of Systemantics Axioms; then discuss the difference between Systemantics
and SSK.
5. Florida resident Marjorie Kinnan Rawlings wrote the best-selling
classic,The Yearling, a novel about the life of a little boy growing up in turn-of-

the-century Florida. When the manuscript was anonymously submitted to
thirteen present-day Florida editors, it was unanimously rejected. Only one
editor recognized it.
Assignment:
Discuss using (1) the concept that celebrities receive still more publicity
because they are well-known; (2) the Peter Principle; (3) Corollary #3 of the
F.L.A.W.(BIG SYSTEM, NARROW INTERFACE). Mention the Coefficient of
Fiction. Compare with items (3) and (4) above.
Essay Questions for Advanced Students (First Edition)
1. Discuss the impact of television on the design of municipal sewage
systems.
2. The development of the Peruvian fishing industry has resulted in less
protein than before for the undernourished children of Peru. Explain.
3. Discuss, from the Systems-standpoint, the following statement:
Prisonscontain those who arenot deterred from crimeby the threat of punishment.
Include in your discussion Bateson’s idea that crime is not an action but a
category of action.
4. Explain (a) why no major organization has ever voluntarily disbanded
itself; (b) why major doctrinal advances are rarely made by the chief officer of a
religion, philosophy, or political party; (c) why company presidents rarely if ever
introduce a major change in the function or product of the company. In light of
the above, discuss Esso’s change of name to Exxon; Bell telephone’s decision (a
generation ago) that their company’s product wasservice.
Essay Questions for Advanced Students (Second Series)
1. A Public Health expert was recently quoted as saying, “. . . there is nothing
so discouraging as a new health center building to keep workersout of the
field.”[clix]
Discussin terms of Architecture and Large Systems. Compare the recent UN
action in commissioning a new African Conference Center to advance the fight
against famine in the Sahel (See Chapter 6).
2. “. . . any medical program that is ambiguous enough to require cost-benefit
analysis is too ambiguous to be resolved by cost-benefit analysis.”[clx]
Discussthis idea as it applies to political, social, or industrial programs.
3. After sixteen years of experience in the School System, a “student” can be
expected to be an expert. . . at being a “student” in the School System.
Axioms ___ and ___.

Discussthe choice of the word “student” as applied to the young person in
such a setting.
4.Discusswhat the consequences might be for society and for individuals if
teen-age computer “criminals” were given prizes for their service to society in
demonstrating weaknesses in computer security. Use the concepts of Model of
the Universe and Reframing.
5. “In 1959 . . . a philanthropic organization called Seeing Eye, Inc., stopped
soliciting money for buying and training seeing-eye dogs. . . because it had more
money than it knew what to do with. At the same timethe National Society for
the Prevention of Blindness was struggling along. . .” on a limited budget.[clxi]
Discussin terms of the Naming Effect and Reframing.
6. Consider a proposal to solve the Farm Problem by Reframing farmers as
Defense Subcontractors (“Food as a Weapon”) and allowing them to operate on
a cost-plus basis. Compare the cost of such a program to the cost of a fleet of
nuclear submarines. Prepare an Impact Statement on the effect of the program on
traditional American rural life patterns. Anticipate, if possible, what objections
might be made to the proposal, and by whom. List three ways ofbypassingsuch
resistance in advanceby modifications of the proposal.
7. To prove that laser beams can be bounced off satellites to destroy enemy
missiles, a beam of laser light was fired from the ground at a small mirror
mounted on the Space ShuttleDiscoveryduring its June (1985) flight. No
returning flash was obtained. A quick search revealed that Mission Control had
positioned the spacecraft backwards, with the mirror facing away from Earth.
After the shuttle had been turned around androtated 180 degrees, the experiment
worked quite well.[clxii]
Assignment:
Using this case as an example, discuss the distinction between Bugs (Glitches,
Gremlins), simple Goofs or Snafus, and the Unexpected Behaviors of Large
Systems.
Essay Questions for Advanced Students (Third Series)
1. For over a century and a half, the British Government was able to hide the
appalling death rate from drowning of British fishermen by classifying such
deaths under another heading. No one noticed, but eventually people did notice.
Assignment:
Discuss, using the concepts of Potemkin Village Effect, Output Phobia, and
the Functional Indeterminacy Theorem.
2. During the California energy crisis of 2000-2001, five private companies,

each of which individually had generating capacity adequate to make up the
deficit, kept their generators shut down, withholding 500 megawatts of energy
from the California market. Prices jumped from $40 per megawatt-hour to as
high as $1500 per megawatt-hour. Two major utility companies were forced into
bankruptcy. The state was plunged into debt as it was forced to spend billions of
dollars to buy power at inflated prices on the open market. “It sure looks
suspicious,” an observer said.[clxiii]
Assignment:
Discuss in terms of the Grand Illusion and System Goals.
3. Every optometrist knows to check the lens, after it is ground and polished,
in order to be sure that it conforms to the prescription. But the giant Hubble
Telescope was sent into orbit without this final check and was immediately
found to be hopelessly nearsighted. A billion-dollar correction was required,
involving three space walks and the fitting of extra lenses ground to an exotic
formula to correct for the telescope’s deficiency.
Assignment:
Discuss in terms of Grandiosity, Colossal Systems, and simple Glitches.
4. When an Atlantic storm threatened to drive the supertanker Amoco Cadiz
onto the rocks on the north shore of France, long-distance radio contact with
Chicago enabled the captain to get emergency instructions, not from a master
mariner, but from the high officers of the corporation. Control of the ship passed
from the Captain to the corporation’s Board of Directors. The Captain carried
out their orders as the Board ran the ship aground.
Assignment:
Taking as your title the theme ofSailing a Ship by Committee, discuss the
above in terms of group or Committee dynamics. Project the probable sequence
of events under Cheyenne Mountain in the event of nuclear missile attack. Draw
appropriate parallels.
5. So-called fast breeder nuclear reactors depend upon anuninterrupted flow of
molten sodiumthrough the reactor core to prevent a meltdown catastrophe.
Assignment:
Discuss in terms of basic design principles. Include in your discussion the
elements of mathematical Catastrophe Theory.
6. When Ignatz Semmelweis proved that deadly childbed fever could be
eradicated if physicians would only wash their hands between patients, the
physicians indignantly refused to do so. Semmelweis was transferred to a distant

province. Doctor Oliver Wendell Holmes applied the discovery in Boston with
great success. But decades later, Philadelphia physicians changed their ways
only after the leading citizens of the city banded together and burned down their
hospital.
Assignment:
Discuss in terms of Le Chatelier's Principle and Fear of Feedback.
156

45. Appendix III. Readers’ Tear-Out
Feedback Sheet
As indicated above, the preceding Catalogue represents only a preliminary
listing of the most basic and immediately obvious of the Systems Axioms. You,
the reader, may well be aware of one or more Systems Axioms that have been
omitted, or perhaps this work has stimulated you to think up some of your own.
Please use the space below to state it (them) in the briefest form commensurate
with ready understandability. New Axioms thus acquired will be submitted to a
panel of impartial judges (the author plus anyone nearby at the time) and the best
of them will be juried in for inclusion in succeeding editions (if any) of this
work. Here is your chance to achieve immortality, even if anonymously!
Axiom #1
Axiom #2
Axiom #3
157

46. Appendix IV. Horrible Examples
Whole Systems Catalogue of Outstanding Examples of the
Operation of the Laws of General Systemantics (“Horrible
Examples”)
DIVISION I: POLITICS
•Recognition is extended to the Nixon White House for a beautifully
coordinated series of examples of the operation of Systems-Laws dating back to
1968 and even earlier. We single out for special attention the truly classic
demonstration of the Newtonian Law of Systems-inertia. When the Watergate
story began to come out, the authors of the cover-up proceeded to try to cover up
the cover-up, thereby demonstrating that:
A SYSTEM CONTINUES TO DO ITS THING, REGARDLESS OF
CIRCUMSTANCES
(For advanced students, we also point out that the System had fallen into the
trap of Self-reference,q.v.)
•In May, 1983, President Reagan delivered an address to the 112th annual
meeting of the National Rifle Association in Phoenix, Arizona. Weapons were
prohibited, and members of the audience were scanned by metal detectors as
they entered the hall. A citizen later commented, in a letter to the editor of the
New York Times, “Gun controlis utilized when the President makes a speech
stating that he does not believe in guncontrol.”[clxiv]
Axioms involved:
SELF-REFERENCE; REALITY FADES
•In 2012, as the Western World careens ever deeper into financial insolvency,
classical economists continue to insist that the remedy is to impose more
“austerity” on the general population, who have already lost everything.
Relevant Concepts include: Nasal Spray Effect; Escalusion.
DIVISION II: ECOLOGY
•The United States Coast Guard and the Canadian Environmental Protection
Service have richly earned recognition for theirOperation Preparedness, a
proposal to study the effects of an oil spill upon the ecology of Lake Saint Clair
(above Lake Erie) by actually dumping jet fuel into the lake, a piece of Systemsbehavior representing a subtle blend ofUnexpected Outcomes, System Kicks
Back, and Outside Reality Pales.[a][clxv]

DIVISION III: COLOSSAL SYSTEMS (MARITIME AFFAIRS)
•Supertankers, those gargantuan vessels that carry as much as half a million
tons of oil around the tip of Africa to Europe and America, represent Colossal
Systems embedded in an even more Colossal System of oil production and
distribution. As such, they exhibit many features of interest to the Systemsstudent. For example, they have a draft of up to sixty feet—too deep for most of
the ports at which they call (Ships But They Can’t Dock), and indeed, too deep
for safe navigation of the English Channel and the North Sea.
To save money, their operators deliberately send them into the wildest water
on earth, some twenty miles off the Cape of Good Hope. Here, they are battered
by eighty-foot waves. Too massive to ride with the waves, they take the full
force of mountainous seas on their bows. But the captain, isolated on the bridge
a thousand feet astern, cannot see the bow of his own ship. The bow can be
smashed in without his knowledge. Even if he should suspect damage, he can do
nothing, as there is no way to get forward in bad weather—there is no belowdecks passage.
Supertankers are equipped with only one boiler and one screw. If either fails,
the ship drifts at the mercy of wind and wave. The one boiler provides electricity
for lights, radio and radar. This example of Bottleneck Designguarantees that the
slightest malfunction can be amplified into a major disaster. If the boiler fails, all
shipboard functions go dead within twenty minutes. An alarm system signals a
malfunction, butdoes not indicate where the problem is.[clxvi]
But these features of supertankers, while interesting, have little fundamental
significance for General Systemantics, since these defects of design and errors of
operation are glaringly obvious. Simple greed is not a Systems-functionper se.
Our attention is drawn to the following Unexpected Behavior: supertankers
exhibit an unexpected tendency to explode and sink on the high seas—not when
loaded with oil, but whenreturning emptyto their home port, an effect that may
be related to the oil- soaked atmosphere of the cavernous hold.

“Aunty” Awards for Horrible Examples of Systems Operation
(Second Cycle)
I. NUCLEAR ENERGY DIVISION
(This Special Awards Category was necessitated by the large number of
meritorious candidates in this field).
•In the State of Michigan, a large Nuclear Power Plant was adopted by the Air
Force as a practice targetfor low-level bombing runs by supersonic jet bombers.
(See Glossary, under CATASTROPHE THEORY; also under TANGLE). In

response to the demands of an aroused public, the bombers were instructed to
stay at least one thousand feet (approximatelyone second’s flying time) from the
plant.
•After an extensive investigation, the Atomic Energy Commission (now the
Nuclear Regulatory Commission), unable to figure out a way to safely burya
melted-down nuclear reactor, decided instead tobury their study.[clxvii]
•And at the Three Mile Islandnuclear power plant in Pennsylvania,
discussions continue as to how to dispose of two million gallons of intensely
radioactive water contaminated in the mishap there. Although the actual amount
of radiation released into the atmosphere was not especially large,
thepsychological falloutwas so intense that even now the citizens of Harrisburg
cannot be approached on this topic without special shielding.[clxviii]
•When the nuclear power plant at Three Mile Island went out of control, no
one was in the offices of the Nuclear Regulatory Commission, and the frantic
call for help had to be left with an answering service.[clxix]
•In 1983, the Nuclear Regulatory Commission learned that the failsafemechanisms by which a nuclear power plant is supposed to be automatically
shut down in the event of a malfunction do not indicatewhere the problemis. So
far from failing safely, these fail-safe devices do not even function safely when
they are working properly. Our present interest, however, is in the strange
element of Hireling’s Hypnosisthat allowed the Nuclear Regulatory Commission
and its predecessor, the Atomic Energy Commission, to remain oblivious to this
oversight for more than twentyyears—a Systems-delusion of the first magnitude.
[clxx]
•When the Fermi Number One fast breeder reactor in Monroe, Michigan, was
finally shut down after going into a meltdown sequence, operators were faced
with the task of retrieving an unidentified foreign object lying at the bottom of
forty feet of radioactive molten sodium.[b]
This involved building and manipulating (1) a heat-resistant periscope with
fourteen sets of lenses and (2) a forty-foot pair of pincers with two right-angle
bends in it. More than a year was spent in trying to pick up the foreign object.
When it was finally retrieved, it did not match anything on the blueprints of the
entire plant. Only then was it realized that the plant had been equipped with an
anti-meltdown device which had never been drawn in on the blueprints, and that
the object that had caused all thetrouble was in fact a piece of that device.[clxxi]
•At Three Mile Island: “One of the most important alarms—reactor coolant
pressure—is right next to the light that tells you the elevatoris stuck in the
turbine building.” With this arrangement, one could identifytwoproblems at the

same time—an admirable efficiency.[clxxii]
•“On March 20, 1978, a worker at the Rancho Seconuclear generating plant
near Sacramento, California, dropped a light bulb into an instrument panel. The
panel shorted out and the plant’s instruments went haywire, flashing fake signals
to the control systems. Cold water flooded into the reactor. . . With no reliable
instrumentation to guide them, control-room technicians kept the cold water
flowing, maintaining the combination ofunexpectedly low temperature and high
pressure for several hours.”[clxxiii]
II. ARCHITECTURAL DIVISION:
•In Boston, it was discovered by Full-Scale Trial that a glass-clad skyscraper
will twist in a cross-wind, popping out glass plates and rendering the streets
below uninhabitable.[clxxiv]
•In March, 1976, the U.S. Pavilion at Montreal’s Expo ’67, a giant plastic
geodesic dome treated with “fire retardant” caught fire and burned fiercely. Fire
engines arrived to find only blackened steel and a mass of liquid acrylic.[clxxv]
•Rain fallsupat the UN: in 1952, all five thousand windows of the UN
Secretariat had to be rebuilt when it was discovered that raindrops were being
driven upward into the double-hung windows.”[clxxvi]
•To avoid the labor of actually pushing the elevator call button, electronic heat
sensors have been installed in a number of modern skyscrapers. These,
responding to the warmth of a nearby fingertip, summon the elevators without
any actual contact with the call button. The device, sensing warmth, also calls
the elevators to thefloor where the fire is, obligingly opening the doors upon
arrival.
III. AERONAUTICAL ENGINEERING:
•Advanced-design airplanes have lost their doors, tail-cones, and engines in
mid-air, a problem not encountered by the Wright brothers, After intensive
investigation, a Systems-person was found who reported, “. . . the problem with
the cargo door was simply not urgent enough to workits way to the top of the
pile.”[clxxvii]
•Washington, D.C,’s National (now Reagan) Airport has a better-than-average
safety record, despite its hazardous features: “It was safe because it was bad. It
kept pilots alert.”[clxxviii]
•The worst aircraft accident in history, a collision between two loaded 747
Jumbo Jets, took placeon the ground.
IV. RAILWAY ENGINEERING:
•The highest passenger railway in the world, the Peru-Andesrailroad, recently

replaced its 1,300 horsepower steam engines with diesel locomotives of 3,000
horsepower, for greater speed and pulling power. Unfortunately, the diesel
locomotives lose almost all their horsepower above 12,000 feet, a fact which was
realized only after they began to fail in actual operation. The railroad must now
usetwo diesellocomotives where beforeone steamlocomotive was enough.
[clxxix]
V. BUREAUCRATIC DIVISION:
Victory for the Antikilopascal Lobby:
•The World Health Assembly in May, 1977, recommended banning the use of
the millimeter of mercury as a unit of measurement in medicine (as for blood
pressure). Instead, they recommended the kilopascal. Six years later, unable to
find a doctor who could define the word “kilopascal,” the EuropeanCommission
gave up trying to implement the recommendation.[clxxx]
VI. ELECTRICAL ENGINEERING:
•Mr. Kirkpatrick Sale has noted that the great New York City blackout of July
13, 1977, was triggered by the fail-safe mechanism built into the Consolidated
Edison Company’s electrical System. To protect the System from overload, a
load-shedding mechanism was built in. When the System sensed overload on the
night in question, it began load-shedding so vigorously that there was
anoversupplyof power to the remaining elements of the system, and the gigantic
generators shut down to prevent a burnout.
But the crucial factor in this episode was that the Systemcould not restart
itself. It was built in such a way that electrical power was needed to start the
System as well as to keep it running. The System, which was designed to
generate electricity, could only function if there was an uninterrupted supply of
(you guessed it)—electricity. Auxiliary power for this purpose had always before
been brought in from outside sources, but the line bringing in this power had
been knocked out by lightning earlier in the evening.[clxxxi]
This is a classic example of a SYSTEM THAT CAN BE STOPPED BUT
CAN’T BE STARTED AGAIN (without outside help). DESIGNED NEVER TO
BE STOPPED, IT NEVERTHELESS WAS STOPPED (by a malfunction of its
own fail-safe mechanism) and was then found UNABLE TO RESTART
ITSELF.
VII. THE MILITARY
•The latest model Tanksfor the U.S. Armed Forces are so designed that the
engine must be removed in order tochange the oil, a procedure that must be
performed every few hundred miles. Huge cranes—themselves appropriately

armored—must follow the Tanks into battle to ensure prompt servicing.
VIII.
SPECIAL
AWARD,
COMPUTERIZED
HEALTH
SERVICESDIVISION
•A special Joint Award goes to two anonymous sources for calling attention to
a large urban medical center, newly constructed, in which the bolts of all doors
are electronically activated from a central computer located in another building
farther downtown. When the computer went awry—as happened within the first
six months of operation—all doors, including fire doors, remained bolted shut
and everyone, staff and patients alike, remained locked in the rooms they were
occupying at the moment. Crowbars were needed to free them. Only then was it
realized that the treatment rooms lacked two-way communications. Then the
lights went out and the further discovery was made that there was no back-up
emergency lighting system.
So far, merely a straightforward example of Grandiosity leading to Bad
Design. What sets it apart as a true classic of Systems operation is the fact that
the medical center had just beenawarded a prizefor outstanding excellence of
architectural design.

Horrible Examples, Third Cycle:
I. HYPNOTIC METAPHOR DEPARTMENT
The Army Corps of Engineers and Flood Control
•For almost a century, the U.S. Army Corps of Engineers has entertained a
concept of flood control that could be summed up in the phrase, “Get rid of all
that water.” To that end the Corps has assiduously pursued a policy of raising
banks and levees and deepening and straightening river channels. As a result, the
Mississippi River basin, which once resembled a great sponge with many
thousands of square miles of swampy lowlands available to soak up and
sequester flood waters, now resembles a great sewer pipe a mile wide and fifteen
hundred miles long. Each Spring the entire runoff of the Mississippi basin
hurtles down the pipe at high speed, producing the potential for catastrophic
failures of restraining walls and the threat of superflooding in the Delta area.
And, as in the case of the Nile River in Egypt, the fertilizing silt is deposited far
from the fields that need it.
The Student is invited to consider in some detail what the consequences might
be of approaching this problem using a “sponge” (Ecological) metaphor rather
than a “plumbing”(Engineering) metaphor.
Women’s Suffrage and Freedom to Smoke Cigarettes:
•Early in the Twentieth Century, Mr. Edward L. Bernays (a nephew of
Sigmund Freud) used Reframing through Renaming to achieve certain personal
and commercial goals. Placing himself in the pay of the tobacco interests, he
forged an indissoluble link in the minds of women between cigarette smoking
and the Women’s Suffrage Movement. For a rich fee, he named and reframed
cigarettes as “Torches of Freedom;” and to drive home his point he had the
debutantes of New York march down Fifth Avenue in their Easter finery, puffing
on cigarettes. In one stroke Mr. Bernays did more than any other single
individual of our era to establish the freedom of women to participate in the
smoking-induced epidemic of lung cancer, respiratory disease, heart attacks, and
stroke.
(Relevant concepts for analysis of this Horrible Example include Hypnotic
Metaphor, The Sorcerer’s Apprentice, Reframing for Personal Gain (System
Kicks Back), and The Naming Fallacy.)
II. ANEMIC FEEDBACK (THE AGE OF UNDESIGN)
Once more we are forced to invent a clumsy and all-too-easily forgettable

circumlocution for a phenomenon rampant in modern society but almost
nowhere acknowledged: the reluctance of designers in the very Age of
Cybernetics to incorporate adequate provision for Feedback into the design of
the systems on which we all depend.
•A trivial Example is the Idiot Light on the dashboard of many modern cars
that flashes the message: “Check Engine”—failing to give any hint of the type or
even the location of the problem. Indeed, the most common problem is that the
Light itself has become stuck in the “On” position, with the result that most
motorists simply ignore it.
•In Henan Province (China) a few years ago, two huge dams failed during a
flood. Engineers had tried to open the sluices but half of them were silted up. As
the flood waters rose higher, the dams burst apart, drowning 100,000 citizens in
the greatest man-made human catastrophe of modern times. Questions: (1)
Should a dam be built with enough strength to hold water all the way up to the
brim? (2) Should the design include a gauge to register the amount of silt in the
sluices? Should the gauge include an alarm set to go off when silting reaches a
certain level?
•The recent conflict in Aghanistan was marked by a momentary flap over
certain “smart bombs” that allegedly failed to seek out and destroy their targets.
It was alleged that their batteries were dead. A smart bomb with dead batteries
reverts to being a dumb bomb. In none of the news reports was any mention
made of the fact that the bombs were not designed in such a way as to reveal to
the user whether the batteries were live or dead. Such feedback is in universal
use in home smoke detectors, but apparently no one bothered to build it into the
design of the bombs.
III. EXEMPLARY DISASTERS, OLD AND NEW
This Department, introduced in the Third Edition, will deal with Horrible
Examples chosen for their complexity and exemplifying the Gravitational
Tendency of errors to accumulate, to pile up and eventually overwhelm
enterprises of magnitude. Typically these examples demonstrate such a degree of
interweaving of Systems-violations as to make retrospective analysis tedious and
intricate. The reward, however, for the serious Systems-student, is not only a rich
trove of individual and singular errors, but also a more comprehensive and
realistic view of how big disasters really happen. Bad planning, per se, is not the
focus of Systemantics.[c] [clxxxii] [clxxxiii] Our concern is with the
paradoxical, even delusional, consequences that can flow from even the best-laid
plans that involve systems of any degree of size or complexity.

The Great Railroad in the Sky (The Air Transport System Versus the People
Transport System)
•Mass Transit systems, being by their very nature large systems, offer a
myriad of paradoxical, even bizarre exemplifications of Systemantic principles.
A quick glance at the U.S. System of Air Travel, for example, reveals a number
of interesting findings. The system is designed like a wheel, with spokes
radiating from several hubs, such as New York, Atlanta, Chicago. Clearly, this
system is designed to simplifyits own logistics. This is the design that requires
the smallest number of airplanes carrying the largest number of passengers. The
passengers are herded together in mobs and masses at the great hubs. The daily
inconvenience to millions of passengers of having to travel from their homes to
the hubs and back again by private car, bus, taxi or limousine is nowhere figured
into anyone’s account sheet of the cost of air travel. Besides, it enriches the other
entrepreneurs who own taxi fleets, busses, auto companies. . .Put quite simply,
the people pay in money and inconvenience so that private airline companies can
maximize their profits. The illusion of efficiency so created can only be
maintained by ignoring the cost to the citizen.[d]
Hypnotized by a definition of the System that leaves out its real purpose
(convenience for the citizen so as to enrich the entire nation)[e], entrepreneurs
and politicos alike look at this shambles and see “efficiency” and “economy.” In
this inverted world view, the transportation system is more c successful, the less
it meets the needs of the citizens. Indeed, the big airlines are now busily engaged
in “phasing out” the less-profitable small feeder airlines (owned by them) that
carry passengers to the big hubs.
Meanwhile, since the railroads are not “paying their own way,” they are to be
eliminated, thereby forcing people to travel by airplane or automobile at vastly
higher rates of energy consumption. A typical jet passenger plane burns three
tons of fuel per hour. With ten thousand flights in the U.S. per day (1983), this
comes to a ballpark estimate of 30,000 tons per day or ten million tons per year,
for the purpose of lifting 20% of the U.S. population thirty thousand feet into the
air and carrying them where they could have gotten on the ground at far less
energy cost.
But there is another cost—that of outright human injury, suffering, and death.
Automobiles in the U.S. are involved in 22 million accidents per year—40,000
or more deaths and 4 million injuries (500,000 permanently crippling injuries per
year), at an estimated annual cost (in 1983 dollars) of 220 billion dollars. Autos
are now the leading cause of death in the age group from 1-24 years of age.
Buses are 250 times safer than automobiles, railroad trains are 72 times safer;

local transit (such as streetcars) is 5,200 times safer than automobiles.[clxxxiv]
The Student is invited to approach the analysis of this Example using such
concepts as Hypnotic Metaphor (“Transportation System” lacks the highly
relevant component of “Life-Threatening Epidemic,” for example) together with
the more familiar Axioms such as System Encroaches. Include calculations of
the cost of an automobile if the auto companies had to pay for road construction;
of the cost of a plane ride if the airlines had to pay for the terminals.
The Spanish Armada
•The Spanish Armada provides many instructive examples of how a great
enterprise can fail. Catastrophe Theory is the relevant concept. Certain
configurations are irretrievable, or nearly so.
(a) The Admiral of the Spanish fleet, the Duke of Medina Sidonia, was a
landlubber with no experience of ships or naval warfare. This mistake (the
appointment of an Admiral with no experience) was not irretrievable, but it was
a premonitory signal that irretrievable mistakes would probably be made in the
future.
(King Philip's staff, who made the appointment and who threatened the Duke
with disgrace when he tried to reject the appointment, apparently believed that
they were still living in the Middle Ages, and that the duty of fealty was
sufficient guarantee of compliance.)
(b) The Armada was given two assignments, each of which was very difficult
to carry out. The task of completing both assignments was far more difficult than
either task singly. The assignments were:
(1) to engage and destroy the English fleet.
(2) to rendezvous with the Duke of Parma in Flanders and transport his army
to England, offloading them in London in order to sack London. Failure to
achieve task (1) would make the achievement of task (2) well- nigh impossible.
But achieving task (1) could hardly be done without losses, probably of
staggering magnitude. So even if task (1) did get carried out, the Armada would
probably be too crippled to carry out task (2). —Well, you get the idea.
Task (2), the rendezvous with the Duke of Parma, required that the latter know
when the ships were coming. The Admiral, the Duke of Medina Sidonia, sent
many letters to the Duke of Parma while on the High Seas of the stormy North
Atlantic, but unfortunately there were no letter drops available and his letters had
to be carried by smaller boats from ship to shore and then overland. The Duke of
Parma thus got his first notice that the Armada was under way on the day before
the ships were to arrive in Flanders. He had no time to mobilize his army for

embarkation.
(c) As soon as the Armada left port, it encountered major Atlantic storms that
delayed it for weeks, using up valuable supplies of food and water and tiring the
sailors. There was no contingency plan in case of bad weather. Once launched,
the plan (and the Fleet) had to continue along on the prescribed course.
(d) When the Armada entered the Channel, the wind and ocean currents were
in their favor. The English Fleet, watching and waiting warily in their harbors,
saw to their amazement and delight that the Armada was drifting past them.
They promptly sailed out and in effect jumped upwind of the vast Armada. From
that point on, the English had the advantage. The Armada had allowed itself to
drift into an irretrievable configuration.
(e) The Spaniards were expecting to fight a traditional medieval sea battle, in
which galleons grappled each other and the soldiers fought hand- to-hand.
Accordingly their galleons were built with decks high above the water. But the
English had no intention of engaging in that way. They intended to destroy the
enemy’s ships with firepower. The English ships, built low, were able to come in
under the Spanish guns and sink the Spanish galleons with cannon-fire.
(f) The Armada did actually get as far as Flanders, where they anchored, but
the English sent fireships among them at night, creating panic and causing them
to cut their cables and drift out into the North Sea. To get back to Flanders to
pick up the army of the Duke of Parma, they would have to fight wind and
strong adverse currents—plus the English fleet. This they could not do. But there
was no other safe place to go. They were forced to sail North, to make the
perilous trip around the Hebrides and Ireland without any safe port of call, a trip
of many weeks’ duration. But their supplies of food and water were running out,
first, because of the delays occasioned by Atlantic storms, and second, because
Sir Francis Drake, even as the Armada was being fitted out in Spanish ports, had
earlier burned their supply of seasoned barrel staves for making tight casks to
carry food supplies and fresh water. Et cetera.
We would not want the reader to infer from this that the English were immune
to catastrophic errors. Two hundred and fifty-some years later, during the Great
Hunger, when Ireland was perishing from lack of food, English ships were
despatched to carry grain to the West Coast of Ireland. The ships could not land
because there still were no suitable harbors on the West Coast of Ireland.
Indeed, it was ascertained (after the fact) that the English Navy, two hundred
and fifty years after the Armada, still hadno mapsof the West Coast of Ireland.[f]
160

Antics Entry Blank
The space below is set aside to provide an opportunity to Systems-students of
every discipline to register their own contenders for the Annual Aunty Award
Contest. The rules are simple: describe (as briefly as possible) your Horrible
Example. Provide documentation or enclose the original report. Indicate which
Axioms (in your opinion) are involved. Write in your name and address. Then
mail this page to us.
HORRIBLE EXAMPLE:

Reference or other documentation: Axioms involved: Your name and address:

You may submit as many entries as you like, using a format similar to the
above.[a]
167

47. Appendix V.Glossary
ANERGY.
The negative of energy. In biological systems, torpor. The amount of effort it
would take to clean up some situation you don’t like. Anergy resides within
messy situations as energy resides within a coiled spring. A coiled spring is full
of energy. When fully uncoiled, it is full of Anergy. A boulder at the top of a hill
is full of energy. After it has rolled to the bottom, it is full of Anergy.
AXIOM. AXIOMATIC METHOD.
The logical and necessary approach to developing the science of General
Systemantics. The traditional approaches ofObservationor ofExperimentare
clearly inadequate; the former because progress bogs down in impenetrable
swamps of data, the latter because experiments upon systems invariably distort
them beyond recognition.
The correct approach is to enunciate the Axioms from the start andthento
show that they apply universally with only apparent exceptions. All that is
necessary is tothink very clearly, at the most fundamental level, and then to state
one’s clear thoughts in the briefest possible way. This saves endless bother. The
result is an AXIOM; and it will be found to be at least as accurate as any
generalization achieved in more conventional ways. Euclid used the method to
advantage; so can we. And everyone knows how successful it has been in the
hands of Descartes, who looked within himself andsaw very clearlythat he was
thinking. The Axiom, “I think, therefore I am,” emerged with disarming ease and
spontaneity.
BACKUP SYSTEM.
The backup systemis the one that gets blamed for failing to work after the
Primary System, which was not supposed to fail, fails. The Backup System is
there to take the blame and thus divert attention from the fact that the Primary
System, in failing, failed to perform as intended. Even more interesting, from the
System standpoint, is the case where the Primary System fails in anunexpected
way, either failing to trigger the Backup System or leading it to believe that
some other type of failure has occurred. In sophisticated Systems with multiple
Backup Systems, this 1 leads to acascade of failures,[clxxxv] with sequential
breakdown of Backup Systems, resulting in the final state known as a TANGLE
(q.v.).
Even more fascinating is the special case in which theoriginal failureoccurs
within the Backup System, causing it to try to seize control from the normalIy

functioning primary system. This effect is regularly exhibited by those
chronically unstable governments that attempt to use the Army or a Palace
Guard[clxxxvi] as a Backup System. Suspecting that the Government has
become too unstable to govern, the Guard steps in, thereby disrupting the
Government and making their own suspicion come true. For those whose taste is
for Science Fiction rather than History, we cite the example of HAL-9000, the
computer in the movie “2001”, which attempted to take over the mission from its
human partners.
CASCADE OF FAILURES.
The usual sequence of events by which a System fails, following the failure to
contain the initial failure. See BACKUP SYSTEM, TANGLE.
Example:
The classic example to date is the incident at Three Mile Island, where a small
pressure-relief valve stuck open, lowering the pressure and the level of coolant
water in the reactor. Unfortunately, the valve was located in the Pressurizer,
which contained a sensing unit whose purpose was to detect and to record the
pressure and level of coolant water. Thus, a Feedback Unit (the pressure-relief
valve) was located inside another Feedback Unit (the pressurizer), a doubly selfreferential arrangement that routinely leads to trouble (see SELF-REFERENCE).
By allowing steam to escape from the Pressurizer, the stuck valve led the sensing
unit to report (erroneously) that the water level and pressure in the reactor itself
were rising when in fact they were falling. The water was in fact escaping from
the reactor at high speed (as steam) through the stuck valve. From this point on,
the backup Systems, including the human operators, were hopelessly confused,
and attempts to intervene simply made things worse.
After three days of chaos, during which multiple backup systems were
fighting each other (and the human operators) for control of the reactor, the
following events had occurred: the reactor core was exposed to the open air and,
deprived of its coolant water, heated up to more than four thousand degrees,
destroying all 36,000 fuel pins; a massive hydrogen explosion occurred (or
didn’t, depending on your source) in the containment building which housed the
reactor; the reactor became one of the most radioactive objects ever created by
man; large amounts of radioactivity were transferred to two million gallons of
coolant water which was inadvertently pumped into another building, bursting
the storage tanks there and flooding the building with highly radioactive water;
and a total meltdown (“China Syndrome”) was narrowly averted, perhaps by
only a matter of minutes.

This situationmeets the definition of a TANGLE in that the resulting problem
of dealing with the radioactive wreckage of Three Mile Island is far more
difficult and expensive than theoriginal problemof generating electricity from
nuclear energy. (See also: ANERGY). As a comparison: When running properly,
the plant could be operated by a handful of personnel. But the cleanup crew for
the crippled enterprise numbered, at last count, approximatelyten thousand.
CATASTROPHE THEORY.
The study of Systems you can fall into but can’t fall out of. See TANGLE. In
this context one should note Agnes Allen’s Law:[a]
ALMOST ANYTHING IS EASIER TO GET INTO THAN OUT OF
CHAOS; CHAOS THEORY.
The way the world really works. The mathematical basis of Systemantics.
Easy enough to see once you get beyond “simple vision and Newton’s sleep.”
COMMUNICATION.
That which passes between the parts of a System, causing them to act as they
do. See INFORMATION. The pragmaticmeaningof a communication is the
subsequent behavior of the Part addressed. Other Parts may and usually do
respond also, and the behavior of those Parts is also part of the meaning of the
communication, even when they were not knowingly addressed in the first place,
and even when their subsequent behavior was totally unexpected.
COMMUNIQUE.
A message with a twist, designed to influence behavior whilst purporting to
inform.
CONSTANT.
A feature of a System that has not yet been observed to vary. See
PARAMETER (footnote k, p. 94). Formal Mathematics has been slow to
recognize that as constants get larger, they tend to turn into Variables. A list of
ten items tends to remain stable, each item faithfully retaining its assigned
number. With a list of three hundred, or three thousand, however, no such
comfortable assumption can be made. One can never be sure that Item Number
274 isn’t really the 275th, or the 273rd, in sequence. And if additions or
subtractions are to be made, the situation rapidly deteriorates. Under such
conditions, the concept “constant” becomes as tenuous and nonfunctional as
“entelechy” in philosophy or “instinct” in biology. With these considerations in
mind, one can readily understand why Jehovah limited His commandments to
the double handful, despite the fact that He doubtless could have imposed many

more.
CREATIVITY. SCIENTIFIC.[clxxxvii]
The art of finding problems that can be solved. In GeneralSystemantics
theory: the art ofrecognizing simple Systems. Often enough, the creative act
consists of recognizing the simple System buried in the messy Problem—i.e., of
restating an existing Problem in such form that it can be solved. See
REFRAMING.
DEJA VU (ALL OVER AGAIN).
The recurrence of a catastrophic event that had been thought impossible
thefirsttime around.
Example:
The crew of a nuclear reactor, in performing a “hot shut-down” of the reactor,
disregarded previous instructions and opened the valves that maintain the
pressure of the coolant water. The coolant water started to boil away, and in
fifteen minutes the cooling system had lost nearly 20% of its pressure. At this
point, alarm bells went off and the crew, realizing their error, closed the valves.
The reactor stabilized itself and no meltdown occurred.
Three Mile Island?No. Monticello Nuclear Power Plant, 40 miles northwest of
Minneapolis-St. Paul.The 1970's?No. October 24, 2001.[clxxxviii]
EFFICIENCY.
Before one can estimate Efficiency, one must first decide thefunctionof the
System. Since most large Systems have multiple functions, many of which are
not apparent on casual inspection, estimating Efficiency is tricky, to say the least.
EFFICIENCY EXPERT.
Someone who thinks s/he knows what a given System is, or what it should be
doing, and who therefore feels s/he is in a position to pass judgment on how well
the System is doing it. At best a nuisance, at worst a menace, on certain rare
occasions a godsend.
EVALUATION.
The process by which the System ascertains that the work it has done is
genuinely good. Compare Genesis 1:31. Advanced Systems periodically review
and evaluatetheir own evaluation procedures. This produces an infinite
regression or incestuous process[b]but no one pays any attention tothat.
EXPERT.
A person who knows all the facts except how the System fits into the larger

scheme of things. Compare SPECIALIST, q.v.
FRANKENSTEIN, FRANKENSTEIN MONSTER.
Since Mankind in its reluctance to acknowledge the existence of undesired
entities has failed to invent a word for A SYSTEM THAT CAN BE TURNED
ON BUT CAN’T BE TURNED OFF, this awkward metaphor must be pressed
into service. Readers are invited to submit their own ideas for a more elegant
terminology.
FUNCTION.
In large Systems, an intangible attribute not susceptible to easy definition.
Often equivalent to whatyouthink the System is doing, or whetheryouthink it is
doing it.
GARBAGE.
A product of a System, for which noimmediateuse is apparent. The point to
remember is that ONE SYSTEM’S GARBAGE IS ANOTHER SYSTEM’S
PRECIOUS RAW MATERIAL. Clearly Garbage, like Beauty, is in the eye of
the beholder, and the amount of Garbage in the world is a function of the
viewer’s imagination and ingenuity.
GOAL.
Whatyouwant the System to do. The designed-in Function of the System is
usually something very different.
GRANDIOSITY.
(1) Failure to use the qualifier “some” when indicated. Results in a distorted
Mental Model of Reality, which then leads to inappropriate action.
(2) In practice, the attempt to alter more than three variables in a System at
one time. The belief that one can go from the existing System to some desired
System without passing in an orderly fashion through the necessary intermediate
stages.
INFORMATION THEORY.
The scientific discipline that treats Information as a bulk commodity like
potatoes, to be weighed out without reference to the quality of individual units.
Within this framework, a message such as “Let there be light!”, if enunciated
without mumbling, has exactly equal weight with, “Winston tastes good, like a
cigarette should.”
INTELLIGENCE, ARTIFICIAL.
At a number of advanced scientific centers around the world, serious studies

are being directed toward the nature of intelligence itself. Presumably, some time
within the next half-century or so, this problem will be resolved.We will then no
longer have to think about it.
LOGIC BOMB.
A Special Requirement of a System such that, if the Special Requirement is
not satisfied, the System self-destructs. The point is, just because no one
deliberately planted a Logic Bomb in your System, that doesn’t mean there isn’t
one or more of them lurking there, inadvertently structured in by yourself when
you built the System.
NONREDUNDANT DESIGN.
Briefly, this means using only one main bolt, as in freeway bridges and swingwing fighter planes. Nature long ago abandoned nonredundant design except for
throwaway situations, where the redundancy is transferred to the entire unit or
individual. Nonredundant design is adopted where loss of the System is judged
less bothersome than the cost of the safety features.
OBJECTIVE.
A lesser goal, greater than a Sub-objective but not sufficiently grand to be an
End-in-itself. A logical fraction of a Total Goal. Example: If the GOAL is to
resolve the structure of DNA, an Objective might be to resolve the left end of the
molecule. A separate team of workers would logically be assigned to this
Objective.
PALACE GUARD EFFECT.
See BACKUP SYSTEM.
PROBLEM.
When spelled with a capital letter, the Problem is the System Goal cast in the
interrogative mode. It represents the old, inadequate conceptualization of the
real-world problem. Examples: “Cancer” is a self-defeating conception of the
problem of new growths. Similarly, “mental retardation” is useless as a basis for
launching a successful solution of the problem of poor intellectual function.
Compare the “ether” problem that plagued nineteenth century physics or the
“phlogiston” problem that bedeviled eighteenth century chemistry.
PSYCHOANALYSIS.
An attempt to understand the Mental Model inside a person’s head without
peeking at the Reality System it is modeling. Based on the assumption that the
Reality System doesn’t matter very much, anyway.
REFRAMING.

The act of recognizing that the components of System “A” fit even better into
System “B”. The art of imparting this awareness to another person.
RUNAWAY. POSITIVE FEEDBACK TRAP.
The reader who, in attempting to slow down his/her vehicle, has inadvertently
stepped on the accelerator, has a gut-level appreciation of this term. Failure to
realize that one’s foot is on the accelerator rather than the brake constitutes the
POSITIVE FEEDBACK TRAP. Things will only get worse, and fast.
SELF-REFERENCE.
This sentence is a good example of Self-reference. Self-reference is usually
ignored or disregarded until it makes trouble. Problems resulting from Selfreference can’t be resolved by ordinary methods. The Self-reference must be
recognized and dealt with. A special case of Self- reference is the Feedback loop
within a Feedback loop. In such a doubly self-referential system, paradoxical
behavior is routine. At Three Mile Island, a pressure-relief valve was located
within a pressure-sensing device, thus establishing a Feedback Loop within a
Feedback loop. The rest is history.
SHUT-DOWN.
A fanciful term applied to a System when one has discontinued some aspect of
the System’s functioning that one happens to be aware of. In the case of Three
Mile Island, “Shutdown” meant the production of only 30 million watts of heat
from secondary radioactivity after the primary neutron flux had been quenched.
The coolant liquid must of course continue to circulate or the “shutdown” reactor
unit will melt down.
SPECIALIST.
One who never makes small mistakes while moving toward the grand fallacy
(McLuhan). Compare EXPERT, q.v.
SYSTEM.
“A set of parts coordinated to accomplish a set of goals. ” Now we need only
define “parts,” “coordinated,” and “goals,” not to mention “set.”[clxxxix]
SYSTEMANTICS.
1. The strange behavior (“antics”) of complex Systems.
2. The scientific study of the antics of complex Systems.
3. The art of coping with such behavior; the art of responding appropriately to
messy problems. And what does “appropriately” mean? We recommend that it
be interpreted as broadly as possible, over the entire range of possible meanings
from “avoidance of catastrophe” to “rapid, effortless success.”

SYSTEMISM.
1. The state of mindless belief in Systems; the belief that systems can be made
to function to achieve desired goals.
2. The state of being immersed in Systems; the state of being a Systemsperson. (See Chapter 8: Inside Systems.)
SYSTEM, LARGE.
When is a System “large,” “very large,” or even “too large”? Two schools of
thought are recognized: (1) the “beats me” school, founded by Ashby[cxc]: “a
system is ‘very large’ if in some way itbeats meby its richness and complexity.”
(2) our own “buried in by-products” school. This school suggests that a
System is “too large” when your back yard begins to fill up with its byproducts.Mutatis mutandis, a city is “too large” when its streets become clogged
with garbage, abandoned cars, etc. At a slightly more abstract level, a city is “too
large” when municipal employees outnumber other workers or—more generally
still—when staving off disaster due to threatened collapse of the System
becomes the predominant task of thecitizens.
SYSTEMS-PERSON.
For purposes of recognition, a Systems-person is someone who wants you to
really believe or (worse) really participate intheirSystem.
SYSTEM-SEMANTICS.
The study of the changes induced in the linguistic habits of a Systems-person
by immersion in the System. A valuable clue to the Mental Model of the System
held by the Systems-person. See Chapter 21: TALKING TO THE SYSTEM.
SYSTEM THEORY.
There are some who assert that General Systemantics represents a spoof of a
serious scientific subject called General System Theory.[d]Devotees of General
System Theory attribute the founding of their science to Professor Ludwig von
Bertalanffy,[e] who noted, in the early decades of the twentieth century, that
scientists had overlooked the establishment of a Science of the Whole Thing,
and who, with Teutonic thoroughness, made up the oversight.
TANGLE.
A System you can fall into but can’t fall out of. See: CATASTROPHE
THEORY. Related Theorem: THE DOG ALWAYS WALKS ON THE SIDE OF
THE BODY OPPOSITE THE HAND HOLDING THE LEASH. Correlative
Stratagem: IF YOU WANT THE DOG TO SWITCH SIDES, MOVE THE
LEASH TO THE OTHER HAND.

THE WILL ROGERS PHENOMENON.
A campaign for earlier diagnosis of cancer will produce encouraging
improvements in length of survival, which will later be shown to be the result of
earlier diagnosis resulting from the campaign.
(How does this relate to Will Rogers? Will Rogers once remarked that the
migration of Okies from Oklahoma to California resulted in a rise in IQ for both
locales.)
UNIT OF CATASTROPHE
As systems get larger, the Unit of Catastrophe becomes larger. New Units of
Catastrophe appear.
173

48. Appendix VI. Animal Exemplars
The Cybernetic Dog and the Analogic Cat: A Partial List of
Animals (Living, Mechanical, or Mythical) that have Contributed
to our Understanding of Systems.
(The contribution of living creatures to our understanding of Systems—which
is more extensive than generally suspected—remains largely unsung. It is hoped
that this modest list will serve as an introduction for those who have not
previously thought about this topic.)
1. The Prepunctuated Polar Bear.
Trapped inside own Mental Model, paces in a rectangle even after the cage is
removed.[cxci]
2. The Self-actuating Laboratory Rat.
Probes the System even when zapped with electricity.[cxcii]
3. The Cybernetic Sleeping Dog.
Transcends mere vectorial response, responds to the perceived intent of the
kick.[cxciii]
4.The Innovative Dolphin.
Understands the command, “Do something you’ve never done before.”[cxciv]
5. The Phenomenological Ferret.
Refuses to look for the rabbit it has already eaten in the burrow where it ate it.
[cxcv]
6. The Self-Reflexive Rhesus (Peeping Primate).
Obsessively observes the Observer observing the Primate.
7. The Ericksonian[a] Otter.
Refuses to do anything twice in the same way and therefore can’t be operantconditioned.[cxcvi]
8. The Whole Dog Spot.
Responds in an integrated way to communications, provides shining example
of how we and our Systems could do it.
9. The Analogic Cat.
Adept at non-verbal communication, acts like a kitten to get milk.[cxcvii]
10. The Phlegmatic Frog.

Fails to jump out of a pan of gradually heated water.[cxcviii]
11. The Bread-and-Butterfly.
Victim of a mortal double-bind: dies if it eats or not.[cxcix]
12. The Electric Turtle.
Lacking brains, fights nevertheless.
13. The Ouroboros.
Devours itself tail-first, thus acting out self-reference.[cc]
14. The Deregulated Dinosaur.
Extra brain in tail; tail wags itself.
15. The Extra-large Tsetse Fly.
Reminds us that the Model is not in all respects just like the Real Thing (The
Map Is Not The Territory) and also that although Every Picture Tells a Story, it is
we who make up the story. (See Note 80, Chapter 19.)
16. The Dog That Did NOT Bark in the Night (Doyle’s Dog)
(thereby sending a very loud message to those who could hear silence). [cci]
[b]
175

49. Appendix VII. List of Horrible
Examples
A
A. G. Bell invents telephone, retires to phone-free island.
Absolute despot can’t make country function, is prisoner of own bureaucracy.
Acid Rain harmful? U.S. elects to study the problem indefinitely
African nation builds medical school and hospital, now has no money for health
care.
After sixteen years of experience in the School System, a student can be
expected to be expert. . . at being a student
Air Force General is surprised to learn that submarines actually travel under
water
Air Travel System increases “efficiency” at expense of passengers
Airborne radio antenna, five miles long, plays snap the whip with mother ship
Airplanes of new design tend to lose major parts in mid-air
Alexander Fleming’s bacterial cultures are bugged by a fungus; Fleming notices,
isolates bug-killer
Americans in 1942 forget to arm their merchant ships, lose 400 of them to
German submarines in first six months
An austerity budget, proposed and implemented by a Conservative
administration, results in the largest deficits in U.S. history
Antiballistic Missile System rushed to completion on grounds of security,
promptly abandoned as not needed—and unworkable anyway
Aquatic life clogs cooling pipes of nuclear power plants
Army Engineers dig Everglades Canal, State of Florida fills it in; taxpayers pay
for both operations
Aswan Dam generates vastly increased need for electricity
Atomic Energy Commission releases its estimate of meltdown risk just in time
for Three Mile Island
Atomic Energy Commission tries to bury meltdown study
Author of “Knowledge is Power” chills own Bacon
Authorities propose to study ecological effects of an oil spill in Lake St. Clair by
actually pouring oil into the lake
Auto Industry builds cars for profits, not transportation
Automated mop cart attacks visitors in hospital hallways

Automatic Pilot fights with cabin thermostat for control of ship on World War II
high-altitude bombers
B
Babbage’s Calculating Machine seizes up, teaches the world (1) Internal Friction
is a power to be reckoned with; (2) Pushing on the System won’t overcome it
Bakolori Dam planners overlook human factor; no wheat gets grown
Bankrupt railroad System continues to fail under government auspices
Barbara McClintock chooses boring research problem, gets little support for
forty years, wins Nobel Prize
Beltline Freeway lacks exit ramp to city
Bible with typo advises, “Sin on more.”
Bismarck embraces Socialism when informed it’s Militarism in disguise
Botanist unable to formulate own Goals and Objectives, comes to grief
Boy Scout movement popularizes Scouting—not wilderness camping
Brazilian government campaigns to get citizens to smoke more tobacco
British Commonwealth based on principle of voluntary association, remains
attractive
British fishermen drown at record rate; Britain drowns the data for two hundred
years in a sea of statistics
British Kings reign but do not rule; monarchy remains stable
C
Campaigns to Conquer Cancer produce uncontrollable overgrowth of
publications
Canada breaks up Trans-Canada railroad, slices ties that bind nation together
Career hospital patient achieves 207 hospital admissions (all free) while in good
health
Celebrities receive still more publicity because they are “well known”.
Cheops’ Pyramid stands; Egypt falls
Cigarette smoking reframed as suffrage issue, women’s health suffers
Colorado River rapids in the Grand Canyon successfully run by entering them
stern first and rowing hard upstream
Computer errors found proportional to fourth power of number of vacuum tubes
Computer goes berserk, no one turns it off
Computer tallies votes, then won’t tell
Computer-defended ship is sunk by “friendly” missile
Computerized hospital security system locks doors by remote control; bolt

cutters needed to rescue patients
Computers convulse over Nylon hose, frosted soft drinks
Computers demonstrate unexpected compatibility with teenage mind
Computers with a failure rate of one in a million are manufactured by companies
with a failure rate of one in three
Con Ed’s load-shedding mechanism works too fast, generators shut down to
protect them from too little load, then can’t be restarted because the power’s off
Congress exempts itself from its own laws
Control panel at Three Mile Island has stuck elevator alarm right next to reactor
coolant pressure alarm, permitting correction of two problems at once
Cordless telephones ring up the emergency hotline on their own; FCC says it
isn’t happening
Cost-benefit analysis doesn’t work in just those cases where it’s most needed
Counsellors chosen for special knowledge find themselves cut off from sources
of their knowledge
“Crash” program makes two million doses of wrong vaccine
Crystallographer on furlough discovers secret of life
D
Danger of nuclear destruction is generated by the presence of nuclear weapons
built to protect against the danger of. . . nuclear destruction
Deadly gas manufactured upwind of large city
Decommissioning old, broken-down Nuclear Power Plants turns out to be a
major Growth Industry
Defense planners overlook Electromagnetic Pulse associated with nuclear
explosions, assume nonexistent communication capability
Defense planners overlook nuclear power plants as potential nuclear bombs
already in place next to large cities
Dictionaries of modern English fail to define “Bug” as a flaw causing
unexpected failure, thereby providing example of same
Dietary salt discovered to be not all bad
Doomsday (firing of nuclear missiles from submarines) will occur even if no
orders are given
E
Egyptian telephone system won’t work, can’t be fixed
Elected President, successful candidate continues to campaign
Electric turtles, lacking brains, fight each other nevertheless

Emergency telephone line runs three hours behind; callers put on hold
Entire Egyptian bureaucracy fails to function; second bureaucracy established
Ever more elaborate sheltered environments are required for survival of fragile
wildlife
Executive Toy turns self off when turned on
F
Factory system tries to make consumers “do it themselves.”
Fading Botany Department Head finds blossoming new career in
Evaluation.
21
Fail-safe shutdown mechanism in Nuclear Power Plants fails to indicate location
of problem causing shutdown
Famed Messier catalogue of star clusters and galaxies began as a list of objects
that were NOT comets and therefore should not be looked at
Family System is loose enough to weather millennial vicissitudes
FBI Building in Washington, D.C., completed just in time to witness disgrace of
Bureau and its first Chief
Fire in lobby makes air-conditioned hotel colder
Five Year Plans typically end up with the problem worse than before
Flood Control defined as a plumbing problem; Midwest rainfall now hurtles at
high speed down to New Orleans, carrying fertilizing sediment with it
Flood waters pour over top of Hoover Dam; nation assured “The System is
working the way it’s supposed to.”
Florida editors reject famous Florida manuscript written by Floridian
Former vandals now police Ethiopian water wells
French build ultimate fortification (Maginot Line); Germans go around the ends
of it. Guns then face wrong way for defense but can’t be turned around
French chemist, unacquainted with silkworms, cures silkworm disease
Futurologist Herman Kahn proves to be unpredictable
G
Garbage collection systems have trouble collecting garbage
Germany builds giant navy because Kaiser Wilhelm wants one just like Uncle
Bertie’s, only bigger
Giant 230-inch telescope takes all night to come to thermal equilibrium, can’t
focus a star image
Giant aircraft have increasing difficulty landing
Giant Postal Service is barely able to deliver a simple letter

Glass-clad skyscrapers twist in a cross-wind, pop off their skins
Government of Haiti requires emergency assistance in filling out requests for
emergency assistance
Government tea-tasters continue to taste tea despite demise of China tea trade
Great British Groundnut Scheme located by mistake in East Africa, not West
Africa; peanuts won’t grow
“Green Revolution” allows people to starve at higher population densities than
ever before
“Gun control is utilized when the President makes a speech stating he does not
believe in gun control.”
H
Heads of State often off their heads
Heads of State spend their time trying to stay there
Heart attack epidemic subsides on its own; cause unclear
Heart Disease researchers study wrong fats in the bloodstream for twenty years
Heat-sensitive elevator call buttons call elevators to the floor where the fire is
High officials donate own official papers to the government, take the deduction
on their income tax
Hitler forgets to equip his soldiers with winter clothing for the invasion of Russia
Hospital beds cut; sick people swamp related agencies
Hospital patients blamed for not getting well
Hungry nations buy guns, not butter
Hungry nations export food
I
Inheritance tax, introduced to prevent accumulation of great hereditary wealth,
favors the very rich by forcing the inheritors of small businesses to sell out to
large corporations to pay the inheritance tax
Insecticides, intended to kill insects, kill just about everything else while
producing super-resistant insects
Internal Revenue Service requires taxpayer to compute own tax
Internet genius proposes World-Wide Web, is scorned by 140 Communications
executives
Investment counselors fail to beat the law of averages
J
Japan after World War II, not having a standing army, is not asked to defend

anything, uses the money saved to overtake the industrial western world
Jet Pilot rotates Mental Model, lands safely
L
Laboratory rats fail to avoid electrified mazes, explore them even more urgently
than before
Large plastic buildings are found to burn rapidly despite treatment with “fire
retardant.”
Largest and strongest nations can’t win wars against smallest and weakest
Latest model military Tanks are so designed that the engine must be removed to
change the oil—every three hundred miles
“Leadership Training” entails behavior better described as “following”,
League of Nations Building completed in time for Mussolini’s invasion of
Abyssinia
League of Nations fails to work—another large system designed from scratch
strikes out
Local village markets in China found by actual test to be essential for delivery of
food to population
Luxurious new Senate Office Building is scene of Abscam scandals, Koreagate,
and Pageboy furore
M
Major product of publishing houses is now the non-book
Mariner I Venus Probe lacks one word in control program, has to be blown up on
launch
Mass-produced bread bears diminishing resemblance to the original product
Mayan civilization disappears; no villain found
Medical Model of Mental Illness mesmerizes medicos
Medical students seldom see common ailments
Mental retardation research project produces mental retardation in retardation
researcher
Michigan State University observatory dome rains on the telescope
Missile alert traced to computer malfunction; nation assured “The System is
working the way it’s supposed to.”
Model Tsetse fly produces misconception
Moon launch program written with minus sign for force of gravity, corrected just
in time
Motorists with car trouble are ticketed, towed

Movie industry produces a movie entitled, “The Movies.”
MX Missile, designed to replace previous generations of missiles located in
vulnerable holes in the ground, ends up consigned to the same holes
N
Napoleon attempts to take Moscow, makes endless trouble for himself
Napoleon can’t grasp idea of temporary enemies
Napoleon gets Paris Opera organized while Moscow burns
Nation switches back to Standard Time, trains all over the U.S. halt, wait for
clock to catch up
National Foundation switches goal from Polio to Genetic Defects, avoids
becoming irrelevant
National prosperity poorly related to quality of leadership
Native families increasingly likely to include one or more anthropologists
Neighborhood bank issues unsecured line of credit to one customer for one
hundred million dollars, persuades giant bank to honor it
New antibiotics foster the emergence of ever more resistant organisms
New Karachi hospital fails to attract sick patients, stands half empty
Non-aligned nations attack each other for not being sufficiently aligned against
the aligned nations
Nuclear Disaster Alarm at Three Mile Island is referred to NRC’s answering
service
Nuclear Power industry undergoes radioactive decay, self-destructs
Nuclear Power Plant fails to fail-safe; anti-meltdown unit fails, causes meltdown
Nuclear Power Plants act as capital sinks, drain off money faster than they
generate electricity
Nuclear power plants continue to generate 200 million watts even when “shut
down.”
Nuclear Power Plants produce electricity for thirty to fifty years, radioactive
poisons for five hundred thousand years
Nuclear reactor used as target in practice bombing runs
Nuclear Winter descends no matter whose missiles are fired; effect overlooked
by planners
O
“Outstanding Citizens” often turn out to be sociopaths
P

Palace of Versailles completed in time for news of French defeat at Blenheim
Peace-keeping forces consist of warriors
Pension plans end up short of money
Peru-Andes Railroad now uses two big diesel locomotives where formerly one
small steam locomotive was enough
Peruvian fishing industry results in less protein than before for Peruvian children
Philip of Spain reads all memos, loses Empire
Plane to Washington, D.C., actually takes you to rural Virginia
Police on strike in Brazil refuse to make illegal arrests until demands are met
Polish workers strike for right to strike; Newfoundland Civil Servants follow suit
Poor French peasants taxed to support wealthy aristocrats
Positive Feedback shakes Electra airplanes apart
Postal box too full to receive a letter. . . and the National Archives are too full to
accept any more documents
Poverty Program administrators thrive while program fails
President is chosen on basis of ability to get elected, not on ability to govern
Primate peeper sees primate peeping back
Prisons contain those who are not deterred from crime by the threat of prison
Prize American oil-rig sinks on launch in calm sea
Prize English warship built with holes in hull, sinks on launch in calm sea
Prize Swedish warship built with holes in hull, sinks on launch in calm sea
Pyramid Building involves entire Egyptian State, goes into Runaway Phase,
can’t be stopped; Egypt collapses
Pyramid of Snofru, paragon of stability, falls down
R
Rain falls up at UN Secretariat
Rancho Seco Escapade: worker drops light bulb, nuclear power plant crashes
Rats under controlled conditions exhibit uncontrolled behavior
Rebound nasal congestion, generated by use of nasal spray, cannot be eliminated
by increasing use of nasal spray
Red Telephone removed from Oval Office, President Kennedy can’t find it
Remedial math courses now constitute 25% of all college mathematics
Revolts against tyranny end up as tyrannies
Rocket shed generates its own weather
Rubik’s Cube: majority of solutions impossible to reach from a given starting
position
Russians drop fifty-megaton nuclear bomb on themselves to see what would

happen
S
Safest, most convenient, most energy-efficient American transportation system
(street railways) is scrapped without discussion
Safety equipment is now a major source of sports injuries
School System makes literacy widespread but not truly popular
Scientists in crash research program crack up, cut tails off mice, paint skins with
ink
Scientists opposed to nuclear war find themselves giving advice on how to wage
it
Search for chemical cancer cure fails, turns up a cure for a different disease
Seeing Eye, Inc., oversubscribed; Blindness Prevention pines
Selective Service System continues registration in time of peace
“Ship-builders” actually negotiate contracts, attend committee meetings
Six hundred alarm bells ringing at Three Mile Island fail to add up to a
comprehensible picture of what’s wrong
Standard Oil a Monopoly? Question studied for thirty years to avoid making a
decision
Statisticians view six meltdowns in 54 trials, conclude risk is one in a hundred
million
Successful flying machine invented by bicycle makers
Supertankers (like Benjamin Whorf’s “empty” gasoline drums) tend to explode
when returning “empty” to home base
Supertankers are too big to come into port
T
Table Shape takes precedence over other questions at the ConferenceTable
Taking Down the System of asbestos insulation costs more than original
installation
Talleyrand explains to the Great Powers that France is just one more victim of
Napoleon’s aggressions
Teenager invents TV, is sent for sanity testing
Telephone company encroachment: first you pay to get listed in the telephone
book, then you pay even more to get unlisted
Temporary Buildings erected for Navy Personnel in World War I still being used
70 years later
Theory of Plate Tectonics, the century’s greatest advance in Geology, is rejected

by the leading Geophysical Research Journal
Three Mile Island inadvertently built with a Feedback Loop inside of a Feedback
Loop, so corrective efforts just made things worse
Three Mile Island Nuclear Power Plant fails in ways never anticipated by
designers
Three Mile Island psychological fallout renders citizens of Harrisburg
unapproachable without adequate shielding
Three Mile Island sues Nuclear Regulatory Commission-for Improper
Regulation
Titanic’s bulkheads run crosswise; iceberg rips hull lengthwise
Token System not working as expected; few notice
Triple boilers fail simultaneously on ocean liner
TV Guide announces a TV special, entitled, “TV Guide. . . the First 25 Years
TV invented by teenager; giant corporation claims credit
U
U.S. negotiator is “very satisfied” with talks that haven’t happened yet
UN responds to famine in the Sahel, builds new Conference Center
UN suspends operations to debate whether its employees should continue to ride
first-class on airplanes
Unidentified Foreign Object in melted-down nuclear reactor turns out to be a
piece of an unauthorized anti-meltdown device
University grading systems oscillate from Type A to type B and back again
University scholars spend their time trying to get published
Unnoticed epidemic of auto accidents kills 50,000 Americans, maims one
million each year, is dismissed as just a fact of life
V
Vietnamese village is burned in order to “save” it
W
War on Crime continues to be waged forever
Washington, D.C., Reagan Airport found “safe because it’s dangerous.”
Water supply to bathrooms overlooked in Senate Office Building, costliest office
building in history
Watergate cover-up authors attempt to cover up their cover-up
Wealthy nations endure recessions
Western civilization: a modest proposal to stuff it under a mountain in Colorado

When their batteries go dead without warning, smart bombs revert to being
dumb bombs
Winnie-the-Pooh probes honey pot, ends up with no honey and head stuck in
pot.
Wishful Feedback: Alarm signal indicating a valve stuck in the “open” position
could be silenced merely by pressing the “close” button
World Health Assembly gives up after six years of trying to get doctors to
measure blood pressure in kilopascals
Worst aircraft accident, a collision between two loaded Jumbo Jets, took place
on the ground
Worst U.S. military disasters (Korea, Vietnam) fought from best headquarters
(Pentagon).
Y
Yap monetary system avoids some common pitfalls
Z
Zilwaukee Bridge: efforts to stabilize sagging pier threaten to cost more than
original estimate for the whole thing
182

50. Biased Bibliography and Good
Reading List
This List contains the principal works cited in the text, plus additional
contributions of interest to the serious Systems-student. Some entries have been
included solely because their title makes good reading. This List is intended to
be good reading. That is, this is a Bibliography that is intended to be read.
TheListis intended to be read, that is. (In some cases the works cited are
themselves rather interesting.)
Arrowsmith, William. “The Shame of the Graduate Schools.”Harper’s
Magazine, March, 1966. pp. 52-59.
Ashby, W. Ross.An Introduction to Cybernetics. London. Chapman & Hall.
1956.
———.Design for a Brain. New York. Wiley. 1952.
Bandler, Richard, and John Grinder.The Structure of Magic.Two Volumes. Palo
Alto, California. Science and Behavior Books. 1975 and 1976.
———.Frogs into Princes. Neuro-Linguistic Programming. Moab, Utah. Real
People Press.
1979. Bateson, Gregory.Steps to an Ecology of Mind.San Francisco, Chandler,
1972.
———.Mind and Nature. A Necessary Unity. New York, Dutton, 1979.
Bennis, Warren. “Who Sank the Yellow Submarine?”Psychology Today,
November, 1972, pp. 112-120.
Berne, Eric.Games People Play. New York, Ballantine Books, Inc., 1964.
———.What Do You Say After You Say Hello?New York, Grove, 1972.
Bertalanffy, Ludwig von.General System Theory. New York, Braziller, 1968.
Blake, Peter.Form Follows Fiasco. Why Modern Architecture Hasn’t
Worked.Boston, Toronto; Atlantic-Little, Brown, 1974, 1975, 1977.
Boulding, Kenneth E.Ecodynamics: A New Theory of Societal Evolution.
Beverly Hills, London; SAGE Publications; 1978.
Brooks, Frederick P., Jr.The Mythical Man-Month. Essays on Software
Engineering.Reading, Massachusetts; Addison-Wesley; 1975.
Calder, Nigel.Einstein’s Universe.New York, Viking, 1979.
Carroll, Lewis.Alice’s Adventures in WonderlandandThrough the Looking Glass.
Illustrated by John Tennie1. New York, Heritage Press, 1941.

Churchman, C. West.The Systems Approach. New York. Dell. 1968.
Colinvaux, Paul.Why Big Fierce Animals Are Rare. An Ecologist’s
Perspective.Princeton, New Jersey. Princeton University Press. 1978.
Drucker, Peter F.Management: Tasks, Responsibilities, Practices. New York.
Harper and Row. 1973.
Dunn, P.D.Appropriate Technology. Technology with a Human Face. New York.
Schocken. 1979.
Elgin, Duane S., and Robert A. Bushnell. “The Limits to Complexity: Are
Bureaucracies Becoming Unmanageable?”The Futurist, December, 1977, pp.
337-349.
Erickson, Milton H. “Further Clinical Techniques of Hypnosis: Utilization
Techniques.”American Journal of Clinical Hypnosis 2, July, 1959, pp. 3-21.
Reprinted in: Rossi, Ernest L., editor.The Collected Papers of Milton H.
Erickson. New York, Irvington Publishers, 1980, Vol I, pp. 177-205.
Farson, Richard.Management of the Absurd. Paradoxes in Leadership.New
York. Touchstone. 1996.
Fener, Steven A., and Kosta Tsipis. “Catastrophic Releases of
Radioactivity.”Scientific American 244, No.4, April 1981, pp. 41-47.
Fiedler, Fred E. “The Trouble With Leadership Training is That It Doesn’t Train
Leaders.”Psychology Today 6, No.9, February, 1973, p. 23.
Ford, Daniel. “The Cult of the Atom.” In:A Reporter At Large. New
YorkerMagazine, October 25, 1982, pp. 107-159.
Fuller, John G.We Almost Lost Detroit. New York, Reader’s Digest Press, 1975.
Fuzzy Sets and Systems: An International Journal. H.-J. Zimmerman, princ. ed.
Amsterdam, North-Holland Publishing Co.
Gall, John.Systemantics.New York. Quadrangle. 1977. (Original Edition
published by General Systemantics Press, Ann Arbor, Michigan, 1975.)
Goffman, Erving.Frame Analysis. New York, Harper Colophon, 1974.
Gordon, David, and Maribeth Meyers-Anderson.Phoenix: Therapeutic Patterns
of Milton H. Erickson. Cupertino, California. Meta Publications. 1981.
Gracian, Balthasar.The Art Of Worldly Wisdom. Translated from the Spanish by
Joseph Jacobs. New York, MacMillan, 1955.
Gray, Mike, and Ira Rosen.The Warning: Accident at Three Mile
Island.Contemporary Books, Inc. Chicago, Illinois, 1983.
Grinder, John, and Richard Bandler.Trance-formations. Neuro-Linguistic
Programming and the Structure of Hypnosis. Moab, Utah. Real People Press,
1981.

Haley, Jay.Uncommon Therapy: The Psychiatric Techniques of Milton H.
Erickson, M.D.New York. W.W. Norton. 1973.
Hall, Peter.Great Planning Disasters. Berkeley and Los Angeles. University of
California Press, 1981.
Hardin, Garrett, and John Baden, Editors.Managing the Commons. San
Francisco. W.H. Freeman and Co., 1977. Herbert, A.P.What a Word!Garden City,
New York. Doubleday, Doran and Co., Inc., 1936.
Hoff, Benjamin.The Tao of Pooh. New York. Penguin. 1982.
Hofstadter, Douglas R.Goedel, Escher, Bach: An Eternal Golden Braid. New
York. Basic Books. 1979.
———. “Metamagical Themas.”Scientific American 244: No.3, March, 1981,
pp. 20-39.
Holtby, Michael. “Origin and Insertion of Script Injunctions.”Transactional
Analysis Journal 6: 4, October 1976.
Janis, Irving L. “Groupthink.”Yale Alumni Magazine, January, 1973, pp. 16-19.
Jay, Anthony.Management and Machiavelli. New York. Holt, Rhinehart and
Winston, 1967.
Johnston, Moira.The Last Nine Minutes. New York. Avon. 1978.
Jung, C.G.The Undiscovered Self. New York. Mentor, 1959.
Keeney, Bradford P.Aesthetics of Change. New York. The Guilford Press. 1983.
Kemeny, John G.Man and the Computer. New York. Scribner’s. 1972.
Klaassen, Johann. “The Sociology of Scientific Knowledge and the Activity of
Science; or, Science is a System, too.”Cybernetica 39: 2, 1996, pp. 77-98.
Kohr, Leopold.The Overdeveloped Nations. The Diseconomies of Scale.New
York. Schocken. 1978. See also:Die Ueberentwickelten. Dusseldorf. EconVerlag. 1962.
Korzybski, Alfred.Science and Sanity. Garden City, New Jersey; Country Life
Press; 1933.
———.Outline of General Semantics. In:General Semantics. Papers from the
First American Congress for General Semantics. Organized by Joseph C.
Trainor and held at Ellensburg, Washington, March 1 and 2, 1935. (Central
Washington College of Education.) Collected and Arranged by Hansell Baugh.
Distributed by Arrow Editions, 444 Madison Avenue, New York, 1938.
Copyright 1938 by the Institute of General Semantics, 1330
East 56th Street, Chicago, Illinois.
Kuhn, Thomas S.The Structure of Scientific Revolutions. Chicago, Univ. of
Chicago Press. 1962.

Laotzu.The Way of Life According to Laotzu. An American Version by Witter
Bynner. New York, John Day, 1944. Levinson, Harry. “Management by Whose
Objectives?”Harvard Business Review, Ju1y-August, 1970, pp. 125-134.
MacKay, Charles, LLD.Extraordinary Popular Delusions and The Madness of
Crowds.London. Richard Bentley, Publisher in Ordinary to Her Majesty. 1841.
Reissued by Suggestion of Bernard Baruch by L.C. Page and Co., 1932.
McLuhan, Marshall.Understanding Media: The Extensions of Man. New York.
New American Library, Inc., 1964. McMahon, Thomas A., and John Tyler
Bonner.On Size and Life. New York. Scientific American Books, Inc. 1983.
Machiavelli, Niccolo.The Prince. Transl. Luigi Ricci, 1903. Revised by E.R.P.
Vincent, 1935. New York. New American Library. 1952.
Mattingly, Garrett.The Armada. Boston. Houghton Mifflin Company, 1959.
Mendelssohn, Kurt. “A Scientist Looks at the Pyramids.”American Scientist 59,
March-April, 1971. pp. 210-220. ———.The Riddle of the Pyramids. London.
Thames & Hudson. 1974.
Mesarovic, Mihajlo, and Eduard Pestel.Mankind at the Turning Point. The
Second Report to the Club of Rome.New York. Signet New American Library.
1974.
Milne, A.A.Winnie-the-Pooh. New York. Dutton. 1926.
Mostert, Noel.Supership. New York. Knopf. 1974.
Ogden, C.K., and I.A. Richards.The Meaning of Meaning. New York. Harcourt
Brace Jovanovich. 1923.
Orwell, George.Nineteen Eighty-Four. London, Secker and Warburg, 1949.
Palazzoli, M.S., Boscolo, L., Cecchin, G., and Prata, G.Paradox and
Counterparadox. A New Model in the Therapy of the Family in Schizophrenic
Transaction. Jason Aronson, Inc., New York and London. English Translation,
1978. Originally published in Italy by Feltrinelli Editore, Milan, 1975.
Parkinson, Cyril Northcote.Parkinson’s Law and Other Studies in
Administration. Boston, Houghton Mifflin, 1957.
Peter, Laurence J., and Raymond Hull.The Peter Principle. New York, Bantam,
1969.
Potter, Stephen.OneUpmanship. New York. Henry Holt and Co. 1951.
Rosenhan, D.L. “On Being Sane in Insane Places.”Science 179, January 19,
1973, pp. 250-258.
Rostow, Eugene V. “In Defense of the Ivory Tower.”Yale Alumni Magazine,June,
1972, pp.5-7.
Russell, Bertrand.Freedom Versus Organization. New York. Norton. 1934.

Sale, Kirkpatrick.Human Scale. New York. G.P. Putnam’s Sons. 1980.
Satir, Virginia, and Michele Baldwin.Satir Step By Step. A Guide to Creating
Change in Families. Science and Behavior Books, Inc. Palo Alto, California
94306. 1983.
Satir, Virginia.Conjoint Family Therapy. Palo Alto, California. Science and
Behavior Books, Inc., 1964. Revised Edition, 1967.
Schell, Jonathan.The Fate of the Earth.Knopf. New York. 1982.
Schiff, Aaron, and Jacqui Schiff. “Passivity.”Transactional Analysis Journal 1,
No. 1, January, 1971, pp. 71-78. Schumacher, E.F.Small is Beautiful. Economics
as if People Mattered. New York, Harper and Row Perennial Library, 1973.
———.Good Work. New York. Harper and Row. 1979.
Shannon, Claude E., and Warren Weaver.The Mathematical Theory of
Communication.Urbana, Chicago, London. University of Illinois Press, 1949.
Smullyan, Raymond M.The Tao is Silent. New York, Harper and Row, 1977.
Solzhenitsyn, Alexander.We Never Make Mistakes. (Two Short Novels). New
York, Norton Library, 1963. Copyright by University of South Carolina Press,
1971.
Spencer-Brown, G.Laws of Form. New York. Dutton. 1979. First published in
London by George Allen and Unwin Ltd., April, 1969.
Stover, Leon E., and Bruce Kraig.Stonehenge. The Indo-European Heritage.
Chicago, Nelson-Hall, 1978.
Tenner, Edward.Why Things Bite Back. Technology and the Revenge of
Unintended Consequences.New York. Knopf. 1996.
Townsend, Robert.Up The Organization. Greenwich, Connecticut; Fawcett
Publications, Inc., 1970.
Toynbee, Arnold J.A Study of History. Abridgement of Volumes I-VI by D.C.
Somervell. New York and London, Oxford University Press, 1947.
Train, John.Remarkable Occurrences. New York; Clarkson N. Potter, Inc., 1978.
Watzlawick, Paul; Janet Helmick Beavin; and Don D. Jackson.Pragmatics of
Human Communication. New York, Norton, 1967.
Watzlawick, Paul.How Real Is Real?New York, Vintage, 1976.
———.The Language of Change. Elements of Therapeutic Communication.New
York, Basic Books, 1978. Watzlawick, Paul; John Weakland, and Richard
Fisch.Change. Principles of Problem Formation and Problem Resolution. New
York, Norton, 1974.
Weber, R.L.A Random Walk in Science. New York, Crane, Russak & Co., 1973.

Weinberg, Gerald M.An Introduction to General Systems Thinking. New York,
Wiley and Sons, 1975.
Whitehead, Alfred North.Process and Reality. Corrected Edition.Eds. D.R.
Griffin and D.W. Sherburne. New York. Free Press. 1985.
Whorf, Benjamin L.Language, Thought, and Reality. Cambridge,
Massachusetts; Technical Press of Massachusetts Institute of Technology, 1956.
Whyte, Jr., William H.The Organization Man. New York, Doubleday and Co.,
1956.
Wiener, Norbert.The Human Use of Human Beings: Cybernetics and Society.
New York, Avon, 1950.
Wittgenstein, Ludwig.Tractatus Logico-philosophicus.D.F. Pears and B.F.
McGuiness, transl. London, Routledge and Kegan Paul, 1961.
Yutang, Lin.The Importance of Living. New York. Published by John Day in
association with Reynal and Hitchcock, 1937.
Zeeman, E.C. “Catastrophe Theory.”Scientific American 234, April 1976, pp.
65-83.
186

51. Endnotes and References
196
[a] Actually, this is Version 3.5—not enough change to qualify as a new
edition, but updated in several important respects, especially the historical.
[a.]a. The Primal Scenario is given in full in the Historical Overview,vide infra.
[b.]b.Yugoslavia, recognized as a founder of the Non-aligned Movement and
formerly respected as one of the most strongly Non-aligned nations, has
subsequently disintegrated and is currently striving to reestablish itself as an
entity, aligned, non-aligned, whatever. (This footnote is preserved here in
Archival Form as a reminder of conditions prevailing in 1986. How quaint it all
seems now!)
[c. ]c.And—at a slightly higher level—in the National Archives office, which
recently announced to other government agencies, “Don’t send us your records. .
. we don’t have room for them.”
[d. ]d.As of July 2, 1983, the Detroit (Michigan) 911 System (Emergency Hot
Line) was running about three hours behind time. (It’s now 2012, and
Emergency Hot Lines generally pick up the phone promptly, but the operator
may require to be convinced that your call is a true emergency, as a few
individuals have begun to use the service for personal convenience, requesting
babysitting or the lottery results.
[e] The interested reader is referred to the scholarly journal entitled “Fuzzy Sets
and Systems.” Any issue will do.
[a.]a.One branch of Kantian epistemology maintains that the System-in-itself
cannot be known. While granting the theoretical validity of this assertion, we
follow in practice a more pragmatic view, namely, that we can deal with what we
do know of it.
[b. ]b.Recent research has linked this impulse to nesting behavior in birds and
to token-collecting in higher Primates.
[c.]c.Additional copies, discreetly mailed in plain brown wrapper, may be
obtained by writing directly to the publisher.
[a. ]a.For an extensive review of things that aren’t working very well at present,
see Peter, L. J.The Peter Principle, pp. ix-xviii.
[b.]b.The Nuclear Age isn’t remarkable for cheer, either.
[c. ]c.Persons new to Systemantic Theory sometimes think the 5% estimate is
intended to be a humorous exaggeration. To correct this misconception,

beginners are referred to headlines such as the following: UPSET NRC KEEPS
FERMI AT 5% POWER which regularly appear in the nation’s newspapers.
(Update note, 2012: The legendary Fermi Unit Number One fast breeder (liquid
sodium coolant) reactor in Monroe, Michigan, after 38 years of
decommissioning, is projected to attain “safe storage” status in 2012.)
[d.]d.Murphy has at last been identified with reasonable certainty. See Endnotes
and References, Note 14.
[e.]e.“Von Bertalanffy” (the name is genuine) belongs to that small and elite
group of names, including “Korzybski,” “Wittgenstein,” and “Whorf,” whose
exotic syllables both bedazzle in print and also resound intimidatingly when
dropped at the right moment.
[f.]f.Parkinson was himself anticipated by the master French diplomat,
Talleyrand, who, before the Congress of Vienna even got under way, insisted that
the main Congress Hall be furnished withfiveseparate and equal entrances, the
fifth in recognition of France as an equal party to the Congress.
[a. ]a.Professor Boulding (personal communication) has challenged this
Theorem, asserting that if it were true, Evolution would be impossible. We defer
to Professor Boulding’s deep Systems-sophistication. But we ask: If Anergy
diminishes, where does it go?
[a.]a. Fundamental Theorem. See preceding Chapter.
[b.]b. See Chapters 3, 4, 6, 14, 16. Why not just read the whole book?
[c.]c.A similar tendency in the tax policies of the United States reached a
temporary climax in the late 1960’s with the practice, widespread among high
government officials, of writing off official papers at inflated values.
(NIXATION. n. Root NIX—. Negative taxation for the well-to-do). The reader
is encouraged to draw his or her own conclusions with regard to current events.
The author assumes no responsibility for the opinions of others.
[d. ]d. See also Self-reference, Chapter 36.
[e.]e. See: Oscillating Systems, Chapter 5. What remains unchanged is the
phenomenon of Encroachment.
[a.]a. For a more detailed discussion of animals that have contributed to our
understanding of Systems, see Appendix VI.
[b. ]b. As true children of the Machine Age, we tend to think this of everything.
[c.]c. See Chapter 14.Systems-Failure (Theory of Errors).
[d. ]d.Not to be outdone, Michigan State University recently inaugurated a onemillion dollar astronomical observatory that accomplishes the same feat. “. .
.under certain conditions, it literally rains inside the dome. . .”

[e.]e.—with a respectful nod to Aristotle, who anticipated the Non-Additivity
Theorem by noting that a sufficiently large boat is more like a floating island
than a boat.
[a. ]a.For Administrators’ Neuroses see (at least) Chapters 7, 8, 11, 32.
[b. ]b.—that he never dared ask his parents.
[c. ]c.Administrator’s Grandiosity Neurosis: desire to recreate the world in the
administrator’simage.
[a. ]a. Technically, it’s all negative, being opposite in sign to the deviation, but
who wants to quibble?
[b.]b. For Active Utilization of such trends, see Catalytic Managership, Chapter
30.
[a. ]a. Undeterred by Toynbee’s travail, a new generation of enthusiasts, led by
Herman Kahn, has founded the science of Futurology, which purports to
establish for future events those laws which have eluded those who merely study
the past. The elusiveness of their task was borne in upon them at the very outset,
when, before they could consider what to do about the future, they were faced
with the problem of what to do about Herman Kahn. This crisis forced the stark
issue: WHAT IS THE FUTURE OF FUTUROLOGY?
[b.]b.The Germans later re-mounted them facing westward toward France, thus
demonstrating that they, too, could be Fully Prepared for the Past.
[c. ] A number of the bathrooms were discovered to be devoid of water supply.
[d.]d.The half-life of Plutonium-239 is 24,110 years, give or take a few.
[a. ]a.Of the scores of different varieties of apple available at the turn of the
century, only ten or twelve are currently offered to the public. Generalizing:
THE LARGER THE SYSTEM, THE LESS THE VARIETY IN THE
PRODUCT. —which also explains why modern “luxury limousines” are
typically produced by (for example) placing a Chevy engine in an enlarged but
standard chassis and adding a few frills.
[b.]b. However, one can honestly say of supermarket fruit that it nowlooksbetter
than the real thing.
[c.]c.We shall not attempt to pursue the origins of this sloppy semantic habit
back to medieval scholasticism, which was more interested in the general
essences of things than in their particularity. Nor shall we mention Plato, to
whom only the essence was really real. Presumably Plato had a plentiful supply
of fresh apples in season and didn’t have to worry about particulars.
[d.]d.This Example, with its accompanying discussion, was written before the
recent invasion of the Foreign Small Cars. It is here retained as a historical
curiosity and also as a validation of the power of the Systemantic approach.

[e.]e. A Systems-delusion. See chapter 9.
[f.]f.According to legend, Mr. Benjamin Whorfwas induced to give up a
promising career as Fire Insurance Inspector and to devote his attention to
Linguistics by a remark that tended to recur in the course of his investigations of
unexplained fires. The remark was “the fire began in anemptyoil barrel.”
[g.]g.See Creative Reframing, Chapter 38.
[h.]h.The method of consigning undesired situations or persons to nonexistence
doesn’t work either, since to hide the name of something is merely to
acknowledge its existence in a negative way. Some of the most influential actors
on the stage of modern history have been, at some point in their lives, Nonpersons.
[a.]a.With McLuhan it is difficult to be sure about anything. The reader seeking
greater clarity is referred to the murky brilliance of McLuhan’s own prose.
[b.]b.In theory, the C. F. may attain 1.00, but in practice removing the last shreds
of reality from the sensory input becomes increasingly difficult.
[c].In this connection we note a haunting Theorem promulgated by H. Harte, to
the effect that:
INFORMATION RARELY LEAKS UP
[d]. It is perhaps only coincidental that the letter i in Mathematics represents an
imaginary quantity.
[e.]e.INTERDISCIPLINARY FUNCTION. The art of correlating one’s own
professional activities more and more with those of other professionals, while
actually doing less and less.
[f.]f.Parkinson’s recognition of Injelititis (Incompetence and Jealousy interacting
according to the formula I J) stands as a landmark in the early history of
Systems-pathology. However, strictly speaking, Injelititis is merelyinducedby the
System in an individual of appropriate susceptibility.
[g. ]g.The Federal Government, following well-established Systemantic
principles, bailed out the largest bank but punished the smaller ones. (The reader
is again cautioned that any attempt to compare this event to the financial goingson of 2008-2009 in the United States is the reader’s own responsibility.)
[a. ]a. The reader is challenged to pair up these villages with the corresponding
metropolitan centers.
[b.]b.This train (or plane) of thought leads inescapably on to the prophetic
commentary of G. Stein, made in reference to the modern metropolis: WHEN
YOU DO GET THERE, THERE’S NO THERE THERE.
[c. ]c.A classic example of a System that can be turned on but can’t be turned

off. See also: TOTAL SYSTEM: TANGLE: FRANKENSTEIN MONSTER;
CATASTROPHE THEORY (Glossary)
[d. ]d. See Chapter 38. The Problem in the Question.
[a. ]a. See Chapter 37. Taming systems.
[b.]b. It is perhaps going too far to remark that Edison, who invented the
phonograph, was deaf.
[c.]c. For further consideration of teenagers in relation to computers, see Essay
Questions, Appendix II.
[a.]a.Impotent Potentate Syndrome—a rather straightforward example.
Additional examples: Mohammed commanding the mountain to come to him,
King Canute desiring the sea to recede, President Nixon ordering the Watergate
mess to disappear.
[b.]b.The corporate dismantling of the Bell System will be followed with interest
by Systems-students everywhere.
[c.]c. It works for the police.
[d.]d.Vending Machine Fallacy. Comparevendetta: a feud between a customer
and a recalcitrant vending machine.
[e. ]e. Rumors implying that the bagpipes have been mastered remain
unconfirmed.
[f. ]f. For more on the Family System, see Chapter 25.
[g. ]g.See previous footnote on the Bell Telephone System, p. 45. The recent
decision of the Coca-Cola company to change the formula of Coke will also be
followed with interest.
[h. ]h.The Complex System known as Star Wars, or Strategic Defense Initiative,
is discussed elsewhere (Fail-Safe Delusions. p. 78).
[a. ]a.Students wishing to investigate this fascinating topic in more detail are
advised to study the lives of Henry VIII, George III, certain Emperors of Japan,
the Czars of Russia, the Sultans of Turkey, etc., etc. Readers may also wish to
review the performance of certain present-day heads of government—the author
wisely refrains.
[b].It was eventually found elsewhere. The decorators had removed it.
[c.]c.Skeptics are invited to contemplate the Three-Body Problem in Physics,
where predicting how three bodies will move in space when subject only to the
force of Gravity proves too difficult for even the largest computers. See
Glossary, under CHAOS; CHAOS THEORY.
[a.]a.For more on the travails of dismantling an operating System (Taking It
Down). see Chapter 25. Design Don’ts.

[a.]a.The tobacco tax, which goes directly into the President’s personal bank
account, is meticulously collected in full.
[b.]b.—estimated (beforethe meltdown) at perhaps one in a hundred million. The
figure was neverofficiallyrevised. SeeThe Suppressing of WASH-740in Chapter
27: Wishful Feedback.
[c.]c.The device was subsequently referred to blandly in official publications as
“a zirconium plate,” without reference to its intended function.
[a.]a. See “Bugging the Writ,” in Partridge’sDictionary of Slang and
Unconventional English.
[b. ]b.Technically one of the Failure Theorems, this Rule is dealt with at this
point for reasons of relevance. It fits here, doesn’t it?
[c. ]c.And, as Brooks reminds us, “Furthermore, the fixing of the documented
component bugs will surely inject unknown bugs. . .”
[d. ]d. See Minsky’s Admonition, Chapter 33.
[e.]e. See Chapter 38. The Problem in the Question.
[a.]a. This particular hypersensitivity was found and corrected. But rumor
persists that a certain popular computer tends to crash when brought in proximity
to a frosty diet cola. See also the Rancho Seco Escapade, where a dropped light
bulb brought down a Nuclear Power Plant. (see Horrible Examples, Appendix
IV)
[a.]a.Sometimes literally down the drain. At Three Mile Island in Pennsylvania,
a major portion of the cleanup job is the removal of tons of radioactive water
from the flooded plant building. Estimated cost of the cleanup: $4.3 billion—
more than the original cost of the power plant. (See Glossary, under BACKUP
SYSTEM, TANGLE, CASCADE OF FAILURES).
[b.]b.See also Aunty Awards, Nuclear Energy Division, Horrible Example
Number 1, in which a Nuclear Power Plant is used as a practice bombing target
by Air Force Jets. (Appendix IV).
[c. ]c.The Inevitability-of-Reality Fallacy. See Chapter 22
[d.]d.Despite continued high fat consumption. the heart attack epidemic is
subsiding on its own. If something isn’t discovered soon, it will be too late.
[e. ]e.A century of failure to come up with any solid support for the Disease
Theory of Mental Illness is interpreted as proof that the disease in question is
merely very subtle. But as Professor Jung has pointed out’: “Psychiatric theory
can always take refuge behind real or alleged organic disorders of the brain. . .”
[f.]f.The observant Student will recall that both the Hatter and the March Hare,
who collaborated in adjusting the Hatter’s watch, were mad.

[g.]g.Any imagined resemblance to Military-Industrial Complexes or ReligiousNational Complexes (foreign or domestic) is the reader’s own responsibility.
[a. ]a.Clearly, this observation can have no real relevance for theories of human
conflict. After all, we human beings are creatures of high intelligence, while
electric turtles are mere automatons.
[b.]b. See Nasal Spray Effect, Chapter 36.
[a. ]a.We owe our awareness of the importance of the Sleeping Dog to G.
Bateson.
[b. ]b.Bateson has here been anticipated by that master of minimal
communication, Sherlock Holmes, who did not fail to note and respond to the
remarkable fact that the dog did NOT bark in the night.
[a.]a.Ultimately, while pursuing knowledge of how to quick-freeze chickens,
Bacon chilled himself and died of pneumonia.
[b.]b.For more on the Model of the Universe, see also Chapters 27, 38.
[c.]c.In Mathematics, Information is considered to be a kind of negative of
Entropy, whateverthatis. Clear?
[d.]d.A few readers of more mature years may remember the Mimeograph
machine, now as vanished as Horseless Carriages and daguerrotypes.
[e. ]e.We observe with respect that the College Student System, formerly able to
retrieve the mimeo master for tomorrow’s exam from the bottom of the
Dumpster, now hacks into the University’s Computer System to access the
Professor’s own notes.
[f.]f.See COEFFICIENT OF FICTION, SELF-REFERENCE.
[a. ]a.For a more concrete example of tail-wagging, see Index under Antenna,
airborne.
[b. ]b.Martian: The language that might be used by a visitor from an alien culture
to describe the events in question. The Frame of Reference, or Metaphorical
Structure, that might be applied to the scene by a naive observer. Term
popularized by E. Berne. For the selection quoted, a Martian translation might
read: “I was lying when I said that, but I am not lying now.”
[c.]c.See Chapter 38: THE PROBLEM IN THE QUESTION
[a] Just after the November, 2012, American presidential election, an official,
asked about the long lines and multi-hour waits people endured in order to vote,
replied, “When lots of people turn out to vote, there are going to be long lines.”
[a. ]
[b. ]b.Darwin himself noted that the inhabitants of Tierra del Fuego seem not to
have realized that they could actually avoid being cold by taking readily

available measures such as wearing clothes.
[c. ]c.The author was thinking about writing a Chapter on Passivity, but it
seemed like a lot of work, so he didn’t. You could look it up.
[a.]a.As a beginning exercise in thinking along these lines, the Student is invited
to ponder the considerable numbers of English who, in the seventeenth century,
did NOT come over on the Mayflower, thereby obviating the hardships of that
journey and the subsequent inconveniences of pioneering in America, and whose
more fortunate descendants came over (if and when they wished) on the Queen
Mary, first class.
[b.]b.Attempting To Take Moscow appears to hold a special fascination for a
certain type of energetic leader who, presumably, scoffs at the Principle of
Problem Avoidance. We ourselves shall Avoid any Problem on this point by
scrupulously omitting any reference to France (Algeria), the United States
(Korea, Cuba, Vietnam, Iraq. . .), Portugal (Angola), England (Ireland),
Argentina (The Falklands), Russia (Poland, Afghanistan), etc., etc., etc. We shall
also avoid violating the spirit of this Principle by not trying to think of a long list
of further Examples.
[c.]c.The author is actually quite fond of the Coast Guard. It is chosen here
simply as an example of a large System. One can end up at sea in any large
System.
[a. ]a.Compare CREATIVITY, SCIENTIFIC (See Glossary).
[a.]a.Fundamental Theorem.
[b.]b.Laws of Growth
[c.]c.Generalized Uncertainty Principle (G.U.P.).
[d.]d.Fundamental Failure Theorem (F.F.T.).
[e.]e.Le Chatelier’s Principle.
[f.]f.Functionary’s Fault.
[g.]g.Administrator’s Anxiety.
[h.]h.Systems-delusion.
[i.]i.For the origin of Agnes Allen’s Law, see Notes and References: Historical
Overview, Ref. 3. See also Glossary: TANGLE.
[j.]j.We note that the decommissioning of the Monroe (Michigan) Fermi Number
One fast breeder reactor to a state of “safe storage” has just occurred this year
(2012), 38 years after the initial disaster.
[j.]j.For more on Remote Effects of System Bugs, see Chapter 15.
[k.]k.Parameters are Variables traveling under an assumed name. They are
Variables that are held artificially constant—which just goes to show how little

Mathematics knows about the real world. See also Glossary: CONSTANT.
[l.]l.Problem-Avoidance: see Chapter 23. In rare cases, the situation or Problem
itself can be restructured or redefined in such a way as to permit an elegant
solution. See Chapter 38: The Problem in the Question.
[m.]m.A more definitive solution—such as closing the sluices of Hoover Dam to
reduce the river to a trickle—would be indignantly rejected by all true
sportspersons. The challenge is to master the rapids, not abolish them
completely. Who wants a solution that takes away the thrill of victory?
[m] The Greek playwright Aristophanes did a little extending of this Law
himself, when he observed that bad politicians drive out good politicians. (We
are duty-bound to concede that, under extreme conditions, Gresham’s Law
reverses itself, at least as far as coinage is concerned.)
[n. ]n.But not for long. Jet engines cannot survive the dust churned up by nuclear
explosions.
[a.]a.Catastrophe Theory is pertinent in Management as well as at the Design
level. See especially Chapters 32 (The Limits to Grandiosity) and 33 (Disaster
Control).
[b.]b.Eventually, people are compelled to notice. Examples: Enron, WorldCom,
Qwest, Tyco, Citicorp, ImClone, Global Crossing. . .We note again that simple
greed is notper segermane to Systemantics, but the grandiosity to which it leads
most certainly is.
[a. ]a.Professor Schumacher apprises us of the experience of countries such as
India and Turkey, where “highly ambitious five-year plans regularly show a
greater volume of unemployment at the end of the five-year period than at the
beginning. .”
[b.]b.“Keep The Study Under Study.”
[c. ]c.A popular “executive toy” consists of a black box with an on-off switch on
one side. When the switch is thrown to the “on” position, the lid of the box lifts
up and a mechanical hand emerges, turns the switch off, and retreats into the box
again.
[a.]a.Stevenson and colleagues, on their record-breaking 1937 balloon ascent
into the stratosphere, report that the last earthly sound heard was the barking of
dogs.
[b.]b.Guinea fowl tend to take frequent naps during the day.
[c.]c.The U. S. Cabinet is now well above the critical number—an ominous
development.
[a.]a.Gandhi was paraphrasing abon mot of Alexandre Ledru-Rollin (I807-1874)
—but how many of his followers would have been aware of that?

[a.]a.The above analysis. which appeared in the First Edition of Systemantics,
has been further confirmed by subsequent events. The recent surge of progress in
cancer research is due in substantial part to Barbara McClintock, whose special
interest incounting colored kernels of cornfailed to arouse the excitement of her
peers and led to a lifetime of poorly funded solo research. That research is now
understood to bear directly on basic mechanisms of cancer causation.
[b.]b.But—and strictly in accordance with the Laws of Systemantics—the
program did stumble upon a cure for adifferenttype of ailment.
[c. ]c.A “crash” government program to respond to the threat of a swine flu
epidemic was significantly delayed when a pharmaceutical company made two
million doses of the wrong vaccine.
[a.]a.The additional word “final” appears to have been scratched in as an
afterthought, perhaps during the baking process.
[b. ]b.Advanced students may ponder the variation attributed to Bateson: IF IT’S
NOT WORTH DOING IT’S WORTH DOING WELL
[c. ]c.A most meticulous autocrat, King Philip insisted that his commands be
carried out without the slightest deviation. This created a problem for his agents
and administrators in the New World, who were faced with the task of
implementing orders that had been issued many months earlier and which often
were not applicable to the current situation. In this managerial nightmare (total
responsibility and no autonomy) the King’s officers learned to abide by the
maxim: “se obedece pero no se cumple,” (to obey but not comply). See also
Systems-semantics (Chapter 21. Talking to the System) and Delayed Feedback
(Chapter 29. Feedback and the Future).
[a. ]a.See also Mark Twain:The Man That Corrupted Hadleyburg. The
admonition: “Lead us into temptation,” is a soundly-based Systemantic
principle.
[b. ]b.As is so often the case with profound insights into Systems-behavior, this
principle keeps popping up spontaneously and apparently independently. It
reappears as theAnna Karenina Principle in Jared Diamond’sGuns, Germs, and
Steel: “. . .success requires avoiding many separate possible causes of failure.”
[a.]a.Change Agents tend to survive, between jobs, by writing magazine articles
explaining the reasons for the disaster that struck the latest object of their
change-agentry.
[a.]a.As usual, G. Bateson was among the first to appreciate what the rat is really
up to. See also the Harvard Law of Animal Behavior, page 22.
[b].We’re talking 1986 here. Interestingly enough, in 2012 the mighty Cube still
has its devotees.

[c. ]c.Significantly, starting configurations can only be changed by actually
dismantling the Cube, using a screwdriver.
[c. ]c.A pertinent example is the Kissimmee River Canal, a 52-mile long channel
dredged through the Florida Everglades several decades ago to drain the
swamps. Built at a cost of 29 million dollars, it is to be filled in over the next few
decades at a cost of perhaps 65 million dollars in order to restore the swamps,
which were belatedly noted to contain most of Florida’s drinking water.
[c.]c. See Glossary: EVALUATlON.
[d.]d. In aggravated cases, Scapegoating and Escalation may be combined.
Failure is then ascribed to lack of vigor in persecuting the Scapegoat. Everyday
speech seems to lack a term for this second-order Delusion. Following
Parkinson’s lead (see reference to Injelititis, Chapter 8), we suggest Escalusion
(for Escalated Delusion), or, for the more mathematically-minded, Delusionsquared, abbreviated D2 . Also known as Khomeini’s Heuristic.
[c.]c.The subjective aspect of Strangeness has been dealt with already. (See Selfreference,supra)
[a.]a.See Logical Levels, Chapter 34.
[a.]a.Ifyou’re lucky, that is. Family Systems are a lot more complex, touchy, and
unpredictable than Space Probes. What we’re talking about here is
theprincipleof the thing. In Family Systems, any strategy that yields a ten or
twenty percent success rate is a valuable asset, to be treasured and tried out
whenever the situation seems promising.
[a. ]a.No.
[b] The boy later became a Rhodes scholar.
[a] The interested reader is referred to the essay by Johann Klaassen, which
asserts that “Science is a System, too.”
[a] Lest this be regarded as an isolated example, a mere fluke, we hasten to add
that the Russians dropped a fifty-megaton nuclear bomb upon their own territory
for the same purpose—to find out what would happen if someone, etc.
[b] In the overheated context of a nuclear power plant, molten (and radioactive)
sodium can be referred to as a “coolant”. See SYSTEMS DELUSIONS.
[c] Readers who wish to pursue this subject in more detail are referred to such
classics as Peter Hall’sGreat Planning Disastersand Edward Tenner’sWhy
Things Bite Back. Technology and the Revenge of Unintended Consequences.
[d] This systems-delusion is not restricted to the United States. Canada, for
example, has recently broken up its Trans-Canada Railroad, thereby severing one
of the major links that bind together and nourish the hundreds of towns and
villages that stretch along the railroad for four thousand miles from coast to

coast.
[e] Mindful of the fact that the “real purpose” of a given system is what
someonewishesit would do, we here unhesitatingly declare our personal bias: if
the system impinges on the life of the citizens generally, it should be judged at
least in part from the standpoint of the citizens: does it workforthem
oragainstthem?
[f] Possibly galvanized by this acme of bureaucratic glaciality (isn’t it fun to mix
metaphors?) the British Admiralty responded in record time to a subsequent
challenge: the demonstration that lime juice prevents scurvy. From first proof of
effectiveness to actual distribution of limes to the sailors took onlyseventy years.
However, scurvy continued to occur until it was realized that the Admiralty, in
its worship of the bitch-goddess Economy, was buying the cheapest limes, which
were lacking in Vitamin C.
[a] Or you could just send me a message at my web site address. I won’t promise
to reply, but I will read every entry.
[a] For the origin of Agnes Allen’s Law, see Notes and References, Note 14.
[b] On the question of Systems and self-reference, see Chapter 36. The Problem
in the Solution.
[d] While denying, on principle, that such is the case, we admit to certain
parallelisms in development of the two fields.
[e] The name is genuine.
[a] So named in honor of Milton H. Erickson, who tried never to solve a problem
in the same way twice.
[b] See Chapter 19, footnote b.
[i] (Injelititis):Parkinson, CN (1957),Parkinson’s Law, (Boston: Houghton
Mifflin) p. 78.
[ii] (Incompetence):Peter, LJ and R Hull (1969),The Peter Principle, (New
York: Bantam).
[iii] (Palaeomagnetism and plate tectonics rejected):John McPhee. “Annals of
the Former World. Basin and Range II.”New YorkerMagazine, October 27, 1980,
p. 139.
[iv] (Computer-defended ship sunk by “friendly” missile):“Friendly Fire.”
Article inCurrentssection ofScience ’83(May, 1983), p. 10. Based on a report in
British magazineNew Scientist. Story denied by British defense minister Peter
Blaker. A more recently released story alleges that the ship’s commander was on
the telephone to headquarters in London and that the ship’s computer couldn’t

function while the telephone was in use. See also the F .L.A. W . (Chapter 8): IF
THE SYSTEM SAYS IT HAPPENED, IT HAPPENED. “Captain of the
Sheffield Jammed Ship Defenses.” London, May I5 (AP).The New York Times,
Friday, May 16, 1986, p. 5.
[v] (Police in Brazil protest low pay, refuse to make illegal arrests):NBC News,
Channel 4, Detroit, Michigan, Wednesday, October 17, 1979.
[vi] (Workers strike for right to strike):The National (Windsor Channel 9—
CBC) 10 PM, September 7, 1986.
[vii] (“Don’t send us the records. . . we don’t have room for them.”):“Reagan
Administration Classifying Increasing Numbers of Documents.” (FromThe
Washington Post).Ann Arbor(Michigan)News, Sunday, May 12, 1985, page B6.
Steven Garfinkel, director of the Information Security Oversight Office, is
quoted as saying the message from the National Archives and Records
Administration to other government agencies is basically as above.
[viii] (Emergency Hot Line Runs Three Hours Late):Detroit(Michigan)Free
Press, July 2, 1983.
[ix] (Most computer runs reveal what needs to be corrected next in the quest
for the correct answer):John G. Kemeny.Man and the Computer. Scribners.
New York. 1972, pp. 15, 18, 22.
[x] (Problems are not the problem; Coping is the problem):Virginia Satir and
Michele Baldwin.Satir Step By Step. A Guide to Creating Change in Families.
Science and Behavior Books, Inc. Palo Alto, California 94306. 1983, p.156.
[xi] (Demons in Systems):Hugh Kenner. Review ofSystemanticsentitled “The
Big Picture” inPrint Queue. Regular Feature inBYTEMagazine, January, 1990, p.
416.
[xii] (Things that aren’t working well):Laurence J. Peter and Raymond Hull.The
Peter Principle. New York, Bantam, 1969.
[xiii] (The Five Percent Rule):Tina Lam. “Upset NRC Keeps Fermi At 5%
Power.”Ann Arbor(Michigan)News, Wednesday, September 11, 1985, page A1.
Considering the fact that the Fermi Number One plant has been kept inactive for
over six years since its licensing in 1979 (even longer since actual physical
completion) it would have to run flawlessly for several years at maximum rated
capacity just to attain the 5% level.
[xiv] (Origin of Murphy’s Law):Jack Smith. “The Lawful Truth.” VIEW, Part
IV.The Los Angeles Times, Thursday, January 13, 1977. The author reports
receiving a letter from George E. Nichols (Reliability and Quality Assurance
Manager of the Viking Project at Caltech Jet Propulsion Lab), attributing origin

of “Murphy’s Law” to Capt. Ed. Murphy, a development engineer for Col. J. P.
Stapp’s rocket sled research at Edwards Air Force Base, Muroc, California, in
1949. This article also gives the origin of Agnes Allen’s Law (ALMOST
ANYTHING IS EASIER TO GET INTO THAN OUT OF). TheTimesarticle was
submitted to me by Mr. S. A. Lanzarotta of Xerox Corp. in January of 1977.
[xv] (General Semantics):Korzybski, Alfred (1994).Science and Sanity: An
Introduction to Non-Aristotelian Systems and General Semantics (5th ed.).
Brooklyn, NY: Institute of General Semantics.
[xvi] (General System Theory):Bertalanffy, L. von (1969).General System
Theory. New York: George Braziller.
[xvii] (One-upmanship):Stephen Potter.One-Upmanship. New York. Henry Holt
and Co. 1951.
[xviii] (Problem of Table Shape in Diplomatic Conferences):C.N.
Parkinson.Parkinson’s Law. Boston. Houghton Mifflin. 1957, p. 17.
[xix] (Self-service):Russell Baker. “The End Result of Self-Service is a Bit
Deadly.”Detroit Free Press, Sunday, July 17, 1983, p. 3B.
[xx] (“God moves. . .”):William Cowper.Light Shining out of Darkness. Olney
Hymns. 1879.
[xxi] (Reality More Complex Than It Seems):Susan West. “The New
Realism.”Science 84, July/August, 1984, p. 31.
[xxii] (Observatory dome rains on telescope within):Detroit(Michigan)Free
Press, April 11, 1976.
[xxiii] (HMS QE 2’s Boilers Fail Simultaneously):Personal communication
from Percival M. Sax, Jr., C.E., dated December 26, 1976, who reports he was
told personally by Captain Mortimer Heher “that the designers had provided for
four boilers, so that one would always be out of service and under maintenance,
but there was simply not enough money for the fourth boiler. . .”
[xxiv] (Management by Objectives: Goals and Objectives Mania fails to
achieve its Goals and Objectives):Harry Levinson. “Management by Whose
Objectives?”Harvard Business Review: July-August, 1970, pp. 125-134.
“Because it is based on a reward-punishment psychology, the process of
management by objectives in combination with performance appraisal is selfdefeating. “ (Reference provided by J .E. Swanson of Livonia, Michigan).
[xxv] (Our little systems. . .):Alfred, Lord Tennyson.In Memoriam. Prologue,
Stanza 5 (1850)
[xxvi] (Futurology):Paul Watzlawick.How Real Is Real?New York. Vintage.
1976. p. 203, footnote: “In spite of highly sophisticated, computer-based

projections, it seems almost impossible to go much beyond the year 2000, and
2100 is the limit of even tentative predictability.” See also: Mihaijlo Mesarovic
and Eduard Pestel.Mankind at the Turning Point. The Second Report to the Club
of Rome. New York. Signet. New American Library. 1974.
[xxvii] (May God us keep. . .):William Blake,Letter to Butts,10 January 1802.
In: G. Keynes, ed.The Complete Writings of William Blake. New York. Random
House, 1957, p.811. Quoted in David Lipset.Gregory Bateson. The Legacy of a
Scientist.Boston. Beacon, 1982, p. 52.
[xxviii] (University Scholar, functions):Eugene V. Rostow. “In Defense of the
Ivory Tower.”Yale Alumni Magazine. June, 1972, pp. 5-7. Also: William
Arrowsmith. “The Shame of the Graduate Schools.”Harper’s Magazine, March,
1966, pp. 52-59.
[xxix] (The Trouble With Leadership Training. . .):Fred E. Fiedler. “The
Trouble With Leadership Training Is That It Doesn’t Train Leaders.”Psychology
Today, February, 1973, pp. 23 ff.
[xxx] (Drawing a Distinction):G. Spencer-Brown.Laws of Form. New York.
Dutton. 1979, p. 3.
[xxxi] (Wrong names perpetuate problems):Paul Watzlawick, John Weakland,
and Richard Fisch.Change. Principles of Problem Formation and Problem
Resolution. New York. Norton. 1974, pp. 159-160.
[xxxii] (The Naming Game):Lao-tzu. In: Witter Bynner.The Way of Life
According to Lao-tzu.New York. John Day. 1944, p.25.
[xxxiii] (U.S. negotiator “very satisfied” with talks that haven’t happened
yet):THE NATIONAL: Canadian National Television News, CBET (Channel 9),
CBC, Windsor, Ontario, March 6, 1985.
[xxxiv] (Information rarely leaks up):Helen Harte.Management Consulting in
Complex Organizations: Mergers and Acquisitions.Presented at the Colloquium
on Managing Complexity, Toronto, Ontario, Canada, April 3-5, 1998.
[xxxv] (Hypnosis by Computer):Associated Press release. “Glitch multiplies
hotel bills 100 times.” Posted on CNN.com/ travel, Friday, November 1, 2002.
[xxxvi] (Neighborhood bank issues giant line of credit, takes banking giants
down with it):Mark Singer. “Funny Money.”Annals of Finance (Penn Square
Bank— Part I.) New YorkerMagazine, April 22, 1985, p. 51, andPart II. New
YorkerMagazine, April 29, 1985, p. 42. The reference is on page 45 of Part II.
[xxxvii] (Amtrak trains all over the U.S. halt, wait for clock to catch up):Ann
Arbor(Michigan)News.Editorial. “Twilight Zone.” Sunday, November 3, 1985,
p. B12.

[xxxviii] (Nuclear reactor said to be “shut down” while still generating 200
megawatts):Mike Gray and Ira Rosen.The Warning: Accident at Three Mile
Island. Chicago. Contemporary Books, Inc. 1982, p. 89. See also: Harold W.
Lewis. “The Safety of Fission Reactors.”Scientific American 242(3): 53-65, p.
57.
[xxxix] (War against cancer stalemated):Editorial. Overoptimism about
cancer.The Lancet. Vol. 355, Number 9199. Saturday, 15 January, 2000, p. 157.
[xl] (Systems-Delusions):Irving L. Janis. “Groupthink.”Yale Alumni Magazine
36: 16-19, (January) 1973.
[xli] (Rohe’s Theorem):Thomas Rohe. Personal Communication, April 25,
1979.
[xlii]
(Congress
Exempts
Self
from
Own
Acts):Cheryl
Arvidson.Commentary:“Double Standard Alive, Thriving in Congress.”
(UPI).Ann Arbor(Michigan)News, Friday, June 29, 1979, page A-12. See also:
Judi Hasson. “‘The Last Plantation.’ Congress Legislates Everybody Except. . .
Congress.” (UPI).Ann Arbor(Michigan)News. Sunday, April 14, 1984, page B-5.
[xliii] (Exploiting the System):“McIlroy Was Here.”Scientific American 241:2
(August, 1979), p. 80. Article based on a paper by C.A. Pallis and A.N. Bamji
inBritish Medical Journal, 1979: i: 973-975.
[xliv] (“Adding Manpower to a Late Software Project Makes It
Later”):Frederick P. Brooks, Jr.The Mythical Man-Month. Essays on Software
Engineering.Reading, Massachusetts. Addison-Wesley. 1975, p. 25.
[xlv] .(“Lead me away. . .”):Sophocles.Antigone. Quotation is from the last
words of Creon at the end of the third play in theOedipustrilogy. Reference in:
Erich Fromm.Greatness and Limitations of Freud’s Thought. New York. Harper
and Row, 1980, p. 37.
[xlvi] (Air Force General surprised to learn that submarines actually travel
under water):Daniel Ford. “The Button—I.”A Reporter At Large.New
YorkerMagazine, April 1, 1985, p. 86. In testimony before Congress in April,
1983, under questioning by Senator Sam Nunn, General Bennie L. Davis,
Commander-in-Chief of the Strategic Air Command, appeared unaware that
submarines actually travel under water.
[xlvii] (Red Telephone removed from Oval Office, President Kennedy can’t
find it):Daniel Ford,loc. cit., p. 54.
[xlviii] (Goals and Functions of the System):C. West Churchman.The Systems
Approach. New York. Dell, 1968, p. 77.
[xlix] (Equifinality):Ludwig von Bertalanffy.General System Theory. New York.

Braziller. 1968, p. 142.
[l] (The System Is Its Own Best Explanation):Paul Watzlawick, Janet Helmick
Beavin, and Don D. Jackson.Pragmatics of Human Communication. New York.
W.W. Norton, 1967. pp. 127-129 (Section 4.33: “Equifinality.”)
[li] (“Graceful Degradation”):Alfred Z. Spector. “Computer Software for
Process Control.”Scientific American 251:3 (September, 1984), p. 185.
[lii] (Haiti needs help in asking for help):Alan Riding. “Saving Haiti.”Saturday
Review, May 17, 1975, p. 57.
[liii] (Failure-mode mantras for meditation: 1):“The core is in a mode that this
is just not designed for.” Quote is from Edson Case, an executive officer at Staff
headquarters of the Nuclear Regulatory Commission. In: Mike Gray and Ira
Rosen.The Warning: Accident at Three Mile Island. Chicago. Contemporary
Books, Inc. 1982, p. 214.
[liv] (Failure-mode mantras for meditation: 2):“We saw failure modes the like
of which have never been analyzed.” Quote is from Roger Mattson, head of
NRC division of Systems Safety. In: Mike Gray and Ira Rosen.The Warning:
Accident at Three Mile Island. Chicago. Contemporary Books, Inc. 1982, p.218.
[lv] (Pyramid of Snofru falls down):Kurt Mendelssohn. “A Scientist Looks At
The Pyramids.”American Scientist 59: 210- 220 (March-April) 1971.
[lvi] (Anti-meltdown Device Fails, Causes Meltdown):John G. Fuller.We Almost
Lost Detroit. New York. Reader’s Digest Press. 1975. p.220.
[lvii] (“Sin on” Bible):Verbatim, Volumes I and II.Essex, Connecticut,
VERBATIM, The Language Quarterly. 1978. (Distributed in the United States
and Canada by Stein and Day). p. 186. “In the first Bible printed in Ireland
(dated 1716),John v, 14, reads, ‘sin on more,’ instead of ‘sin no more.’” From a
review ofBrewer’s Dictionary of Phrase and Fable. Rev. by Ivor H. Evans.
Harper and Row, 1970.
[lviii] (One word missing from computer program, Mariner I Venus probe
blown up on launching):Steve Olson. “Sage of Software.”Science ’84.
(Jan/Feb), pp. 75-80. Discusses the structured programming concepts of Edsger
Dijkstra.
[lix] (Negative gravity discovered just in time):Steve Olson,loc. cit.
[lx] (Phantom Dialing):NBC Channel 4, Detroit (Michigan), March 5, 1985,
8:10 AM EST.
[lxi] (Intermittent Bugs prefer to disrupt complex projects such as the maiden
voyage of the Space Shuttle):Alfred Z. Spector. “Computer Software for Process
Control.”Scientific American 251:3, p. 178.

[lxii] (“One does not know all the expected effects of known bugs”):Brooks,
op. Cit., p. 148. “Furthermore, the fixing of the documented component bugs
will surely inject unknown bugs. . .”
[lxiii] (Famed Messier catalogue of star clusters and galaxies began as a list of
objects NOT to be looked at):Nigel Calder.Einstein’s Universe. New York.
Viking, 1979, p. 3.
[lxiv] (Form and Function of Systems):Norbert Wiener.The Human Use of
Human Beings. New York. Avon. 1950, p. 79.
[lxv] (New Functions Appear Suddenly):Watzlawick,op. cit., p. 161. In
reference to the Primate brain, the author states, “. . . the emergence of new and
higher functions occurs in a stepwise fashion. . . at around 1000 grams the
richness of a brain’s organization. . . permits the development of language.”
From the footnote on the same page: “. . . increases in . . . complexity bring
about stepwise, discontinuous increments of . . . functioning. These increases are
virtually impossible to predict.”
[lxvi] (Nuclear Power Plants as Nuclear Bombs Already in Place):Jonathan
Schell.The Fate of the Earth.New York. Knopf. 1982, pp. 60-61.
[lxvii] (Great British Groundnut Scheme located by Mistake in East Africa
Rather than West Africa, Produces Peanuts for a Dollar Apiece):Kirkpatrick
Sale.Human Scale. New York. G.P. Putnam’s Sons. 1980, pp. 154-155.
[lxviii] (Bakolori Dam planners ignore people living both above and below the
dam; no wheat gets grown):Regine Reim. “Relief Agencies Can Make Food
Crises
Worse.”Deutsche
PresseAgentur.
(Rome).
TheAnn
Arbor(Michigan)News, Sunday, December 2, 1984, page B8.
[lxix] (50,000 auto deaths per year accepted as just a fact of life):Arthur M.
Grossman, M.D. “Americans Called Hostages to Cars; Top ‘Pathogen’ in
Young.”Perspective and Commentary(Feature) in:Pediatric News, Vol. 18, No.5,
May, 1984, page 3.
[lxx] (U.S. street railway system dismantled, replaced by busses and autos at
huge cost in human life, pollution, congestion, noise, and energy
consumption):Barry Commoner.The Poverty of Power.New York. Knopf. 1976.
pp. 188-195.
[lxxi] (Heart attack epidemic subsiding on its own; cause unclear):Reuel A.
Stallones. “The Rise and Fall of Ischemic Heart Disease.”Scientific American
243(5): 53-59, November, 1980.
[lxxii] (“Obesity May Be Healthy After All”):Susan Fogg. “Obesity May Be
Healthy After All.” (Newhouse News Service).Ann Arbor(Michigan)News,

Sunday, July 1, 1979, page A-2. “In a review of 17 longterm health studies, Dr.
Reubin Andres of the National Institute on Aging found that in no instance were
death rates higher among the obese—even in those 30 percent over the ideal
weight.”
[lxxiii] (Salt May Be Good For You):“Study Finds Proper Diet, Not Salt Ban,
Curbs Hypertension.”Ann Arbor(Michigan)News(Washington, D.C., AP).
Friday, June 22,1984, p. C3. Report of an article published that day
inSciencemagazine by Dr. David A. McCarron and coworkers.
[lxxiv] (Disease Theory of Mental Illness):C.G. Jung.The Archetypes and the
Collective Unconscious.New York. Princeton University Press. 1959. Page 280.
Also: Peter Hayes. “The Nosological Status of Schizophrenia.”Lanceti (June 16,
1984), pp. 1342-1344. (Traces the basic error in logic back to Kraepelin). And:
Jay Haley.Reflections on Therapy and Other Essays.1981. Chevy Chase,
Maryland. The Family Therapy Institute of Washington, D.C. See especially
Chapter 2.The Family of the Schizophrenic: A Model System, pp. 64-93.
[lxxv] (Pyramid-building as a Runaway phenomenon in a Total System):Kurt
Mendelssohn.The Riddle of the Pyramids. London. Thames and Hudson. 1974.
Reference in: Leon E. Stove and Bruce Kraig.Stonehenge. The Indo-European
Heritage. Nelson-Hall. Chicago. 1978. In Chapter 4, in an essay entitled
“Parkinsons’s Law and Megalithic Decadence” (pp. 132-136), these authors
refer to Mendelssohn’s conclusions as follows: “Once begun, the building
program had to continue; it could not stop, because it was the only effective
means of redistribution. . .”
[lxxvi] (Unexpected Interactions):W. Evert Welch. “Systemantics.” (A
review),Production and Inventory Management 19: 4, p. 50.
[lxxvii] (Fearful Symmetry):The term has been used in another context by
Antony Jay to refer to the “fearful symmetry” of the ideal or classical
hierarchical organization chart: Antony Jay.Management and Machiavelli. New
York. Bantam. 1967. Chapter 9, “The Fearful Symmetry”, pp. 70-82. Our usage
corresponds to the definition of Symmetry as originally employed by Bateson
and as more fully defined in Watzlawick, et al.,Pragmatics of Human
Communication, p. 68.
[lxxviii] (The Batesonian Sleeping Dog):Gregory Bateson. “The Group
Dynamics of Schizophrenia.” In:Chronic Schizophrenia: Explorations in Theory
and Treatment.Edited by L. Appleby, J.M. Scher, and J. Cumming. Glencoe,
Illinois. The Free Press. 1960. Reprinted in: Bateson, G.Steps to an Ecology of
Mind. New York. Ballantine. 1972, pp. 228-243. The reference is on page 229,
also p. 482. The dog reappears in Bateson, G.Mind and Nature. A Necessary

Unity. New York. Dutton. 1979, p. 101. Watzlawicket al. (Pragmatics of Human
Communication, p. 29) cite the same example.
[lxxix] (The Message Sent Is Not Necessarily the Message Received):Michael
Holtby. “Origin and Insertion of Script Injunctions.”Transactional Analysis
Journal 6: 4 (October, 1976), p. 373.
[lxxx] (Extra-large Tsetse Flies):P.D. Dunn.Appropriate Technology.
Technology with a Human Face. New York. Schocken. 1979. p. 50.
[lxxxi] (Every Picture Tells a Story, But Not the Same Story):Ibid., p. 48.
[lxxxii] (Impossibility of NOT Communicating):Virginia Satir.Conjoint Family
Therapy. Palo Alto, California. Science and Behavior Books, Inc. 1964. Third
Edition, 1983, p. 100 (Chapter IX, paragraph II). See also: Paul Watzlawick,
Janet Beavin, and Don D. Jackson.Pragmatics of Human Communication. New
York. W.W. Norton. 1967, p. 51. And also: Gregory Bateson.Steps to an Ecology
of Mind. New York. Ballantine. 1972, p. 452. In “Form, Substance, and
Difference,” being the Nineteenth Annual Korzybski Memorial Lecture,
delivered January 9, 1970. For an illuminating footnote on the origin of this
notion see: Jay Haley.Reflections on Therapy and Other Essays. Chevy Chase,
Maryland. The Family Therapy Institute of Washington, D.C. 1981, p. 39
(footnote).
[lxxxiii] (The Meaning of a Communication is the Behavior that
Results):Richard Bandler and John Grinder.Frogs into Princes. Neurolinguistic
Programming. Moab, Utah. Real People Press. 1979, p. 61. Also: John Grinder
and Richard Bandler.Trance-formations. Neurolinguistic Programming and the
Structure of Hypnosis. Moab, Utah. Real People Press. 1981. p.24.
[lxxxiv] (Lynd’s Lemma):Robert S. Lynd.Knowledge for What? The Place of
Social Science in American Culture.Princeton, New Jersey. Princeton University
Press. 4th Printing, 1945.
[lxxxv] (Information Decays):Norbert Wiener.The Human Use of Human
Beings. Cybernetics and Society.New York. Avon. 1950, p. 159.
[lxxxvi] (Inaccessibility Theorem):Editorial. “Birth Counts.”Lanceti, June 30,
1984, pp. 1448-1449. (Referred to therein as Finagle’s Law of Health Data).
[lxxxvii] (Mindless bureaucracies):Edward T. Hall.Beyond Culture. New York.
Anchor/Doubleday. 1976. p. 218.
[lxxxviii] (How to Speak and Understand Martian):Eric Berne.What Do You
Say After You Say Hello?New York. Grove Press. 1972. p.100.
[lxxxix] (“Eliminate R.F.D.2”):From a Talk of the Town Column,The New
YorkerMagazine. Reported without further reference in Erving Goffman.Frame

Analysis. New York. Harper Colophon. 1974. p. 319.
[xc] (Problem-solving Considered as a Problem):Paul Watzlawick, John
Weakland, and Richard Fisch.Change. Principles of Problem Formation and
Problem Resolution.New York. W.W. Norton. 1974.
[xci] (Clothing Can Keep You Warm: Fuegians Slow to Grasp):Charles
Darwin.The Voyage of the Beagle.(First published 1839). New York. Doubleday.
1962. p. 213. See also: B.F. Skinner.Beyond Freedom and Dignity.New York.
Bantam. 1972. p. 29.
[xcii] (Passivity):Aaron Schiff and Jacqui Schiff. “Passivity:’Transactional
Analysis Journal.Vol. I, No.1, 1971. p. 71.
[xciii] (Away from a Theory of . . .”):Eric Berne. “Away from a Theory of the
Impact of Interpersonal Interaction on Nonverbal Participation.”Transactional
Analysis Journal 1:1 (January, 1971), pp. 6-13.
[xciv] (“Getting Rid Of. . :’):Stuart Plattner. “Rural Market Networks.”Scientific
American, May, 1975. pp. 66-79. Refers to the work of G. William Skinner as
reported in articles published in 1964 and 1965 in theJournal of Asian Studies,
Volume 24.
[xcv] (Taoism and Problem Avoidance):Raymond M. Smullyan.The Tao Is
Silent. New York. Harper and Row. 1977.
[xcvi] (Creative Incompetence):Dr. Laurence J. Peter and Raymond Hull.The
Peter Principle. New York. Morrow. 1969, pp. 127-138.
[xcvii] (Zilwaukee Bridge repairs threaten to cost more than the original
estimate for the whole thing):“Work on Zilwaukee Bridge to Resume with
Spring Thaw.”Ann Arbor(Michigan)News, Sunday, February 10, 1985, page A16.
[xcviii] (Asbestos Removal Costs More Than Installation):“Risks of Asbestos
Removal.”Lancetii, November 26, 1983, p. 1244.
[xcix] (No one wants to clean up asbestos):“Asbestos in Schools.”Lanceti, May
11, 1985, p. 1091.
[c] (Unfavorable Settings: The Galloway Technique):D.L. Baars. “Grand
Canyon by River.” Chapter in:The Grand Canyon: Up Close and
Personal.Edited by R.C. Euler and F. Tikalsky. Western Montana College
Foundation. 1980.
[ci] (Gresham’s Law of Therapeutics):D.H. Spodick: “Randomized controlled
clinical trials. The behavioral case.”Journal of American Medical Association
247: 2258-2260 (April 23/30) 1982. Source of reference: Irving
Emanuel.Lancetii, 2 July 1983. From Spodick’s article: “ . . .repeated reporting

of biased data . . . giving an illusion of success due to sheer quantity of
superficially favorable outcomes. The result is a Gresham’s Law of therapeutics:
Large amounts of poor data tend to preempt any amount of good data.”
[cii] (“Plan to scrap the first system. . . you will anyway”):Frederick P. Brooks,
Jr.The Mythical Man-month. Essays on Software Engineering.Reading,
Massachusetts. Addison-Wesley. 1975. p. 116.
[ciii] (Airborne antenna, five miles long, plays snap-the-whip with mother
ship.):Daniel Ford. “The Button-II.”A Reporter At Large. New YorkerMagazine,
April 8, 1985, p. 79. (Article begins on page 49).
[civ] (Vasa sinks on launch):Bengt Ohrelius.Vasa: The King’s Ship. New York.
Chilton Books, 1962. The story is retold in: John Train.Remarkable
Occurrences. New York. Potter. 1978, pp. 23-24.
[cv] (Stable Configurations):W. Ross Ashby.Design for a Brain. New York.
Wiley. 1952. See especially Chapter 11. The Fully-joined System, pp. 148-157.
[cvi] (Arcana of Corporate Mergers):Helen Harte.Management Consulting in
Complex Organizations: Mergers and Acquisitions.Presented at the Colloquium
on Managing Complexity, Toronto, Ontario, Canada, April 3-5, 1998.
[cvii] (Five-year plans fail to meet quotas):E.F. Schumacher.Small is Beautiful.
Economics as if People Mattered. New York. Harper and Row Perennial Library.
1973. p. 175.
[cviii] (Output is Dangerous. Keep it In The Study Phase):From “Paperland”, a
documentary directed by Donald Brittain. Produced by the Canadian
Broadcasting Company and National Film Board of Canada. Shown on USA
Cable Network, Sunday, January 23, 1983, at 3 PM, E.S.T.
[cix] (WASH-740 Update suppressed):John G. Fuller.We Almost Lost Detroit.
New York. Reader’s Digest Press. 1975. See especially Chapters Ten and Eleven
for a detailed account of the suppression of the 1965 update of the 1957
Brookhaven Report (“WASH-740”).
[cx] (Wishful Feedback at Three Mile Island):Mike Gray and Ira Rosen.The
Warning: Accident at Three Mile Island. Chicago. Contemporary Books, Inc.
1982, p. 75, p. 77.
[cxi] (Ultrastability):W. Ross Ashby.Design for a Brain. New York. Wiley.
1952. p. 108.
[cxii] (Progress always transcends the obvious):A.N.Whitehead.Process and
Reality. Corrected Edition.Eds. D.R. Griffin and D.W. Sherburne. New York.
Free Press. 1985, p. 9.
[cxiii] (Nature only wise when feedbacks rapid):26. Commons and Community:

The Idea of a Public. Kenneth Boulding. In:Managing The Commons. Edited by
Garrett Hardin and John Baden. W.H.Freeman and Co. San Francisco 1977, p.
284.
[cxiv] (The Axiom of Experience):Gerald M. Weinberg.An Introduction to
General Systems Thinking. New York, Wiley and Sons, 1975, p. 141.
[cxv] (Data is always locked into the past):Helen Harte.Management Consulting
in Complex Organizations: Mergers and Acquisitions.Presented at the
Colloquium on Managing Complexity, Toronto, Ontario, Canada, April 3-5,
1998, p.5.
[cxvi] (Utilizing the Utilization Technique):Milton H. Erickson. “Further
Clinical Techniques of Hypnosis—Utilization Techniques.”American Journal of
Clinical Hypnosis 2: 3-21 (July, 1959). Reprinted in: Rossi, Ernest L., Editor:The
Collected Papers of Milton H. Erickson. New York. Irvington Publishers. 1980.
Volume I, pp. 177-205.
[cxvii] (Complex Systems Have Complex Behaviors):W. Ross Ashby.An
Introduction to Cybernetics. London. Methuen. 1964. First published by
Chapman and Hall, Ltd., 1956. Page 54 (Section 4/11).
[cxviii] (“Crash” program produces two million doses of the wrong vaccine):
Ann Arbor (Michigan) News, June 3, 1976.(Washington, D.C., AP news report)
[cxix] (“If it’s not worth doing it’s worth doing well”):This variation is
attributed to Gregory Bateson by Jay Haley in: Jay Haley.Reflections on Therapy
and Other Essays. Chevy Chase, Maryland. The Family Therapy Institute of
Washington, D.C. 1981. Page 52.
[cxx] (To obey but not comply):Paul Watzlawick.The Language of Change.
Elements of Therapeutic Communication.New York, Basic Books, 1978, pp. 7980.
[cxxi] (“Imagination in Evil”):C.G. Jung.The Undiscovered Self. New York.
Mentor. 1959. (Copyright 1957, 1958 by C.G. Jung), p. 109.
[cxxii] (“Lead Us Into Temptation”):Mark Twain. The Man That Corrupted
Hadleyburg. InThe Signet Classic Book of Mark Twain’s Short Stories. New
York. Signet Classic. 1985, pp. 400-442.
[cxxiii] (Minsky’s Admonition):Marvin Minsky. Reference in Patrick Huyghe.
“Of Two Minds.”Psychology Today, December, 1983, p. 34. “He believes that
the mind, in order to succeed, must know how to avoid the most likely ways to
fail.”
[cxxiv] (The Anna Karenina Principle):Jared Diamond.Guns, Germs, and Steel.
The Fates of Human Societies. New York. Norton. 1997, p. 157.

[cxxv] (“If It Puts A Weapon In Your Hand . . .”):C.G. Jung.op. cit., p. 112.
[cxxvi] (Right Logical Level):Paul Watzlawick, John Weakland, and Richard
Fisch.Change. Principles of Problem Formation and Problem Resolution. New
York. Norton. 1974. p. 39.
[cxxvii] (The Laboratory Rat Scandal):Gregory Bateson. “The Logical
Categories of Learning and Communication.” 1964. Submitted as a position
paper to the “Conference on World Views” sponsored by the Wenner-Gren
Foundation, August 2-11, 1968. Reprinted in Gregory Bateson.Steps to An
Ecology of Mind.New York. Ballantine. 1972, pp. 279-308. Reference is on p.
282. The rat’s behavior is re-considered in Gregory Bateson.Mind and Nature. A
Necessary Unity. New York. Dutton. 1979, p. 124 and also p. 139. For a more
explicit statement of the rat’s exploratory behavior as a series of probes, see: M.
Selvini Palazzoli, L. Boscolo, G. Cecchin, and G. Prata.Paradox and
Counterparadox. A New Model in the Therapy of the Family in Schizophrenic
Transaction. Jason Aronson, Inc. New York and London. English translation,
1978. (Originally published in Italy by Feltrinelli Editore, Milan, 1975), p. 47.
[cxxviii] (The Law of Requisite Variety):W. Ross Ashby.An Introduction to
Cybernetics. London. Chapman and Hall. 1961, page 206.
[cxxix] (Von Foerster’s Ethical Imperative):Heinz von Foerster.On
Constructing A Reality. Address given April 17, 1973, to the Fourth
International Environmental Design Research Association Conference at the
College of Architecture, Virginia Polytechnic Institute, Blacksburg, Virginia.
Adapted and reprinted in: Paul Watzlawick.The Invented Reality. New York. W.
W. Norton. 1984, pp. 41-61. The Ethical Imperative appears on page 60 as
follows: “Act always so as to increase the number of choices.”
[cxxx] (Rubik’s Cube):Douglas R. Hofstadter. “Metamagical Themas.”Scientific
American 244: 3 (March 1981), pp. 20-39.
[cxxxi] (Progress often possible only by seeming to regress):Hofstadter,ibid.
[cxxxii] (Everglades Canal dug, then filled in):“Now You See It, Now You
Don’t.”TIMEMagazine, August 6, 1984. page 56.
[cxxxiii] (System Altered by Probe Used to Test It):A.A. Milne.Winnie-thePooh. New York. Dutton. 1926. See especially Chapter V: “In Which Piglet
Meets a Heffalump.” Collateral Reading: Benjamin Hoff.The Tao of Pooh.New
York. Penguin. 1982.
[cxxxiv] (Self-reference):Douglas R. Hofstadter. In monthly column
forScientific Americanentitled “Metamagical Themas,” two essays on selfreference: (1)Scientific American 244:1, January, 1981, pp. 22-32. (2)Scientific
American 246:1, January, 1982, pp. 16-28.

[cxxxv] (Self-reference, continued):Bradford P. Keeney.Aesthetics of Change.
New York. Guilford Press. 1983, p. 30.
[cxxxvi] (Television schedules a two-hour special on the Television
Schedule):NBC Channel 4, Detroit, Michigan, October 21, 1979. 8-10 PM EDT.
Big Event: “TV Guide—First 25 Years.”
[cxxxvii] (One-fourth of all college math courses now consist of high-school
math):“A Nation At Risk.” Report of the National Commission on Excellence in
Education. 1983. Superintendent of Documents, U.S. Government Printing
Office, Washington, D.C., 20402. 36 pp.
[cxxxviii] (Escalation):Paul Watzlawick, John Weakland, and Richard
Fisch.Change. Principles of Problem Formation and Problem Resolution. New
York. Norton. 1974, pp. 31-39.
[cxxxix] (Green Revolution allows people to starve at higher population
densities than ever before):Garrett Hardin. “An Operational Analysis of
‘Responsibility’.” In:Managing The Commons. (Garrett Hardin and John Baden,
Eds.) San Francisco, W.H. Freeman and Company. 1977, p. 74.
[cxl] (Green Revolution limited by fundamental energy considerations):Paul
Colinvaux.Why Big Fierce Anima1s are Rare. An Ecologist’s Perspective.
Princeton. Princeton University Press. 1978, p. 45.
[cxli] (Stone Money):Mort Rosenblum. “Stone Money Still Used in Yap.”Ann
Arbor(Michigan)News, Sunday, Feb. 4, 1973. See also: Gregory Bateson.
Personal Communication to Paul Watzlawick, reported in: Watzlawick,et al.
Change. p. 96, footnote 5.
[cxlii] (Ethiopian guards protect the wells they used to vandalize):Dunn,op cit.,
p. 91.
[cxliii] (The painfulness of paradigm shifts):Thomas S. Kuhn.The Structure of
Scientific Revolutions.Chicago. University of Chicago Press. 1962. See
especially Chapter VIII:The Response to Crisis.
[cxliv] (France reframed as victim of Napoleon):Duff Cooper.Talleyrand. A
Biography. 1932. Republished 1986 by Fromm Int’l Publ. Corp. New York.
[cxlv] (Reframing):David Gordon and Maribeth Meyers-Anderson.Phoenix.
Therapeutic Patterns of Milton H. Erickson. Cupertino, California. Meta
Publications. 1981. See also: Keeney,op. cit., pp. 25-27.
[cxlvi] (The Net of Indra):Buddha.The Avatamsaka Sutra. In: Francis H.
Cook.Hua-Yen Buddhism: The Jewel Net of Indra. 1977.
[cxlvii] (Ultrastability):W. Ross Ashby.Design for a Brain. New York. Wiley.
1952.

[cxlviii] (Cybernetics of Cybernetics):Margaret Mead. Cybernetics of
Cybernetics. In H. von Foerster, H. Peterson, J. White, and J. Russell
(Eds.).Purposive Systems. New York. Spartan Books. 1968. (Reference in
Keeney, op. cit., p. 76.)
[cxlix] (Ultrastability):W. Ross Ashby.Design for a Brain. New York. Wiley.
1952. p. 108.
[cl] (Cheap Chip Fails; Computer Signals Missile Attack):Daniel Ford. “The
Button—I.” A Reporter at Large.New Yorker Magazine, April 1, 1985, p. 71.
(Article begins on page 43.)
[cli] (Government of Brazil officially encourages smoking to increase
revenues):Fernando C. Barros. “A Government That Encourages Smoking.”
Letter to Editor.Lancet ii (August 15, 1981), p. 366.
[clii] (Save your government some money; die young of lung cancer):John
Cairns.Cancer: Science and Society. San Francisco. 1978. W.H. Freeman and
Company, pp. 162-163.(Horrible example of economic thinking provided by Dr.
William E. Powers.)
[cliii] (New Hospital Stands Empty; People Won’t Use It):Mary Carpenter.
“Restructuring Health Care in the Third World.”Journal of the American
Medical Association 247: 10 (March 12, 1982), pp. 1383-1388.
[cliv] (Nuclear Power Plant sues NRC for Improper Regulation):Mike Gray
and Ira Rosen.The Warning: Accident at Three Mile Island. Chicago.
Contemporary Books, Inc. 1982, p. 268.
[clv] (Asian Clams Clog Cooling Pipes in Arkansas Nuclear Generating
Plant.): Science ’84, December, page 12. Article entitled “Sailing Clams.”
(Feature entitled Currents.)
[clvi] (Japanese Nuclear Power Plants Plagued by Jellyfish Clogging Cooling
Pipes):Barry Commoner.The Poverty of Power. New York. Knopf. 1976, p. 117.
[clvii] (Auto accidents contribute to Gross National Product):Ralph Nader, as
quoted by Schumacher, in Peter N. Gillingham. “The Meaning of Good
Work.”Good Work. New York. Harper and Row, 1979, p. 194.
[clviii] (Science is a System, too.):Johann A. Klaassen. “The Sociology of
Scientific Knowledge and the Activity of Science; or, Science is a System,
too.”Cybernetica 39: 2, 1996.
[clix] (New Health Centers keep health workers out of the field):Carl Taylor,
M.D. Quoted in Mary Carpenter,loc. cit.
[clx] (Ambiguities of Cost-benefit Analysis):Brandon S. Centerwall. “Costbenefit Analysis and Heart Transplantation.” Editorial.New England Journal of

Medicine 304: 15 (April 9, 1981), pp. 901-903.
[clxi] (Seeing Eye, Inc., oversubscribed; Blindness Prevention
overlooked):Garrett Hardin. “An Operational Analysis of ‘Responsibility’.”
In:Managing The Commons(Garrett Hardin and John Baden, Eds.) San
Francisco, W.H. Freeman and Company. 1977, pp. 73-74.
[clxii]
(Space
Shuttle
Aimed
Wrong
Way
for
Laser
Equipment):TIMEMagazine. “A Star Wars Snafu.” July 1, 1985, p. 26.
[clxiii] (Power Plants remain shut down during California energy crisis):John
M. Broder. “California Power Failures Linked to Energy Companies.”The New
York Times, September 18, 2002.
[clxiv] (“Gun Control is utilized when the President makes a speech stating
that he does not believe in gun control.”):Jervis Anderson. “An Extraordinary
People.” In:A Reporter at Large. New YorkerMagazine, November 12, 1984, pp.
109-173. The quotation is from a letter to the editor of theNew York Times.
[clxv] (Oil Spill, Actual Test of Effects Proposed):“Canada Cancels Oil Spill.”
Walpole Island, Ontario (AP).Ann Arbor(Michigan)News, Friday, August 23,
1974.
[clxvi] (Supertankers Bring Super Problems):Noel Mostert.Supership. New
York. Knopf. 1974. See also “Oil Is Pouring On Troubled
Waters.”TIMEMagazine, January 10, 1977, pp. 45-47.
[clxvii] (NRC Buries Reactor Meltdown Study):Daniel Ford. “The Cult of the
Atom.” In:A Reporter At Large. New YorkerMagazine, October 25, 1982. pp.
107-159. Reference is on page 146. See also: John G. Fuller.We Almost Lost
Detroit. New York. Reader’s Digest Press, 1975, Chapters Ten and Eleven, for a
detailed account of the suppression of the 1965 update of the 1957 Brookhaven
Report (W ASH-740).
[clxviii] (Radioactive water at Three Mile Island):Mike Gray and Ira Rosen.The
Warning: Accident at Three Mile Island. Chicago. Contemporary Books, Inc.
1982, p. 191.
[clxix] (Three Mile Island’s emergency call to NRC left with answering
service):Mike Gray and Ira Rosen.The Warning: Accident at Three Mile Island.
Chicago. Contemporary Books, Inc. 1982, p. 122.
[clxx] (Fail-safe shutdown device fails to indicate location of problem leading
to shutdown):Matt Yancey. (AP) “Reactor Safety Problem May Be
Widespread.”Ann Arbor(Michigan)News, Friday, May 13, 1983, p. C-1.
[clxxi] (Unidentified Foreign Object in Nuclear Power Plant):John G.
Fuller.We Almost Lost Detroit. New York. Reader’s Digest Press. 1975.

[clxxii] (Control panel at Three Mile Island has stuck-elevator alarm next to
reactor coolant pressure alarm, permitting correction of two problems at
once):Mike Gray and Ira Rosen.The Warning: Accident at Three Mile Island.
Chicago. Contemporary Books, Inc. 1982, p. 77.
[clxxiii] (Rancho Seco Escapade: Worker drops light bulb, nuclear power
plant crashes):Edward Edelson. “Thermal Shock—New Nuclear-Reactor Safety
Hazard?”Popular Science, June, 1983, p. 55.
[clxxiv] (Glass-clad skyscrapers twist, pop out plates on passersby):Peter
Blake.Form Follows Fiasco: Why Modern Architecture Hasn’t Worked. Boston,
Toronto. Atlantic-Little, Brown, 1974, 1975, 1977, pp. 74-75.
[clxxv] (“Fireproof’ Plastic Dome Burns Briskly: Firefighters Can’t Reach
It):Blake,op. cit., p. 156.
[clxxvi] (Rain Falls Up at UN):Blake,op cit., p. 72.
[clxxvii] (Cargo door problem just not urgent enough to get out of “in”
basket):Moira Johnston.The Last Nine Minutes. New York. Avon. 1978. p. 145.
[clxxviii] (National Airport Safe Because It’s So Dangerous):Moira
Johnston,op cit., p. 123.
[clxxix](Peru-Andes Railroad Uses Diesels That Give Out at 12,000
Feet):William Thompson. “Great Railway Journeys of the World.” PBS,
Channel 56, Detroit, Michigan (WTVS). Sunday, July 17, 1983, 9-10 PM E.D.T.
[clxxx] (Antikilopascalians Win Big):“Victory for Antikilopascal
Lobby.”Lancetii, August 20, 1983, p. 469. In:Pediatrics 72: 6 (December, 1983),
page A58.
[clxxxi] (Consolidated Edison’s fail-safe mechanism turns off the generators,
which then can’t start up again because the power’s off):Kirkpatrick
Sale.Human Scale. New York. Putnams, 1980, pp. 83-87.
[clxxxii] (Complex Debacles):Peter Hall.Great Planning Disasters. Berkeley
and Los Angeles, California. University of California Press. 1981. 308 pages.
[clxxxiii] (Unintended Consequences):Edward Tenner.Why Things Bite Back.
Technology and the Revenge of Unintended Consequences. New York. Knopf.
1996.
[clxxxiv] (Automobile Epidemic):Arthur M. Grossman, M.D. “Americans
Called Hostages to Cars; Top ‘Pathogen’ in Young.”Perspective and
Commentary(Feature) in:Pediatric News, Vol. 18, No.5, May, 1984, page 3.
[clxxxv] (Cascade of Failures):Mike Gray and Ira Rosen,op. cit., p. 98.
[clxxxvi] (Palace Guard Effect: Malfunctioning Backup System seizes control
from normally functioning primary):Alfred Z. Spector. “Computer Software for

Process Control.”Scientific American 251:3, p. 185.
[clxxxvii] (Scientific Creativity):Thomas H. Maugh, II. “Creativity: Can It Be
Dissected? Can It Be Taught?” In: Speaking of Science.ScienceMagazine, Vol.
184, 21 June, 1974, p. 1273. The Author reports that Hans Krebs was taught by
his mentor, Otto Warburg, that research “is the art of finding problems that can
be solved.”
[clxxxviii] (The Repetition Compulsion):David Hanners. “Xcel Nuclear Lapses
Cited by Regulators.” St. Paul Pioneer Press, Sunday, November 17, 2002, p.1A.
[clxxxix] (Definition of “System” produces new terms to be defined):C. West
Churchman.The Systems Approach. New York. Dell, 1968, p. 29.
[cxc] (When is a System “very large” or “too large”?):Ashby,Introduction to
Cybernetics, p. 62. See also: Peter F. Drucker.Management: Tasks,
Responsibilities, Practices.New York. Harper and Row. 1973, especially Chapter
53: “On Being the Right Size”, p. 638, and Chapter 55: “On Being the Wrong
Size,” p. 664.
[cxci] (The Prepunctuated Polar Bear):Richard Bandler and John
Grinder.Frogs into Princes. Moab, Utah. Real People Press. 1979. p. 192.
[cxcii] (The Self-Actuating Laboratory Rat):Gregory Bateson,Mind and Nature.
p. 124 (this is the same reference as given previously, under Lab Rat Scandal:
note 127, Chapter 35).
[cxciii] (The Cybernetic Sleeping Dog):Bateson,Steps, p. 229 (This reference is
the same as given previously, under Batesonian Sleeping Dog, Chapter 19, note
78.)
[cxciv] (The Innovative Dolphin):Karen Pryor.Lads Before the Wind. Harper
and Row. New York. 1975. p. 236. Quoted in Lipset.Gregory Bateson, p. 250.
[cxcv] (The Phenomenological Ferret):B.P. Keeney. “Glimpses of Gregory
Bateson.”Pilgrimage: The Journal of Existential Psychology 7: 17-44, 1979, pp.
23-24. Reference and excerpt in B.P. Keeney.Aesthetics of Change.New York.
Guilford Press. 1983. p. 26.
[cxcvi] (The Ericksonian Otter)Karen Pryor.Lads Before the Wind. New York.
Harper and Row. 1975. pp. 136-37. Quoted in David Lipset.Gregory Bateson:
The Legacy of a Scientist. Boston. Beacon Press, 1980. p. 247, footnote 2.
[cxcvii] (The Analogic Cat):Gregory Bateson. “A Theory of Play and
Fantasy.”Psychiatric Research Reports 2: 39-51, 1955. Quoted in
Watzlawick,Pragmatics, p. 63.
[cxcviii] (The Phlegmatic Frog that fails to jump out of a pan of gradually
heated water):Gregory Bateson.Mind and Nature. A Necessary Unity. New

York. Dutton. 1979, p.98.
[cxcix] (The Bread-and-Butterfly of Lewis Carroll):Lewis Carroll.Through the
Looking Glass.In:The Annotated Alice. Introduction and Notesby Martin
Gardner. New York. The American Library. 1960, p. 223. Discussion in:
Gregory Bateson. “The Birth of a Matrix, or Double Bind and Epistemology.”
Chapter 3 of: Milton M. Berger, Ed.Beyond the Double Bind. New York.
Brunner/Mazel. 1978. pp. 41-64. Reference is on p. 62.
[cc] (The Ouroboros: devours itself tail-first, thus acting out selfreference):B.P. Keeney.Aesthetics of Change, New York. Guilford Press, 1983,
p. 32.
[cci] (The Dog that did not bark in the night):Doyle, AC ‘The Adventure of
Silver Blaze.’ In:The Original Illustrated Sherlock Holmes (New York: Castle
Books), p. 197.

Table of Contents
Copyright
Dedication
Acknowledgments
Preface to the First Edition
Preface to the Second Edition
Preface to the Third Edition
Introduction
Historical Overview
Part One: Basic Theory
A. The Mysterious Ways of Systems
B. Inside and Outside
C. Function and Failure
D. Communication Theory
Part Two: Applied Systemantics
A. Systems and Self-Defense (Meta-Strategies)
B. Practical Systems-Design
C. Management and Other Myths
D. Intervention

