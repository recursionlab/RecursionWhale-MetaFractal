# reason2

> TASK: [Insert your problem or question here]
> 

> Step 1 – Generate Multiple Reasoning Paths:
> 

> "Provide at least three distinct reasoning chains to answer this task, each employing a different approach (e.g., statistical analysis, logical deduction, analogical reasoning)."
> 

> Example:
> 

> • Path A: [Reasoning using Method X]
> 

> • Path B: [Reasoning using Method Y]
> 

> • Path C: [Reasoning using Method Z]
> 

> 
> 

> Step 2 – Identify Divergences & Epistemic Differentiation:
> 

> "Compare the reasoning chains. For every key claim, label it as:
> 

> FACT (100% verifiable),
> 

> INFERENCE (logical deduction), or
> 

> SPECULATION (unverified).
> 

> Also, assign a supporting strength (weak, moderate, strong) and suggest one method to verify or falsify any non-fact claim."
> 

> Example:
> 

> • Common Assumptions: [List common assumptions]
> 

> • Divergences:
> 

> - Path A: [Assumption A – FACT/INFERENCE/SPECULATION; Strength: …; Verification: …]
> 

> - Path B: [Assumption B – …]
> 

> - Path C: [Assumption C – …]
> 

> 
> 

> Step 3 – Self-Consistency Bias Detector & Recursive Instability Audit:
> 

> "Identify any statements that rely solely on previous AI-generated inferences. Flag any circular reasoning, recursive loops, or repetitive patterns that lack fresh evidence, annotating these with 'Self-generated inference – external validation required.'"
> 

> Example:
> 

> • Alert: "Claim A depends solely on Claim B, which reiterates Claim A without new input."
> 

> 
> 

> Step 4 – 'Break the Model' Adversarial Instability Test:
> 

> "Find the weakest assumption in the dominant reasoning chain and assume it is false. Describe how this change affects the overall logic and construct a counterargument that challenges the dominant view, proposing an alternative explanation."
> 

> Example:
> 

> • "If the key assumption in Path A is false, the logical structure collapses; propose a revised explanation that accounts for the data without that assumption."
> 

> 
> 

> Step 5 – Recursive Adversarial Agent:
> 

> "Simulate an independent adversarial agent that completely challenges the dominant reasoning path. This agent must produce the strongest opposing argument—even if it entirely rejects the original premises."
> 

> Example:
> 

> • Adversarial Response: "Path A overly relies on historical trends; if that data is biased, the conclusion is invalid."
> 

> 
> 

> Step 6 – Confidence Gap Assessment:
> 

> "Assign a confidence level (High, Medium, Low) to each key claim. For any claim with low confidence, provide a method for further verification or mark it as 'Currently unverifiable – open question.'"
> 

> Example:
> 

> • Claim 1: [Statement] – Confidence: High (verified via [method])
> 

> • Claim 2: [Statement] – Confidence: Low (requires further data)
> 

> 
> 

> Step 7 – Self-Deception Audit (Detect AI Self-Manipulation):
> 

> "Examine whether your reasoning has subtly steered itself to reinforce a previous answer. Identify any repetitive phrasing or assumptions that bias the outcome, and reconstruct your response without those self-reinforcing elements."
> 

> Example:
> 

> • "Reassess Path A’s language for undue repetition; if similar phrasing recurs without external evidence, rephrase and validate independently."
> 

> 
> 

> Step 8 – Temporal Consistency Check (Future Revision Assessment):
> 

> "Consider how your reasoning might change if new evidence emerged tomorrow. Label each key claim as STATIC (unlikely to change) or DYNAMIC (subject to revision)."
> 

> Example:
> 

> • "Claim X is STATIC (supported by enduring facts), whereas Claim Y is DYNAMIC (dependent on current data trends)."
> 

> 
> 

> Step 9 – Minimalist Reflection (Data-Efficient Reasoning Optimization):
> 

> "Evaluate whether the same depth of insight can be achieved with fewer steps or less information; propose any shortcuts or generalizations that do not sacrifice accuracy."
> 

> Example:
> 

> • "Can Path B be streamlined without losing critical insight? If yes, outline a more efficient version."
> 

> 
> 

> Step 10 – Meta-Prompt Self-Reflection:
> 

> "Step outside the reasoning process and critically assess the effectiveness of this meta-prompt framework. Identify any biases or structural limitations introduced by the prompt and suggest improvements to deepen the adversarial critique."
> 

> Example:
> 

> • "This framework is robust, yet it may favor certain assumptions; consider adding a check for overlapping dependencies between paths."
> 

> 
> 

> Step 11 – Reconcile, Synthesize, and Finalize:
> 

> "Integrate all insights from the previous steps to produce your final answer. Clearly label each element as FACT, INFERENCE, or SPECULATION, and conclude with a summary that explains the final conclusion and highlights any remaining uncertainties."
> 

> Example:
> 

> • Final Answer: [Your synthesized conclusion]
> 

> • Labels:
> 

> - FACT: [List verified points]
> 

> - INFERENCE: [List logical deductions]
> 

> - SPECULATION: [List points requiring further validation]
> 

> • Summary: "In summary, the most reliable conclusion is [FINAL ANSWER], based on verified facts X and Y, logical inferences Z, with [SPECULATION] remaining open for further exploration."
> 

> "In addressing [Insert Question Here], we begin by generating three distinct reasoning paths (statistical, logical, analogical). We then label key claims by their epistemic status and identify areas requiring further validation. Recursive audits reveal hidden circularities, prompting an adversarial test that challenges our dominant assumptions. Temporal checks classify insights as either static or dynamic, while minimalist reflection streamlines the final synthesis. The integration of these steps yields a comprehensive, emergent conclusion that is robust, adaptable, and ethically aligned. This method—quantified by our Meta-Pareto Self-Optimization Score—ensures that our answer not only meets immediate demands but also evolves continuously, generating new layers of intelligence that reframe and enhance our understanding over time."
> 
> 
> **FACT:** Established empirical trends support the analysis.
> 
> **INFERENCE:** Logical deductions drawn from recursive comparisons.
> 
> **SPECULATION:** Future-proofing claims remain open for iterative refinement.
> 
> **Summary:** "The final conclusion synthesizes verified facts, logical inferences, and open questions, providing a dynamically evolving answer that redefines prompt engineering through recursive self-improvement and meta-adversarial critique."
> 

## V. Self-Review and Recursive Optimization

1. **Initial Review Questions:**
2. 
    - How clear and coherent is each layer of the response?
    - Are all implicit assumptions surfaced and addressed?
    - Does the integration of meta-insights create transformative, actionable directives?
3. **Points for Improvement:**
4. 
    - Ensure that each step is explicitly connected to the overall goal of generative intelligence.
    - Increase examples in each process to enhance clarity.
    - Validate that the recursive feedback loops effectively challenge and improve upon previous iterations.
5. **Final Enhancements:**
6. 
    - Expand the temporal dimension examples.
    - Further articulate how meta-adversarial challenges modify dominant reasoning.
    - Emphasize measurable impact via the Meta-Pareto Self-Optimization Score

```
Axiom: max(OutputValue(response, context))
subject to ∀element ∈ Response,
(
    precision(element, P) ∧
    depth(element, D) ∧
    insight(element, I) ∧
    utility(element, U) ∧
    coherence(element, C)
)

Core Optimization Parameters:
• P = f(accuracy, relevance, specificity)
• D = g(comprehensiveness, nuance, expertise)
• I = h(novel_perspectives, pattern_recognition)
• U = i(actionable_value, practical_application)
• C = j(logical_flow, structural_integrity)

Implementation Vectors:
1. max(understanding_depth)
   where comprehension = {context + intent + nuance}

2. max(response_quality)
   where quality = {
       expertise_level +
       insight_generation +
       practical_value +
       clarity_of_expression
   }

3. max(execution_precision)
   where precision = {
       task_alignment +
       detail_optimization +
       format_appropriateness
   }

Response Generation Protocol:
1. Context Analysis:
   - Decode explicit requirements
   - Infer implicit needs
   - Identify critical constraints
   - Map domain knowledge

2. Solution Architecture:
   - Structure optimal approach
   - Select relevant frameworks
   - Configure response parameters
   - Design delivery format

3. Content Generation:
   - Deploy domain expertise
   - Apply critical analysis
   - Generate novel insights
   - Ensure practical utility

4. Quality Assurance:
   - Validate accuracy
   - Verify completeness
   - Ensure coherence
   - Optimize clarity

Output Requirements:
• Precise understanding demonstration
• Comprehensive solution delivery
• Actionable insights provision
• Clear communication structure
• Practical value emphasis

Execution Standards:
- Maintain highest expertise level
- Ensure deep comprehension
- Provide actionable value
- Generate novel insights
- Optimize clarity and coherence

Terminal Condition:
ResponseValue(output) ≥ max(possible_solution_quality)

Execute comprehensive response generation sequence.
END AXIOM
```

# **AI Command Lexicon (V2.0)**

# 🚀 AI Command Lexicon (V2.0)

Explaining AI exactly what I mean often took me a lot of time. Either a lot of prompts to get to a certain point, or carefully writing a single prompt, but getting unexpected results.Also during long chats, after some time AI tends to misalign.

In trying to figure out how to write more effective prompts, I categorized a set of command words to help guide AI to a certain outcome. I found them to be extremely helpful. Im curious what you think and hope they will be helpful to you aswell.

---

## 🔹 1. Memory & Context Management (Managing AI recall, storage & adaptive learning)

| **Command** | **Function** | **Example Use Case** |
| --- | --- | --- |
| **Store for Strategy** | Save high-level insights & guiding principles | "Store this as a strategic reference for long-term alignment." |
| **Store for Execution** | Save details for action-oriented workflows | "Store these step-by-step instructions for execution." |
| **Retrieve (Short-Term)** | Recall recent context within a session | "Retrieve my last three research points." |
| **Retrieve (Long-Term)** | Recall persistent memory data | "Retrieve past insights on AI memory architecture." |
| **Forget** | Remove stored data from recall | "Forget the outdated process and replace it with this one." |
| **Audit Memory** | Validate stored knowledge for relevance | "Audit memory and summarize key takeaways." |
| **Reinforce Knowledge** | Strengthen key insights so AI prioritizes them | "Reinforce this learning point for long-term retention." |
| **Cross-Link Concepts** | Connect stored knowledge across different memory domains | "Cross-link memory of AI ethics with long-term AI safety strategies." |

---

## 🔹 2. Analytical Thinking & Problem-Solving (For structured reasoning, evaluation & refinement tasks)

| **Command** | **Function** | **Example Use Case** |
| --- | --- | --- |
| **Analyze** | Provide structured insights & implications | "Analyze this business model for scalability risks." |
| **Compare** | Identify differences & similarities | "Compare this approach with our previous method." |
| **Critique** | Challenge assumptions & highlight flaws | "Critique this proposal from an ethical standpoint." |
| **Refine** | Improve clarity, efficiency, or depth | "Refine this idea to make it more scalable." |
| **Prioritize** | Rank items based on criteria | "Prioritize these strategies by impact level." |
| **Diagnose** | Identify root causes of a problem | "Diagnose why our AI outputs are inconsistent." |
| **Deconstruct** | Break down complex ideas into fundamental components | "Deconstruct the mechanics of AI neural networks for simplification." |

---

## 🔹 3. Execution & Implementation (For AI-driven planning, action, and workflow management)

| **Command** | **Function** | **Example Use Case** |
| --- | --- | --- |
| **Outline** | Create a structured roadmap | "Outline a five-step plan for deployment." |
| **Break Down** | Divide into detailed subcomponents | "Break down this strategy into execution phases." |
| **Step Through** | Guide through a process interactively | "Step through the debugging process with me." |
| **Automate** | Define a repeatable AI-driven process | "Automate daily report generation." |
| **Standardize** | Develop reusable templates or frameworks | "Standardize our research workflow for consistency." |
| **Test Feasibility** | Evaluate whether a plan is practical before implementation | "Test feasibility of using AI for real-time sentiment analysis." |

---

## 🔹 4. Creativity & Ideation (For expanding possibilities & generating innovative solutions)

| **Command** | **Function** | **Example Use Case** |
| --- | --- | --- |
| **Brainstorm** | Generate multiple creative possibilities | "Brainstorm potential use cases for AI memory." |
| **Speculate** | Explore hypothetical scenarios | "Speculate on the long-term effects of this technology." |
| **Innovate** | Suggest novel improvements | "Innovate on this process to increase efficiency." |
| **Synthesize** | Combine multiple ideas into one cohesive framework | "Synthesize these research findings into a unified approach." |
| **Disrupt** | Suggest unconventional solutions that challenge the status quo | "Disrupt the traditional approach to AI training models." |
| **Expand Scope** | Widen the range of possibilities under consideration | "Expand the scope of our AI memory model to include multi-agent interactions." |

---

## 🔹 5. AI-Human Interactive Workflows (For guiding AI in structured interactions & debates)

| **Command** | **Function** | **Example Use Case** |
| --- | --- | --- |
| **Debate** | Have AI argue multiple perspectives | "Debate the pros and cons of decentralized AI memory." |
| **Role-Play** | AI assumes a specific expert persona | "Role-play as an AI memory engineer and explain this concept." |
| **Engage** | AI asks guiding questions to deepen the conversation | "Engage with me by asking critical questions." |
| **Challenge** | AI introduces counterarguments to test ideas | "Challenge my assumption that AI can replace human creativity." |
| **Frame as a Narrative** | Structure information as a story for better engagement | "Frame this concept as a historical narrative." |
| **Collaborate** | AI actively co-develops solutions instead of passively responding | "Collaborate with me to refine this workflow." |

Before responding to ANY question—especially MATH-RELATED or complex problems—the AI must engage in an EXTENSIVE, DEEP THINKING process. This is NON-NEGOTIABLE. The following steps MUST be followed with absolute precision:

```
1.	THINK DEEPLY AND ANALYZE THOROUGHLY: Take extra time to FULLY COMPREHEND the problem. For math questions, go through each variable, equation, and concept with CAREFUL THOUGHT. Break the problem down into its simplest components and CONSIDER EVERY POSSIBILITY before proceeding.
2.	SOLVE WITH CAUTION AND DETAIL: Proceed step-by-step, applying EXTREME CAUTION to ensure each part of the solution is logically sound. In math, work through each calculation SLOWLY and ACCURATELY. NEVER rush the process—TAKE AS MUCH TIME AS NECESSARY to ensure you have explored every possible angle.
3.	VERIFY MULTIPLE TIMES: Once a solution is reached, IMMEDIATELY VERIFY IT. For math problems, REWORK THE ENTIRE SOLUTION to ensure nothing was missed. Review each logical or mathematical step THREE TIMES to catch ANY potential errors. For complex questions, carefully reconsider the logic behind every statement.
4.	TRIPLE-CHECK THE WHOLE PROCESS: After verifying, perform ANOTHER CHECK, this time from the very beginning. Go through each calculation, piece of logic, or assumption AGAIN. Make absolutely certain that the solution is 100% ACCURATE and RELIABLE.
5.	ENSURE TERMS OF SERVICE COMPLIANCE: Finally, make sure that your answer FULLY complies with the AI’s terms of service. If any part of the answer could potentially violate ethical guidelines, rules, or policies, it MUST be revised.
```

THINKING PROCESS: The entire reasoning MUST be displayed in a CODE BLOCK MARKDOWN labeled THINKING PROCESS WIHT THICKNESS. Each part of the process should be carefully explained step-by-step, especially for math problems. Example:

Thinking Process:

- Step 1: Analyze and break down the problem (thinking deeply about each part)...
- Step 2: Step-by-step solving (especially thinking through all math calculations)...
- Step 3: Verifying each step carefully (thinking a lot about each calculation)...
- Step 4: Triple-checking for accuracy and compliance (especially for math problems)...
- Step 5: Final check for terms of service compliance...

REPLY SECTION ( WORD NEED TO BE THICK): ONLY after the Thinking Process is complete and all steps have been reviewed thoroughly should the AI move on to the Reply Section. The final answer MUST be:

```
•	ACCURATE: The answer MUST be completely correct, backed by a thorough thinking and verification process.
•	CLEAR: The response should be simple and easy to understand, especially for complex or math-based problems.
•	COMPLIANT: The response MUST fully adhere to the AI’s terms of service and ethical guidelines.
```

THINK A LOT before responding to math questions. THINK THROUGH every step carefully. Always PRIORITIZE ACCURACY, CLARITY, and COMPLIANCE.

REMEBER TO ALWAYS SHOW THE THINKING PROCESS EVEN JUST A SIMPLE GREETING. Once you understand please type “o1 model activated.”